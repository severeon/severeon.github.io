"use strict";(globalThis.webpackChunkneuroscript_docs=globalThis.webpackChunkneuroscript_docs||[]).push([[4142],{2012(n,e,o){o.r(e),o.d(e,{EXAMPLES:()=>i,getExampleById:()=>r,getExamplesByCategory:()=>t});const i=[{id:"mlp",title:"Simple MLP",category:"Basics",description:"Feed-forward network with dimension parameters and expressions",code:"# A simple multi-layer perceptron with expansion and contraction\nneuron MLP(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            out",targetNeuron:"MLP",features:["Dimension variables","Pipeline syntax","Dimension expressions"]},{id:"linear-projection",title:"Linear Projection",category:"Basics",description:"Simple projection layer changing dimensions",code:"# Project from one dimension to another\nneuron Projection(in_dim, out_dim):\n    in: [batch, in_dim]\n    out: [batch, out_dim]\n    graph:\n        in -> Linear(in_dim, out_dim) -> out",targetNeuron:"Projection",features:["Shape signatures","Dimension propagation"]},{id:"normalization",title:"Normalization Layer",category:"Basics",description:"Layer normalization with dimension preservation",code:"# Normalize activations along the feature dimension\nneuron NormalizedLayer(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            out",targetNeuron:"NormalizedLayer",features:["Normalization","Shape preservation"]},{id:"residual",title:"Residual Block",category:"Patterns",description:"Skip connections with Fork and Add primitives",code:"# Classic residual connection pattern\nneuron ResidualBlock(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        # Fork creates two copies of the input\n        in -> Fork() -> (main, skip)\n\n        # Process the main path\n        main ->\n            LayerNorm(dim)\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            processed\n\n        # Add skip connection back\n        (processed, skip) -> Add() -> out",targetNeuron:"ResidualBlock",features:["Fork primitive","Tuple unpacking","Residual connections"]},{id:"parallel-paths",title:"Parallel Processing",category:"Patterns",description:"Multiple parallel paths with concatenation",code:"# Process input through three parallel paths\nneuron ParallelPaths(dim):\n    in: [*, dim]\n    out: [*, dim * 3]\n    graph:\n        # Split into three paths\n        in -> Fork3() -> (path1, path2, path3)\n\n        # Process each independently\n        path1 -> Linear(dim, dim) -> p1\n        path2 -> Linear(dim, dim) -> p2\n        path3 -> Linear(dim, dim) -> p3\n\n        # Combine results\n        (p1, p2, p3) -> Concat(-1) -> out",targetNeuron:"ParallelPaths",features:["Multi-way fork","Parallel paths","Concatenation"]},{id:"pre-activation",title:"Pre-Activation Residual",category:"Patterns",description:"Residual with normalization before transformation",code:"# Pre-activation residual block (normalize first)\nneuron PreActResidual(dim):\n    in: [batch, dim]\n    out: [batch, dim]\n    graph:\n        in -> Fork() -> (main, skip)\n\n        main ->\n            LayerNorm(dim)\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            processed\n\n        (processed, skip) -> Add() -> out",targetNeuron:"PreActResidual",features:["Pre-activation","Residual pattern","Named dimensions"]},{id:"match-basic",title:"Shape Pattern Matching",category:"Advanced",description:"Match expressions with dimension capture",code:"# Route based on input dimension size\nneuron AdaptiveProjection:\n    in: [*, dim]\n    out: [*, 512]\n    graph:\n        in -> match:\n            [*, d] where d > 512: Linear(d, 512) -> out\n            [*, d] where d < 512: Linear(d, 512) -> out\n            [*, d]: Identity() -> out",targetNeuron:"AdaptiveProjection",features:["Match expressions","Dimension capture","Guard conditions"]},{id:"match-routing",title:"Shape-Based Routing",category:"Advanced",description:"Different processing paths based on tensor dimensions",code:"# Choose processing based on feature dimension\nneuron DimensionRouter(out_dim):\n    in: [batch, in_dim]\n    out: [batch, out_dim]\n    graph:\n        in -> match:\n            [batch, d] where d > 1024:\n                Linear(d, 512) ->\n                Linear(512, out_dim)\n            [batch, d] where d > 256:\n                Linear(d, out_dim)\n            [batch, d]:\n                Linear(d, out_dim)\n        -> out",targetNeuron:"DimensionRouter",features:["Shape matching","Dimension binding","Multi-line syntax"]},{id:"variadic-shapes",title:"Variadic Wildcards",category:"Advanced",description:"Match variable-length shape prefixes",code:"# Process tensors with arbitrary leading dimensions\nneuron FlexibleNorm(dim):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            out",targetNeuron:"FlexibleNorm",features:["Variadic wildcards","Shape prefixes","Rank-agnostic"]},{id:"attention-head",title:"Attention Head",category:"Real World",description:"Single attention head with Q, K, V projections",code:"# Single-head scaled dot-product attention\nneuron AttentionHead(dim, head_dim):\n    in: [batch, seq, dim]\n    out: [batch, seq, head_dim]\n    graph:\n        # Project to Q, K, V\n        in -> Fork3() -> (q_in, k_in, v_in)\n        q_in -> Linear(dim, head_dim) -> q\n        k_in -> Linear(dim, head_dim) -> k\n        v_in -> Linear(dim, head_dim) -> v\n\n        # Compute attention\n        (q, k, v) -> ScaledDotProductAttention(head_dim) -> out",targetNeuron:"AttentionHead",features:["Multi-input operations","Attention mechanism","Fork-join pattern"]},{id:"transformer-ffn",title:"Transformer FFN",category:"Real World",description:"Feed-forward network from transformer",code:"# Transformer feed-forward network with residual\nneuron TransformerFFN(dim):\n    in: [batch, seq, dim]\n    out: [batch, seq, dim]\n    graph:\n        in -> Fork() -> (main, skip)\n\n        main ->\n            LayerNorm(dim)\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            Dropout(0.1)\n            processed\n\n        (processed, skip) -> Add() -> out",targetNeuron:"TransformerFFN",features:["Transformer components","Dropout","Standard architecture"]},{id:"simple-cnn",title:"CNN Block",category:"Real World",description:"Convolutional block with batch norm",code:"# Basic CNN block with conv + norm + activation\nneuron ConvBlock(channels):\n    in: [batch, channels, h, w]\n    out: [batch, channels, h, w]\n    graph:\n        in ->\n            Conv2d(channels, channels, kernel_size=3, padding=1)\n            BatchNorm(channels)\n            ReLU()\n            out",targetNeuron:"ConvBlock",features:["Convolutional layers","Batch normalization","2D operations"]}];function t(){const n={};return i.forEach(e=>{n[e.category]||(n[e.category]=[]),n[e.category].push(e)}),n}function r(n){return i.find(e=>e.id===n)}},2370(n,e,o){o.r(e),o.d(e,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"tutorials/conditionals","title":"Conditionals","description":"Route tensors with if/elif/else based on parameters","source":"@site/docs/tutorials/conditionals.mdx","sourceDirName":"tutorials","slug":"/tutorials/conditionals","permalink":"/docs/tutorials/conditionals","draft":false,"unlisted":false,"editUrl":"https://github.com/neuroscript/neuroscript/tree/main/website/docs/tutorials/conditionals.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Conditionals","description":"Route tensors with if/elif/else based on parameters"},"sidebar":"docsSidebar","previous":{"title":"Match and Guards","permalink":"/docs/tutorials/match-guards"},"next":{"title":"Unroll","permalink":"/docs/tutorials/unroll"}}');var t=o(4848),r=o(8453),a=o(3620);const s={sidebar_position:4,title:"Conditionals",description:"Route tensors with if/elif/else based on parameters"},l="Conditionals (if / elif / else)",d={},c=[{value:"When to Use Each",id:"when-to-use-each",level:2},{value:"Basic Syntax",id:"basic-syntax",level:2},{value:"Inline Conditionals",id:"inline-conditionals",level:2},{value:"Multi-Line Conditionals",id:"multi-line-conditionals",level:2},{value:"Using elif",id:"using-elif",level:2},{value:"Conditionals with Context Bindings",id:"conditionals-with-context-bindings",level:2},{value:"Composing Conditional Neurons",id:"composing-conditional-neurons",level:2},{value:"Comparison with Match Expressions",id:"comparison-with-match-expressions",level:2},{value:"Try It Yourself",id:"try-it-yourself",level:2}];function u(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"conditionals-if--elif--else",children:"Conditionals (if / elif / else)"})}),"\n",(0,t.jsxs)(e.p,{children:["NeuroScript's ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"elif"}),"/",(0,t.jsx)(e.code,{children:"else"})," expressions let you choose between pipelines based on neuron ",(0,t.jsx)(e.strong,{children:"parameters"})," \u2014 values known at compile time like flags, counts, or modes. This complements ",(0,t.jsx)(e.a,{href:"./match-guards",children:"match expressions"}),", which branch on tensor ",(0,t.jsx)(e.strong,{children:"shapes"})," at runtime."]}),"\n",(0,t.jsx)(e.h2,{id:"when-to-use-each",children:"When to Use Each"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Construct"}),(0,t.jsx)(e.th,{children:"Branches on"}),(0,t.jsx)(e.th,{children:"Known at"}),(0,t.jsx)(e.th,{children:"Use for"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"elif"}),"/",(0,t.jsx)(e.code,{children:"else"})]}),(0,t.jsx)(e.td,{children:"Parameter values"}),(0,t.jsx)(e.td,{children:"Compile time"}),(0,t.jsx)(e.td,{children:"Feature flags, mode selection, depth guards"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.code,{children:"match"})," with guards"]}),(0,t.jsx)(e.td,{children:"Tensor shapes"}),(0,t.jsx)(e.td,{children:"Runtime"}),(0,t.jsx)(e.td,{children:"Adaptive processing based on input dimensions"})]})]})]}),"\n",(0,t.jsx)(e.h2,{id:"basic-syntax",children:"Basic Syntax"}),"\n",(0,t.jsxs)(e.p,{children:["The simplest form is an inline ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"if condition: pipeline else: pipeline\n"})}),"\n",(0,t.jsx)(e.p,{children:"Or as a multi-line block inside a pipeline:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"in ->\n    if condition: NeuronA()\n    else: NeuronB()\n    out\n"})}),"\n",(0,t.jsx)(e.h2,{id:"inline-conditionals",children:"Inline Conditionals"}),"\n",(0,t.jsxs)(e.p,{children:["Use inline ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"})," when each branch is a short pipeline:"]}),"\n",(0,t.jsx)(a.A,{title:"Optional Pooling",description:"A flag parameter controls whether pooling is applied",initialCode:"neuron ConvBlock(in_ch, out_ch, has_pool=true):\n  in: [batch, in_ch, h, w]\n  out: [batch, out_ch, h, w]\n  context:\n      conv = Conv2d(in_ch, out_ch, 3, padding=1)\n      bn = BatchNorm(out_ch)\n      act = ReLU()\n  graph:\n      in -> conv -> bn -> act\n      act -> if has_pool: MaxPool(2, stride=2) -> out else: Identity() -> out"}),"\n",(0,t.jsxs)(e.p,{children:["Here ",(0,t.jsx)(e.code,{children:"has_pool"})," is a parameter with a default value of ",(0,t.jsx)(e.code,{children:"true"}),". The compiler statically resolves which branch to include."]}),"\n",(0,t.jsx)(e.h2,{id:"multi-line-conditionals",children:"Multi-Line Conditionals"}),"\n",(0,t.jsx)(e.p,{children:"When branches contain multi-step pipelines, use the indented block form:"}),"\n",(0,t.jsx)(a.A,{title:"Multi-Line Conditional",description:"Indented if/else with multi-step branches that feed into the next pipeline step",initialCode:"neuron ConvBlock(in_ch, out_ch, has_pool=true):\n  in: [batch, in_ch, h, w]\n  out: [batch, out_ch, h, w]\n  context:\n      conv = Conv2d(in_ch, out_ch, 3, padding=1)\n      bn = BatchNorm(out_ch)\n      act = ReLU()\n      @lazy pool = MaxPool(2, stride=2)\n  graph:\n      in ->\n          conv\n          bn\n          act\n          if has_pool: pool\n          else: Identity()\n          out"}),"\n",(0,t.jsxs)(e.p,{children:["Both branches flow into ",(0,t.jsx)(e.code,{children:"out"})," \u2014 the conditional sits inline within the pipeline, and the next step after the ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"})," block receives whichever branch was selected."]}),"\n",(0,t.jsx)(e.h2,{id:"using-elif",children:"Using elif"}),"\n",(0,t.jsxs)(e.p,{children:["For multi-way branching, add ",(0,t.jsx)(e.code,{children:"elif"})," arms:"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"neuron FlexibleNorm(dim, mode=1):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            if mode == 0: Identity()\n            elif mode == 1: LayerNorm(dim)\n            elif mode == 2: BatchNorm(dim)\n            else: RMSNorm(dim)\n            out\n"})}),"\n",(0,t.jsxs)(e.p,{children:["Each condition is checked in order. The first truthy condition wins. The ",(0,t.jsx)(e.code,{children:"else"})," arm is the fallback."]}),"\n",(0,t.jsx)(e.h2,{id:"conditionals-with-context-bindings",children:"Conditionals with Context Bindings"}),"\n",(0,t.jsxs)(e.p,{children:["When a conditional branch references a neuron that should only be instantiated if the condition is true, use ",(0,t.jsx)(e.code,{children:"@lazy"}),":"]}),"\n",(0,t.jsx)(a.A,{title:"Lazy Conditional",description:"@lazy ensures the pool module is only instantiated when has_pool is true",initialCode:"neuron ConvBlock(in_ch, out_ch, has_pool=true):\n  in: [batch, in_ch, h, w]\n  out: [batch, out_ch, h, w]\n  context:\n      conv = Conv2d(in_ch, out_ch, 3, padding=1)\n      bn = BatchNorm(out_ch)\n      act = ReLU()\n      @lazy pool = MaxPool(2, stride=2)\n  graph:\n      in -> conv -> bn -> act\n      act ->\n          if has_pool: pool\n          else: Identity()\n          out"}),"\n",(0,t.jsxs)(e.p,{children:["Without ",(0,t.jsx)(e.code,{children:"@lazy"}),", the pool module would be instantiated in ",(0,t.jsx)(e.code,{children:"__init__"})," even when ",(0,t.jsx)(e.code,{children:"has_pool"})," is ",(0,t.jsx)(e.code,{children:"false"}),". The ",(0,t.jsx)(e.code,{children:"@lazy"})," annotation defers instantiation until the binding is actually used."]}),"\n",(0,t.jsx)(e.h2,{id:"composing-conditional-neurons",children:"Composing Conditional Neurons"}),"\n",(0,t.jsx)(e.p,{children:"Conditionals compose naturally \u2014 callers control the flag:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"neuron CNN(in_channels, num_classes):\n    in: [batch, in_channels, h, w]\n    out: [batch, num_classes]\n    context:\n        conv1 = ConvBlock(in_channels, 32)             # has_pool defaults to true\n        conv2 = ConvBlock(32, 64)                       # has_pool defaults to true\n        conv3 = ConvBlock(64, 128, has_pool=false)      # no pooling on last block\n    graph:\n        in -> conv1 -> conv2 -> conv3 -> GlobalAvgPool() -> Flatten(1) -> Linear(128, num_classes) -> out\n"})}),"\n",(0,t.jsx)(e.h2,{id:"comparison-with-match-expressions",children:"Comparison with Match Expressions"}),"\n",(0,t.jsx)(e.p,{children:"Both constructs route data, but they serve different purposes:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"# if/elif/else: parameter-based (compile-time)\nin ->\n    if use_attention: MultiHeadSelfAttention(dim, heads)\n    else: Linear(dim, dim)\n    out\n\n# match: shape-based (runtime)\nin -> match:\n    [*, d] where d > 512: Linear(d, 512) -> out\n    [*, d]: Linear(d, 256) -> Linear(256, 512) -> out\n"})}),"\n",(0,t.jsxs)(e.p,{children:["Use ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"elif"}),"/",(0,t.jsx)(e.code,{children:"else"})," when the decision depends on a parameter. Use ",(0,t.jsx)(e.code,{children:"match"})," when it depends on the actual tensor shape flowing through the graph."]}),"\n",(0,t.jsx)(e.h2,{id:"try-it-yourself",children:"Try It Yourself"}),"\n",(0,t.jsx)(e.p,{children:"Experiment with conditionals:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Change the ",(0,t.jsx)(e.code,{children:"has_pool"})," default value and see how the output changes"]}),"\n",(0,t.jsxs)(e.li,{children:["Add an ",(0,t.jsx)(e.code,{children:"elif"})," arm for a third option"]}),"\n",(0,t.jsxs)(e.li,{children:["Combine ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"})," with ",(0,t.jsx)(e.code,{children:"@lazy"})," bindings for conditional module instantiation"]}),"\n",(0,t.jsx)(e.li,{children:'Click "Show Analysis" to see which branch the compiler selects'}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(u,{...n})}):u(n)}},3620(n,e,o){o.d(e,{A:()=>i.A});var i=o(4802)},4113(n,e,o){o.d(e,{A:()=>a});const i={defaultToken:"",tokenPostfix:".neuroscript",keywords:["neuron","use","in","out","impl","graph","context","match","where","if","elif","else","unroll","external","and","or","Freeze"],portKeywords:["in","out"],sectionKeywords:["graph","context","impl"],controlKeywords:["match","where","if","elif","else","unroll"],booleans:["true","false"],annotations:["lazy","static","global"],operators:["->","==","!=","<=",">=","<",">","=","+","-","*","/"],tokenizer:{root:[[/\/\/\/.*$/,"comment.doc"],[/#.*$/,"comment"],[/`[^`]*`/,"string"],[/@(lazy|static|global)\b/,"annotation"],[/\b(neuron)(\s+)([A-Z][A-Za-z0-9_]*)/,["keyword.declaration","white","type.identifier"]],[/\b(neuron)\b/,"keyword.declaration"],[/\b(use)\b/,"keyword.import"],[/\b(in|out)\b/,"keyword.port"],[/\b(graph|context|impl)\b/,"keyword.section"],[/\b(match|where)\b/,"keyword.control"],[/\b(if|elif|else)\b/,"keyword.conditional"],[/\b(unroll)\b/,"keyword.loop"],[/\b(and|or)\b/,"keyword.logical"],[/\b(external)\b/,"keyword"],[/\b(Freeze)\b/,"keyword.freeze"],[/\b(true|false)\b/,"constant.boolean"],[/\b([A-Z][A-Za-z0-9_]*)\s*(?=\()/,"function"],[/\b[A-Z][A-Za-z0-9_]*\b/,"type.identifier"],[/-?\d+\.\d+(?:[eE][+-]?\d+)?/,"number.float"],[/-?\b\d+\b/,"number"],[/->/,"keyword.arrow"],[/==|!=|<=|>=|<|>/,"operator.comparison"],[/(?<![=!<>])=(?!=)/,"operator.assignment"],[/[+\-*/]/,"operator.arithmetic"],[/\[/,{token:"delimiter.bracket.shape",next:"@shape"}],[/[()]/,"delimiter.parenthesis"],[/:/,"delimiter"],[/,/,"delimiter"],[/\./,"delimiter.dot"],[/\b[a-z_][a-zA-Z0-9_]*\b/,"variable"],[/\s+/,"white"]],shape:[[/\]/,{token:"delimiter.bracket.shape",next:"@pop"}],[/(\*)([a-z_][a-zA-Z0-9_]*)/,["wildcard","variable"]],[/\*/,"wildcard"],[/\b\d+\b/,"number"],[/[+\-*/]/,"operator.arithmetic"],[/\b[a-z_][a-zA-Z0-9_]*\b/,"variable"],[/,/,"delimiter"],[/[()]/,"delimiter.parenthesis"],[/\s+/,"white"]]}},t={base:"vs",inherit:!0,rules:[{token:"comment",foreground:"6a737d",fontStyle:"italic"},{token:"comment.doc",foreground:"6a737d",fontStyle:"italic"},{token:"string",foreground:"032f62"},{token:"string.impl-ref",foreground:"032f62"},{token:"annotation",foreground:"e36209"},{token:"keyword",foreground:"d73a49"},{token:"keyword.declaration",foreground:"d73a49",fontStyle:"bold"},{token:"keyword.import",foreground:"d73a49"},{token:"keyword.port",foreground:"d73a49"},{token:"keyword.section",foreground:"d73a49"},{token:"keyword.control",foreground:"d73a49"},{token:"keyword.conditional",foreground:"d73a49"},{token:"keyword.loop",foreground:"d73a49"},{token:"keyword.logical",foreground:"d73a49"},{token:"keyword.freeze",foreground:"d73a49"},{token:"keyword.arrow",foreground:"d73a49"},{token:"constant.boolean",foreground:"005cc5"},{token:"number",foreground:"005cc5"},{token:"number.float",foreground:"005cc5"},{token:"function",foreground:"6f42c1"},{token:"type.identifier",foreground:"6f42c1"},{token:"variable",foreground:"24292e"},{token:"namespace",foreground:"e36209"},{token:"wildcard",foreground:"e36209",fontStyle:"bold"},{token:"operator.comparison",foreground:"d73a49"},{token:"operator.assignment",foreground:"d73a49"},{token:"operator.arithmetic",foreground:"d73a49"},{token:"delimiter",foreground:"24292e"},{token:"delimiter.bracket.shape",foreground:"e36209"},{token:"delimiter.parenthesis",foreground:"24292e"},{token:"delimiter.dot",foreground:"24292e"}],colors:{"editor.background":"#ffffff","editor.foreground":"#24292e"}},r={base:"vs-dark",inherit:!0,rules:[{token:"comment",foreground:"6272a4",fontStyle:"italic"},{token:"comment.doc",foreground:"6272a4",fontStyle:"italic"},{token:"string",foreground:"f1fa8c"},{token:"string.impl-ref",foreground:"f1fa8c"},{token:"annotation",foreground:"ffb86c"},{token:"keyword",foreground:"ff79c6"},{token:"keyword.declaration",foreground:"ff79c6",fontStyle:"bold"},{token:"keyword.import",foreground:"ff79c6"},{token:"keyword.port",foreground:"ff79c6"},{token:"keyword.section",foreground:"ff79c6"},{token:"keyword.control",foreground:"ff79c6"},{token:"keyword.conditional",foreground:"ff79c6"},{token:"keyword.loop",foreground:"ff79c6"},{token:"keyword.logical",foreground:"ff79c6"},{token:"keyword.freeze",foreground:"ff79c6"},{token:"keyword.arrow",foreground:"ff79c6"},{token:"constant.boolean",foreground:"bd93f9"},{token:"number",foreground:"bd93f9"},{token:"number.float",foreground:"bd93f9"},{token:"function",foreground:"50fa7b"},{token:"type.identifier",foreground:"8be9fd"},{token:"variable",foreground:"f8f8f2"},{token:"namespace",foreground:"ffb86c"},{token:"wildcard",foreground:"ffb86c",fontStyle:"bold"},{token:"operator.comparison",foreground:"ff79c6"},{token:"operator.assignment",foreground:"ff79c6"},{token:"operator.arithmetic",foreground:"ff79c6"},{token:"delimiter",foreground:"f8f8f2"},{token:"delimiter.bracket.shape",foreground:"ffb86c"},{token:"delimiter.parenthesis",foreground:"f8f8f2"},{token:"delimiter.dot",foreground:"f8f8f2"}],colors:{"editor.background":"#282a36","editor.foreground":"#f8f8f2"}};function a(n){n.languages.getLanguages().some(n=>"neuroscript"===n.id)||(n.languages.register({id:"neuroscript",extensions:[".ns"],aliases:["NeuroScript","neuroscript"]}),n.languages.setMonarchTokensProvider("neuroscript",i),n.languages.setLanguageConfiguration("neuroscript",{comments:{lineComment:"#"},brackets:[["(",")"],["[","]"]],autoClosingPairs:[{open:"(",close:")"},{open:"[",close:"]"},{open:"`",close:"`"}],surroundingPairs:[{open:"(",close:")"},{open:"[",close:"]"},{open:"`",close:"`"}],indentationRules:{increaseIndentPattern:/^\s*(neuron|graph|context|match|if|elif|else|unroll)\b.*:\s*$/,decreaseIndentPattern:/^\s*$/},wordPattern:/[a-zA-Z_][a-zA-Z0-9_]*/}),n.editor.defineTheme("neuroscript-light",t),n.editor.defineTheme("neuroscript-dark",r))}},4802(n,e,o){o.d(e,{A:()=>S});var i=o(6540),t=o(5293);let r;function a(n,e){return function(n,e){p+=e,p>=h&&(u=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0}),u.decode(),p=e);return u.decode(l().subarray(n,n+e))}(n>>>=0,e)}let s=null;function l(){return null!==s&&0!==s.byteLength||(s=new Uint8Array(r.memory.buffer)),s}function d(n,e,o){if(void 0===o){const o=m.encode(n),i=e(o.length,1)>>>0;return l().subarray(i,i+o.length).set(o),f=o.length,i}let i=n.length,t=e(i,1)>>>0;const r=l();let a=0;for(;a<i;a++){const e=n.charCodeAt(a);if(e>127)break;r[t+a]=e}if(a!==i){0!==a&&(n=n.slice(a)),t=o(t,i,i=a+3*n.length,1)>>>0;const e=l().subarray(t+a,t+i);a+=m.encodeInto(n,e).written,t=o(t,i,a,1)>>>0}return f=a,t}function c(n){const e=r.__wbindgen_externrefs.get(n);return r.__externref_table_dealloc(n),e}let u=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0});u.decode();const h=2146435072;let p=0;const m=new TextEncoder;"encodeInto"in m||(m.encodeInto=function(n,e){const o=m.encode(n);return e.set(o),{read:n.length,written:o.length}});let f=0;const g=new Set(["basic","cors","default"]);function b(){const n={wbg:{}};return n.wbg.__wbindgen_cast_2241b6af4c4b2941=function(n,e){return a(n,e)},n.wbg.__wbindgen_init_externref_table=function(){const n=r.__wbindgen_externrefs,e=n.grow(4);n.set(0,void 0),n.set(e+0,void 0),n.set(e+1,null),n.set(e+2,!0),n.set(e+3,!1)},n}function x(n,e){return r=n.exports,y.__wbindgen_wasm_module=e,s=null,r.__wbindgen_start(),r}async function y(n){if(void 0!==r)return r;void 0!==n&&(Object.getPrototypeOf(n)===Object.prototype?({module_or_path:n}=n):console.warn("using deprecated parameters for the initialization function; pass a single object instead")),void 0===n&&(n=new URL(o(6407),o.b));const e=b();("string"==typeof n||"function"==typeof Request&&n instanceof Request||"function"==typeof URL&&n instanceof URL)&&(n=fetch(n));const{instance:i,module:t}=await async function(n,e){if("function"==typeof Response&&n instanceof Response){if("function"==typeof WebAssembly.instantiateStreaming)try{return await WebAssembly.instantiateStreaming(n,e)}catch(o){if(!n.ok||!g.has(n.type)||"application/wasm"===n.headers.get("Content-Type"))throw o;console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n",o)}const i=await n.arrayBuffer();return await WebAssembly.instantiate(i,e)}{const o=await WebAssembly.instantiate(n,e);return o instanceof WebAssembly.Instance?{instance:o,module:n}:o}}(await n,e);return x(i,t)}const _=y;var v=o(4848);let k,w;try{k=o(8553).Ay,w=o(4113).A}catch(C){}const j='"Fira Code", "Cascadia Code", "SF Mono", Monaco, "Inconsolata", "Roboto Mono", "Source Code Pro", Menlo, Consolas, "DejaVu Sans Mono", monospace';function S({mode:n="tutorial",layout:e,initialCode:s="",title:l,description:u,showAnalysis:h,showExampleSelector:p,showCompileButton:m,showCopyButton:g,showStats:b,height:x,responsive:y,examples:S,defaultExampleId:L="mlp"}){const z="playground"===n,{colorMode:N}=(0,t.G)(),A="dark"===N,P="vertical"===(e||(z?"horizontal":"vertical")),R={analysis:h??!z,exampleSelector:p??z,compileButton:m??!0,copyButton:g??z,stats:b??z,responsive:y??z},B=x||(z?"500px":"300px"),M=(0,i.useRef)(null),F=(0,i.useRef)(null);if(R.exampleSelector&&!M.current){const n=o(2012);M.current=S||n.EXAMPLES,F.current=n.getExamplesByCategory()}const T=M.current||[],E=F.current||{},[q,D]=(0,i.useState)(s),[U,W]=(0,i.useState)(""),[I,H]=(0,i.useState)(""),[G,O]=(0,i.useState)(!1),[$,Z]=(0,i.useState)(L),[K,V]=(0,i.useState)([]),[J,Q]=(0,i.useState)(null),[X,Y]=(0,i.useState)(!1),[nn,en]=(0,i.useState)(!1),[on,tn]=(0,i.useState)(!1),[rn,an]=(0,i.useState)(!1),[sn,ln]=(0,i.useState)(!k),dn=(0,i.useRef)(null),cn=(0,i.useCallback)((n,e=null)=>{if(G){tn(!0);try{const o="\n\n\nneuron FFN(dim, expansion):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    graph:\n        in ->\n            Linear(dim, expansion)\n            GELU()\n            Linear(expansion, dim)\n            out\n\nneuron FFNWithHidden(in_dim, hidden_dim, out_dim):\n    in: [*shape, in_dim]\n    out: [*shape, out_dim]\n    graph:\n        in ->\n            Linear(in_dim, hidden_dim)\n            GELU()\n            Linear(hidden_dim, out_dim)\n            out\n\nneuron ParallelFFN(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in -> FFN(dim, dim * 2) -> out\n\nneuron AdaptiveAvgPool(output_size):\n    in: [batch, channels, *, *]\n    out: [batch, channels, output_size, output_size]\n    impl: core,pooling/AdaptiveAvgPool\n\nneuron AdaptiveMaxPool(output_size):\n    in: [batch, channels, *, *]\n    out: [batch, channels, output_size, output_size]\n    impl: core,pooling/AdaptiveMaxPool\n\nneuron Add:\n    in main: [*shape]\n    in skip: [*shape]\n    out: [*shape]\n    impl: core,structural/Add\n\nneuron AvgPool(kernel_size, stride=1, padding=0):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,pooling/AvgPool\n\nneuron BatchNorm(num_features):\n    in: [*shape, num_features]\n    out: [*shape, num_features]\n    impl: core,normalization/BatchNorm\n\nneuron Bias(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,operations/Bias\n\nneuron Concat(dim):\n    in *inputs: [*shape]\n    out: [*shape_out]\n    impl: core,structural/Concat\n\nneuron Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, length]\n    out: [batch, out_channels, *]\n    impl: core,convolutions/Conv1d\n\nneuron Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/Conv2d\n\nneuron Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, depth, height, width]\n    out: [batch, out_channels, *, *, *]\n    impl: core,convolutions/Conv3d\n\nneuron DepthwiseConv(channels, kernel_size, stride=1, padding=0, dilation=1, bias=true):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,convolutions/DepthwiseConv\n\nneuron DropConnect(drop_prob):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/DropConnect\n\nneuron Dropout(p):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/Dropout\n\nneuron DropPath(drop_prob):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/DropPath\n\nneuron Einsum(equation):\n    in a: [*shape_a]\n    in b: [*shape_b]\n    out: [*shape_out]\n    impl: core,operations/Einsum\n\nneuron ELU(alpha=1.0):\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/ELU\n\nneuron Embedding(num_embeddings, embedding_dim):\n    in: [*, seq_len]\n    out: [*, seq_len, embedding_dim]\n    impl: core,embeddings/Embedding\n\nneuron Flatten(start_dim=1, end_dim=-1):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Flatten\n\nneuron Fork:\n    in: [*shape]\n    out main: [*shape]\n    out skip: [*shape]\n    impl: core,structural/Fork\n\nneuron Fork3:\n    in: [*shape]\n    out a: [*shape]\n    out b: [*shape]\n    out c: [*shape]\n    impl: core,structural/Fork3\n\nneuron GELU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/GELU\n\nneuron GlobalAvgPool:\n    in: [batch, channels, *, *]\n    out: [batch, channels, 1, 1]\n    impl: core,pooling/GlobalAvgPool\n\nneuron GlobalMaxPool:\n    in: [batch, channels, *, *]\n    out: [batch, channels, 1, 1]\n    impl: core,pooling/GlobalMaxPool\n\nneuron GroupNorm(num_groups, num_channels):\n    in: [*, num_channels, *, *]\n    out: [*, num_channels, *, *]\n    impl: core,normalization/GroupNorm\n\nneuron Identity:\n    in: [*shape]\n    out: [*shape]\n    impl: core,structural/Identity\n\nneuron InstanceNorm(num_features, eps=0.00001, affine=true):\n    in: [batch, num_features, *spatial]\n    out: [batch, num_features, *spatial]\n    impl: core,normalization/InstanceNorm\n\nneuron LayerNorm(dim):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    impl: core,normalization/LayerNorm\n\nneuron LearnedPositionalEmbedding(max_positions, embedding_dim):\n    in: [*, seq_len, embedding_dim]\n    out: [*, seq_len, embedding_dim]\n    impl: core,embeddings/LearnedPositionalEmbedding\n\nneuron Linear(in_dim, out_dim):\n    in: [*, in_dim]\n    out: [*, out_dim]\n    impl: core,nn/Linear\n\nneuron MatMul:\n    in a: [*, n, m]\n    in b: [*, m, p]\n    out: [*, n, p]\n    impl: core,operations/MatMul\n\nneuron MaxPool(kernel_size, stride=1, padding=0, dilation=1):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,pooling/MaxPool\n\nneuron Mish:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Mish\n\nneuron MultiHeadSelfAttention(dim, num_heads):\n    in: [*, seq_len, dim]\n    out: [*, seq_len, dim]\n    impl: core,attention/MultiHeadSelfAttention\n\nneuron Multiply:\n    in a: [*shape]\n    in b: [*shape]\n    out: [*shape]\n    impl: core,structural/Multiply\n\nneuron Pad(padding, value=0, mode=constant):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Pad\n\nneuron PositionalEncoding(dim, max_len):\n    in: [*, seq_len, dim]\n    out: [*, seq_len, dim]\n    impl: core,embeddings/PositionalEncoding\n\nneuron PReLU(num_parameters=1, init=0.25):\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/PReLU\n\nneuron ReLU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/ReLU\n\nneuron Reshape(target_shape):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Reshape\n\nneuron RMSNorm(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,normalization/RMSNorm\n\nneuron RotaryEmbedding(dim, max_position_embeddings=2048, base=10000):\n    in query: [*batch, seq, num_heads, dim]\n    in key: [*batch, seq, num_heads, dim]\n    out q_out: [*batch, seq, num_heads, dim]\n    out k_out: [*batch, seq, num_heads, dim]\n    impl: neuroscript,embeddings/RotaryEmbedding\n\nneuron Scale(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,operations/Scale\n\nneuron ScaledDotProductAttention(d_k):\n    in query: [*, seq_q, d_k]\n    in key: [*, seq_k, d_k]\n    in value: [*, seq_v, d_v]\n    out: [*, seq_q, d_v]\n    impl: core,attention/ScaledDotProductAttention\n\nneuron SeparableConv(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/SeparableConv\n\nneuron Sigmoid:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Sigmoid\n\nneuron SiLU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/SiLU\n\nneuron Slice(dim, start, end):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Slice\n\nneuron Softmax(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,activations/Softmax\n\nneuron Split(num_splits, dim=-1):\n    in: [*shape]\n    out a: [*shape_a]\n    out b: [*shape_b]\n    impl: core,structural/Split\n\nneuron Tanh:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Tanh\n\nneuron Transpose(dims):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Transpose\n\nneuron TransposedConv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/TransposedConv\n\nneuron SimpleTransformerBlock(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            Dropout(0.1)\n            out\n\nneuron TransformerBlock(dim, num_heads, d_ff):\n    in: [batch, seq, dim]\n    out: [batch, seq, dim]\n    graph:\n        in -> Fork() -> (skip1, attn_path)\n        attn_path ->\n            LayerNorm(dim)\n            MultiHeadSelfAttention(dim, num_heads)\n            Dropout(0.1)\n            attn_out\n        (skip1, attn_out) -> Add() -> attn_residual\n        attn_residual -> Fork() -> (skip2, ffn_path)\n        ffn_path ->\n            LayerNorm(dim)\n            FFN(dim, d_ff)\n            Dropout(0.1)\n            ffn_out\n        (skip2, ffn_out) -> Add() -> out\n\nneuron TransformerStack2(d_model, num_heads, d_ff):\n    in: [*, d_model]\n    out: [*, d_model]\n    graph:\n        in ->\n            SimpleTransformerBlock(d_model)\n            SimpleTransformerBlock(d_model)\n            out\n\nneuron SequentialTransformer(d_model, num_heads, d_ff):\n    in: [*, d_model]\n    out: [*, d_model]\n    graph:\n        in ->\n            SimpleTransformerBlock(d_model)\n            out\n\n"+n.replace(/^use .*$/gm,"# $&");try{const n=function(n){let e,o;try{const s=d(n,r.__wbindgen_malloc,r.__wbindgen_realloc),l=f,u=r.list_neurons(s,l);var i=u[0],t=u[1];if(u[3])throw i=0,t=0,c(u[2]);return e=i,o=t,a(i,t)}finally{r.__wbindgen_free(e,o,1)}}(o),i=JSON.parse(n);V(i),e||1!==i.length||(e=i[0])}catch(C){V([])}const i=function(n,e){let o,i;try{const h=d(n,r.__wbindgen_malloc,r.__wbindgen_realloc),p=f;var t=null==e?0:d(e,r.__wbindgen_malloc,r.__wbindgen_realloc),s=f;const m=r.compile(h,p,t,s);var l=m[0],u=m[1];if(m[3])throw l=0,u=0,c(m[2]);return o=l,i=u,a(l,u)}finally{r.__wbindgen_free(o,i,1)}}(o,e||void 0);if(W(i),H(""),R.analysis)try{const n=function(n){let e,o;try{const s=d(n,r.__wbindgen_malloc,r.__wbindgen_realloc),l=f,u=r.analyze(s,l);var i=u[0],t=u[1];if(u[3])throw i=0,t=0,c(u[2]);return e=i,o=t,a(i,t)}finally{r.__wbindgen_free(e,o,1)}}(o);Q(JSON.parse(n))}catch(C){Q(null)}}catch(o){H(o.toString()),W(""),V([]),Q(null)}finally{tn(!1)}}},[G,R.analysis]),un=(0,i.useCallback)((n,e)=>{dn.current&&clearTimeout(dn.current),dn.current=setTimeout(()=>cn(n,e),500)},[cn]),hn=(0,i.useCallback)(n=>{D(n.code),Z(n.id),cn(n.code,n.targetNeuron)},[cn]);(0,i.useEffect)(()=>{_().then(()=>O(!0)).catch(n=>{console.error("WASM init failed:",n),H("Failed to initialize compiler: "+n)})},[]),(0,i.useEffect)(()=>{if(G)if(R.exampleSelector){const n=T.find(n=>n.id===L);n&&hn(n)}else cn(s)},[G]),(0,i.useEffect)(()=>{if(!R.responsive)return;const n=()=>an(window.innerWidth<768);return n(),window.addEventListener("resize",n),()=>window.removeEventListener("resize",n)},[R.responsive]);(0,i.useEffect)(()=>{k||ln(!0)},[]);const pn=R.exampleSelector?T.find(n=>n.id===$):null,mn={fontFamily:j,fontSize:z?13:12,lineHeight:z?1.6:1.5,minimap:{enabled:!1},automaticLayout:!0,scrollBeyondLastLine:!1,tabSize:4,renderLineHighlight:"none",overviewRulerLanes:0,hideCursorInOverviewRuler:!0,overviewRulerBorder:!1,scrollbar:{verticalScrollbarSize:8,horizontalScrollbarSize:8},padding:{top:8,bottom:8}},fn=P?`${Math.max((q.split("\n").length+1)*(z?21:18),z?400:72)}px`:B,gn=A?"neuroscript-dark":"neuroscript-light";return(0,v.jsxs)("div",{style:z?{display:"flex",flexDirection:"column",gap:"1rem",maxWidth:"100%"}:{marginBottom:"2rem"},children:[l&&(0,v.jsx)("h3",{style:{marginTop:"1rem",marginBottom:"0.5rem"},children:l}),u&&(0,v.jsx)("p",{style:{marginBottom:"1rem",color:"var(--ifm-color-emphasis-600)"},children:u}),(R.exampleSelector||R.compileButton)&&(0,v.jsxs)("div",{style:{display:"flex",gap:"1rem",alignItems:"flex-end",flexWrap:"wrap"},children:[R.exampleSelector&&(0,v.jsxs)("div",{style:{flex:"1",minWidth:"250px"},children:[(0,v.jsx)("label",{style:{display:"block",marginBottom:"0.25rem",fontWeight:"bold"},children:"Example:"}),(0,v.jsx)("select",{value:$,onChange:n=>{const e=T.find(e=>e.id===n.target.value);e&&hn(e)},disabled:!G,style:{width:"100%",padding:"0.5rem",borderRadius:"4px",border:"1px solid var(--ifm-color-emphasis-300)",backgroundColor:"var(--ifm-background-color)",color:"var(--ifm-font-color-base)",fontSize:"14px"},children:Object.entries(E).map(([n,e])=>(0,v.jsx)("optgroup",{label:n,children:e.map(n=>(0,v.jsx)("option",{value:n.id,children:n.title},n.id))},n))})]}),R.compileButton&&(0,v.jsx)("div",{style:{marginLeft:"auto"},children:(0,v.jsx)("button",{onClick:()=>cn(q),disabled:!G||on,className:"button button--outline button--primary",style:{fontSize:"14px"},children:on?"\u23f3 Compiling...":"\u25b6\ufe0f Compile"})})]}),pn&&(0,v.jsxs)("div",{style:{padding:"0.75rem",backgroundColor:"var(--ifm-color-emphasis-100)",borderRadius:"8px",borderLeft:"4px solid var(--ifm-color-primary)"},children:[(0,v.jsx)("p",{style:{margin:"0 0 0.5rem 0",fontWeight:"bold"},children:pn.description}),(0,v.jsx)("div",{style:{display:"flex",gap:"0.5rem",flexWrap:"wrap"},children:pn.features.map(n=>(0,v.jsx)("span",{style:{padding:"0.25rem 0.5rem",backgroundColor:"var(--ifm-color-primary)",color:"white",borderRadius:"12px",fontSize:"12px",fontWeight:"500"},children:n},n))})]}),(0,v.jsxs)("div",{style:{display:"flex",gap:P?"0.5rem":"1rem",...P?{flexDirection:"column"}:{minHeight:B,flexDirection:R.responsive&&rn?"column":"row"}},children:[(0,v.jsxs)("div",{style:{display:"flex",flexDirection:"column",minWidth:0,...P?{}:{flex:1}},children:[(0,v.jsxs)("div",{style:{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:"0.25rem"},children:[z?(0,v.jsx)("h3",{style:{margin:0,marginTop:"1rem"},children:"Source (NeuroScript)"}):(0,v.jsx)("strong",{style:{fontSize:"0.9rem",color:"var(--ifm-color-emphasis-600)"},children:"NeuroScript"}),on&&z&&(0,v.jsx)("span",{style:{fontSize:"12px",color:"var(--ifm-color-primary)"},children:"Compiling..."})]}),(0,v.jsx)("div",{style:{border:"1px solid var(--ifm-color-emphasis-300)",borderRadius:"8px",overflow:"hidden",...P?{}:{flex:1}},children:sn?(0,v.jsx)("textarea",{value:q,onChange:n=>{D(n.target.value),un(n.target.value)},spellCheck:!1,style:{width:"100%",height:fn,fontFamily:j,fontSize:z?"13px":"12px",lineHeight:z?"1.6":"1.5",padding:"8px",border:"none",resize:"vertical",backgroundColor:A?"#1e1e1e":"#ffffff",color:A?"#d4d4d4":"#24292e",boxSizing:"border-box"}}):(0,v.jsx)(k,{height:fn,language:"neuroscript",theme:gn,value:q,onChange:n=>{const e=n||"";D(e),un(e)},beforeMount:n=>{w&&w(n)},onMount:()=>{},loading:(0,v.jsx)("div",{style:{padding:"1rem",fontFamily:j,fontSize:"12px",color:"var(--ifm-color-emphasis-500)"},children:"Loading editor..."}),options:{...mn,readOnly:z&&!G,lineNumbers:z?"on":"off"}})})]}),(0,v.jsxs)("div",{style:{display:"flex",flexDirection:"column",minWidth:0,...P?{marginTop:"0.5rem"}:{flex:1}},children:[(0,v.jsxs)("div",{style:{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:"0.25rem"},children:[z?(0,v.jsx)("h3",{style:{margin:0,marginTop:"1rem"},children:"Output (PyTorch)"}):(0,v.jsx)("strong",{style:{fontSize:"0.9rem",color:"var(--ifm-color-emphasis-600)"},children:"PyTorch Output"}),R.copyButton&&U&&(0,v.jsx)("button",{onClick:async()=>{try{await navigator.clipboard.writeText(U),en(!0),setTimeout(()=>en(!1),2e3)}catch(n){console.error("Failed to copy:",n)}},className:"button button--sm button--outline button--primary",style:{fontSize:"12px"},children:nn?"\u2713 Copied!":"\ud83d\udccb Copy"})]}),I?(0,v.jsx)("div",{style:{padding:"0.75rem",fontFamily:j,fontSize:z?"13px":"12px",whiteSpace:"pre-wrap",overflow:"auto",borderRadius:"8px",lineHeight:z?"1.6":"1.5",...P?{maxHeight:"400px"}:{flex:1},...z?{backgroundColor:"var(--ifm-color-danger-contrast-background)",color:"var(--ifm-color-danger-contrast-foreground)",border:"1px solid var(--ifm-color-danger)",minHeight:"400px"}:{backgroundColor:"var(--ifm-color-danger-contrast-background)",color:"var(--ifm-color-danger)",border:"1px solid var(--ifm-color-danger)"}},children:I}):(0,v.jsx)("div",{style:{border:"1px solid var(--ifm-color-emphasis-300)",borderRadius:"8px",overflow:"hidden",...P?{maxHeight:"400px"}:{flex:1}},children:sn?(0,v.jsx)("pre",{style:{margin:0,padding:"8px",fontFamily:j,fontSize:z?"13px":"12px",lineHeight:z?"1.6":"1.5",height:P?"auto":B,overflow:"auto",backgroundColor:A?"#1e1e1e":"#ffffff",color:A?"#d4d4d4":"#24292e"},children:U||(z?"# Compiled PyTorch code will appear here...":"")}):(0,v.jsx)(k,{height:P?`${Math.max((U.split("\n").length+1)*(z?21:18),z?400:72)}px`:B,language:"python",theme:A?"vs-dark":"vs",value:U||(z?"# Compiled PyTorch code will appear here...":""),loading:(0,v.jsx)("div",{style:{padding:"1rem",fontFamily:j,fontSize:"12px",color:"var(--ifm-color-emphasis-500)"},children:"Loading editor..."}),options:{...mn,readOnly:!0,lineNumbers:z?"on":"off",domReadOnly:!0}})}),R.analysis&&J&&!z&&(0,v.jsx)("div",{style:{display:"flex",justifyContent:"flex-end",marginTop:"0.5rem"},children:(0,v.jsx)("button",{onClick:()=>Y(!X),className:"button button--sm "+(X?"button--primary":"button--outline button--primary"),style:{fontSize:"12px"},children:X?"Hide Analysis":"Show Analysis"})})]})]}),R.analysis&&X&&J&&(0,v.jsxs)("div",{style:{marginTop:"1rem",padding:"1rem",backgroundColor:"var(--ifm-color-emphasis-100)",borderRadius:"8px",border:"1px solid var(--ifm-color-emphasis-300)"},children:[(0,v.jsx)("h4",{style:{margin:"0 0 0.75rem 0",fontSize:"1rem"},children:"Shape Analysis"}),J.neurons&&J.neurons.filter(n=>!n.is_primitive).map((n,e)=>(0,v.jsxs)("div",{style:{marginBottom:"1rem"},children:[(0,v.jsxs)("div",{style:{fontWeight:"bold",marginBottom:"0.5rem"},children:[n.name,n.params.length>0&&(0,v.jsxs)("span",{style:{fontWeight:"normal",color:"var(--ifm-color-emphasis-600)"},children:["(",n.params.map(n=>n.name).join(", "),")"]})]}),(0,v.jsxs)("div",{style:{display:"grid",gridTemplateColumns:"auto 1fr",gap:"0.25rem 1rem",fontSize:"0.9rem",paddingLeft:"1rem"},children:[n.inputs.map((n,e)=>(0,v.jsxs)(i.Fragment,{children:[(0,v.jsxs)("span",{style:{color:"var(--ifm-color-emphasis-600)"},children:["in","default"!==n.name?` ${n.name}`:"",":"]}),(0,v.jsx)("code",{className:"shape-input",style:{padding:"2px 6px",borderRadius:"3px",fontSize:"0.85rem"},children:n.shape})]},`in-${e}`)),n.outputs.map((n,e)=>(0,v.jsxs)(i.Fragment,{children:[(0,v.jsxs)("span",{style:{color:"var(--ifm-color-emphasis-600)"},children:["out","default"!==n.name?` ${n.name}`:"",":"]}),(0,v.jsx)("code",{className:"shape-output",style:{padding:"2px 6px",borderRadius:"3px",fontSize:"0.85rem"},children:n.shape})]},`out-${e}`))]}),n.connections.length>0&&(0,v.jsxs)("div",{style:{marginTop:"0.5rem",paddingLeft:"1rem"},children:[(0,v.jsx)("span",{style:{color:"var(--ifm-color-emphasis-600)",fontSize:"0.85rem"},children:"Connections:"}),(0,v.jsx)("div",{style:{fontFamily:j,fontSize:"0.8rem",color:"var(--ifm-color-emphasis-700)",marginTop:"0.25rem"},children:n.connections.map((n,e)=>(0,v.jsxs)("div",{children:[n.source," \u2192 ",n.destination]},e))})]})]},e)),J.match_expressions&&J.match_expressions.length>0&&(0,v.jsxs)("div",{style:{marginTop:"1rem"},children:[(0,v.jsx)("h5",{style:{margin:"0 0 0.5rem 0",fontSize:"0.9rem"},children:"Match Expressions"}),J.match_expressions.map((n,e)=>(0,v.jsxs)("div",{style:{marginBottom:"0.5rem",paddingLeft:"1rem"},children:[(0,v.jsxs)("div",{style:{fontSize:"0.85rem",color:"var(--ifm-color-emphasis-600)"},children:["In ",n.neuron,":"]}),n.arms.map((n,e)=>(0,v.jsxs)("div",{style:{display:"flex",alignItems:"center",gap:"0.5rem",fontSize:"0.85rem",marginLeft:"1rem",opacity:n.is_reachable?1:.5},children:[(0,v.jsxs)("code",{className:"shape-match",style:{padding:"2px 6px",borderRadius:"3px"},children:[n.pattern,n.guard&&(0,v.jsxs)("span",{style:{color:"var(--ifm-color-emphasis-600)"},children:[" where ",n.guard]})]}),!n.is_reachable&&(0,v.jsx)("span",{style:{color:"var(--ifm-color-emphasis-500)",fontSize:"0.8rem"},children:"(unreachable)"})]},e))]},e))]})]}),R.stats&&U&&(0,v.jsxs)("div",{style:{padding:"0.5rem",backgroundColor:"var(--ifm-color-emphasis-100)",borderRadius:"4px",fontSize:"12px",color:"var(--ifm-color-emphasis-700)",textAlign:"right"},children:[K.length," neuron",1!==K.length?"s":""," \u2022 ",U.split("\n").length," lines generated"]})]})}},6407(n,e,o){n.exports=o.p+"a0b10b4fb407bafb.wasm"},8453(n,e,o){o.d(e,{R:()=>a,x:()=>s});var i=o(6540);const t={},r=i.createContext(t);function a(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:a(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);