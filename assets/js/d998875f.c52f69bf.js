"use strict";(globalThis.webpackChunkneuroscript_docs=globalThis.webpackChunkneuroscript_docs||[]).push([[9951],{8478(e,n,t){t.d(n,{A:()=>o});t(6540);var i=t(2303),a=t(4848);function o({children:e,fallback:n}){return(0,i.A)()?(0,a.jsx)(a.Fragment,{children:e?.()}):n??null}},5143(e,n,t){t.r(n),t.d(n,{default:()=>p});var i=t(6540),a=t(4060),o=t(8478);const r=[{name:"Linear",level:0,category:"core",status:"implemented",description:"Dense/fully-connected layer with shape tracking. The most fundamental neural network operation.",dependencies:[],implRef:"neuroscript_runtime.primitives.linear.Linear",source:"stdlib/primitives/Linear.ns"},{name:"Bias",level:0,category:"core",status:"implemented",description:"Additive bias parameter.",dependencies:[],implRef:"neuroscript_runtime.primitives.operations.Bias"},{name:"Scale",level:0,category:"core",status:"implemented",description:"Multiplicative scaling parameter.",dependencies:[],implRef:"neuroscript_runtime.primitives.operations.Scale"},{name:"MatMul",level:0,category:"core",status:"implemented",description:"Matrix multiplication operation.",dependencies:[],implRef:"neuroscript_runtime.primitives.operations.MatMul"},{name:"Einsum",level:0,category:"core",status:"implemented",description:"Einstein summation for generalized tensor operations.",dependencies:[],implRef:"neuroscript_runtime.primitives.operations.Einsum"},{name:"ReLU",level:0,category:"activations",status:"implemented",description:"Rectified Linear Unit activation. max(0, x).",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.ReLU"},{name:"GELU",level:0,category:"activations",status:"implemented",description:"Gaussian Error Linear Unit activation. Used in transformers (BERT, GPT).",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.GELU"},{name:"SiLU",level:0,category:"activations",status:"implemented",description:"Sigmoid Linear Unit (Swish) activation. x * sigmoid(x).",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.SiLU"},{name:"Tanh",level:0,category:"activations",status:"implemented",description:"Hyperbolic tangent activation.",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.Tanh"},{name:"Sigmoid",level:0,category:"activations",status:"implemented",description:"Logistic sigmoid activation function.",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.Sigmoid"},{name:"Softmax",level:0,category:"activations",status:"implemented",description:"Softmax activation. Normalizes to probability distribution.",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.Softmax"},{name:"Mish",level:0,category:"activations",status:"implemented",description:"Mish: self-regularized non-monotonic activation.",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.Mish"},{name:"PReLU",level:0,category:"activations",status:"implemented",description:"Parametric ReLU with learnable negative slope.",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.PReLU"},{name:"ELU",level:0,category:"activations",status:"implemented",description:"Exponential Linear Unit activation.",dependencies:[],implRef:"neuroscript_runtime.primitives.activations.ELU"},{name:"LayerNorm",level:0,category:"normalizations",status:"implemented",description:"Layer normalization. Standard in transformers.",dependencies:[],implRef:"neuroscript_runtime.primitives.normalization.LayerNorm"},{name:"BatchNorm",level:0,category:"normalizations",status:"implemented",description:"Batch normalization. Standard in CNNs.",dependencies:[],implRef:"neuroscript_runtime.primitives.normalization.BatchNorm"},{name:"RMSNorm",level:0,category:"normalizations",status:"implemented",description:"Root Mean Square normalization. Efficient variant used in LLaMA.",dependencies:[],implRef:"neuroscript_runtime.primitives.normalization.RMSNorm"},{name:"GroupNorm",level:0,category:"normalizations",status:"implemented",description:"Group normalization. Works well with small batch sizes.",dependencies:[],implRef:"neuroscript_runtime.primitives.normalization.GroupNorm"},{name:"InstanceNorm",level:0,category:"normalizations",status:"implemented",description:"Instance normalization. Used in style transfer.",dependencies:[],implRef:"neuroscript_runtime.primitives.normalization.InstanceNorm"},{name:"WeightNorm",level:0,category:"normalizations",status:"planned",description:"Weight normalization. Reparameterizes weight vectors.",dependencies:[]},{name:"Dropout",level:0,category:"regularization",status:"implemented",description:"Random neuron dropout regularization with training/eval modes.",dependencies:[],implRef:"neuroscript_runtime.primitives.regularization.Dropout"},{name:"DropPath",level:0,category:"regularization",status:"implemented",description:"Stochastic depth / drop path regularization.",dependencies:[],implRef:"neuroscript_runtime.primitives.regularization.DropPath"},{name:"DropConnect",level:0,category:"regularization",status:"implemented",description:"Connection dropout (drops weights instead of activations).",dependencies:[],implRef:"neuroscript_runtime.primitives.regularization.DropConnect"},{name:"Dropblock",level:0,category:"regularization",status:"planned",description:"Structured dropout for CNNs. Drops contiguous regions.",dependencies:[]},{name:"SpecAugment",level:0,category:"regularization",status:"planned",description:"Frequency/time masking for audio data augmentation.",dependencies:[]},{name:"Conv1d",level:0,category:"convolutions",status:"implemented",description:"1D convolution for sequence data.",dependencies:[],implRef:"neuroscript_runtime.primitives.convolutions.Conv1d"},{name:"Conv2d",level:0,category:"convolutions",status:"implemented",description:"2D convolution for image data.",dependencies:[],implRef:"neuroscript_runtime.primitives.convolutions.Conv2d"},{name:"Conv3d",level:0,category:"convolutions",status:"implemented",description:"3D convolution for video/volumetric data.",dependencies:[],implRef:"neuroscript_runtime.primitives.convolutions.Conv3d"},{name:"DepthwiseConv",level:0,category:"convolutions",status:"implemented",description:"Depthwise (channel-wise) convolution.",dependencies:[],implRef:"neuroscript_runtime.primitives.convolutions.DepthwiseConv"},{name:"SeparableConv",level:0,category:"convolutions",status:"implemented",description:"Separable convolution: depthwise + pointwise.",dependencies:[],implRef:"neuroscript_runtime.primitives.convolutions.SeparableConv"},{name:"TransposedConv",level:0,category:"convolutions",status:"implemented",description:"Transposed (deconvolution) for upsampling.",dependencies:[],implRef:"neuroscript_runtime.primitives.convolutions.TransposedConv"},{name:"DilatedConv",level:0,category:"convolutions",status:"planned",description:"Atrous/dilated convolution for expanded receptive field.",dependencies:[]},{name:"MaxPool",level:0,category:"pooling",status:"implemented",description:"Max pooling layer.",dependencies:[],implRef:"neuroscript_runtime.primitives.pooling.MaxPool"},{name:"AvgPool",level:0,category:"pooling",status:"implemented",description:"Average pooling layer.",dependencies:[],implRef:"neuroscript_runtime.primitives.pooling.AvgPool"},{name:"AdaptiveAvgPool",level:0,category:"pooling",status:"implemented",description:"Adaptive average pooling with fixed output size.",dependencies:[],implRef:"neuroscript_runtime.primitives.pooling.AdaptiveAvgPool"},{name:"AdaptiveMaxPool",level:0,category:"pooling",status:"implemented",description:"Adaptive max pooling with fixed output size.",dependencies:[],implRef:"neuroscript_runtime.primitives.pooling.AdaptiveMaxPool"},{name:"GlobalAvgPool",level:0,category:"pooling",status:"implemented",description:"Global average pooling. Reduces spatial dims to 1x1.",dependencies:[],implRef:"neuroscript_runtime.primitives.pooling.GlobalAvgPool"},{name:"GlobalMaxPool",level:0,category:"pooling",status:"implemented",description:"Global max pooling. Reduces spatial dims to 1x1.",dependencies:[],implRef:"neuroscript_runtime.primitives.pooling.GlobalMaxPool"},{name:"Embedding",level:0,category:"embeddings",status:"implemented",description:"Token embedding: discrete tokens to dense vectors.",dependencies:[],implRef:"neuroscript_runtime.primitives.embeddings.Embedding"},{name:"PositionalEncoding",level:0,category:"embeddings",status:"implemented",description:"Sinusoidal positional encoding (Attention Is All You Need).",dependencies:[],implRef:"neuroscript_runtime.primitives.embeddings.PositionalEncoding"},{name:"LearnedPositionalEmbedding",level:0,category:"embeddings",status:"implemented",description:"Learned positional embeddings (BERT/GPT style).",dependencies:[],implRef:"neuroscript_runtime.primitives.embeddings.LearnedPositionalEmbedding"},{name:"RotaryEmbedding",level:0,category:"embeddings",status:"implemented",description:"Rotary Position Embedding (RoPE). Used in LLaMA, PaLM.",dependencies:[],implRef:"neuroscript_runtime.primitives.embeddings.RotaryEmbedding"},{name:"ALiBi",level:0,category:"embeddings",status:"planned",description:"Attention with Linear Biases. Length-extrapolatable positional encoding.",dependencies:[]},{name:"Identity",level:0,category:"utility",status:"implemented",description:"Identity pass-through operation. Useful for routing and skip connections.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Identity"},{name:"Fork",level:0,category:"utility",status:"implemented",description:"Split tensor into two references for multi-path processing.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Fork"},{name:"Fork3",level:0,category:"utility",status:"implemented",description:"Split tensor into three references for multi-path processing.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Fork3"},{name:"Add",level:0,category:"utility",status:"implemented",description:"Element-wise addition. Core of residual connections.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Add"},{name:"Multiply",level:0,category:"utility",status:"implemented",description:"Element-wise multiplication. Core of gating mechanisms.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Multiply"},{name:"Concat",level:0,category:"utility",status:"implemented",description:"Concatenate tensors along a dimension.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Concat"},{name:"Reshape",level:0,category:"utility",status:"implemented",description:"Reshape tensor to new shape (preserves element count).",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Reshape"},{name:"Transpose",level:0,category:"utility",status:"implemented",description:"Permute tensor dimensions.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Transpose"},{name:"Flatten",level:0,category:"utility",status:"implemented",description:"Flatten a contiguous range of dimensions.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Flatten"},{name:"Split",level:0,category:"utility",status:"implemented",description:"Split tensor into chunks along a dimension.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Split"},{name:"Slice",level:0,category:"utility",status:"implemented",description:"Slice tensor along a dimension.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Slice"},{name:"Pad",level:0,category:"utility",status:"implemented",description:"Pad tensor with a value along dimensions.",dependencies:[],implRef:"neuroscript_runtime.primitives.structural.Pad"},{name:"Crop",level:0,category:"utility",status:"planned",description:"Crop/trim tensor along dimensions.",dependencies:[]},{name:"Cast",level:0,category:"utility",status:"planned",description:"Dtype conversion (float32, float16, bfloat16, etc.).",dependencies:[]},{name:"Clone",level:0,category:"utility",status:"planned",description:"Tensor duplication.",dependencies:[]},{name:"ScaledDotProductAttention",level:0,category:"attention",status:"implemented",description:"Scaled dot-product attention. The core transformer building block.",dependencies:[],implRef:"neuroscript_runtime.primitives.attention.ScaledDotProductAttention"},{name:"MultiHeadSelfAttention",level:0,category:"attention",status:"implemented",description:"Multi-head self-attention mechanism. Complete attention with head splitting.",dependencies:[],implRef:"neuroscript_runtime.primitives.attention.MultiHeadSelfAttention"},{name:"Log",level:0,category:"debug",status:"implemented",description:"Debug logging with colored output and tensor info. Pass-through operation.",dependencies:[],implRef:"neuroscript_runtime.primitives.logging.Log"},{name:"FFN",level:1,category:"ffn",status:"implemented",description:"Feed-Forward Network / MLP. Linear (expand) -> GELU -> Linear (project). Standard in transformers.",dependencies:["Linear","GELU"],source:"stdlib/FFN.ns"},{name:"FFNWithHidden",level:1,category:"ffn",status:"implemented",description:"FFN variant with explicit input, hidden, and output dimensions.",dependencies:["Linear","GELU"],source:"stdlib/FFN.ns"},{name:"GatedFFN",level:1,category:"ffn",status:"planned",description:"Gated feed-forward with GLU-style gating mechanism.",dependencies:["Linear","Fork","Multiply","Sigmoid"]},{name:"SwiGLU",level:1,category:"ffn",status:"implemented",description:"SiLU-gated FFN. Fork -> Linear+SiLU * Linear -> Linear. Used in LLaMA.",dependencies:["Fork","Linear","SiLU","Multiply"],source:"examples/real_world/llama_rope.ns"},{name:"GeGLU",level:1,category:"ffn",status:"planned",description:"GELU-gated FFN variant.",dependencies:["Fork","Linear","GELU","Multiply"]},{name:"Expert",level:1,category:"ffn",status:"planned",description:"Single expert block for Mixture of Experts architectures.",dependencies:["Linear","GELU"]},{name:"MultiHeadAttention",level:1,category:"attention",status:"implemented",description:"Multi-head attention with parallel heads. Documented in stdlib.",dependencies:["ScaledDotProductAttention","Linear"],source:"stdlib/MultiHeadAttention.ns"},{name:"SelfAttention",level:1,category:"attention",status:"implemented",description:"Self-attention where query = key = value.",dependencies:["MultiHeadSelfAttention"]},{name:"CrossAttention",level:1,category:"attention",status:"planned",description:"Cross-attention: query from one source, key/value from another.",dependencies:["ScaledDotProductAttention","Linear"]},{name:"FlashAttention",level:1,category:"attention",status:"planned",description:"Memory-efficient attention with tiling and recomputation.",dependencies:["ScaledDotProductAttention"]},{name:"SparseAttention",level:1,category:"attention",status:"planned",description:"Local/strided/block-sparse attention patterns.",dependencies:["ScaledDotProductAttention"]},{name:"LinearAttention",level:1,category:"attention",status:"planned",description:"Kernel-based O(n) attention approximation.",dependencies:["Linear","Softmax"]},{name:"GroupedQueryAttention",level:1,category:"attention",status:"planned",description:"GQA: shared key/value heads across query groups.",dependencies:["ScaledDotProductAttention","Linear"]},{name:"MultiQueryAttention",level:1,category:"attention",status:"planned",description:"MQA: single key/value head shared across all query heads.",dependencies:["ScaledDotProductAttention","Linear"]},{name:"Residual",level:1,category:"residual",status:"planned",description:"Basic residual connection: out = x + f(x).",dependencies:["Fork","Add"]},{name:"PreNormResidual",level:1,category:"residual",status:"planned",description:"Pre-norm residual: norm -> f(x) -> add. Standard in modern transformers.",dependencies:["Fork","Add","LayerNorm"]},{name:"PostNormResidual",level:1,category:"residual",status:"planned",description:"Post-norm residual: f(x) -> norm -> add. Original transformer style.",dependencies:["Fork","Add","LayerNorm"]},{name:"HighwayConnection",level:1,category:"residual",status:"planned",description:"Gated residual with learned mixing of skip and transform paths.",dependencies:["Fork","Linear","Sigmoid","Multiply","Add"]},{name:"DenseConnection",level:1,category:"residual",status:"planned",description:"DenseNet-style: concatenate all previous layer outputs.",dependencies:["Concat"]},{name:"GLU",level:1,category:"gating",status:"planned",description:"Gated Linear Unit: element-wise product of two linear projections.",dependencies:["Linear","Fork","Sigmoid","Multiply"]},{name:"LSTMGate",level:1,category:"gating",status:"planned",description:"LSTM-style forget/input/output gates.",dependencies:["Linear","Sigmoid","Tanh","Multiply","Add"]},{name:"GRUGate",level:1,category:"gating",status:"planned",description:"GRU-style update/reset gates.",dependencies:["Linear","Sigmoid","Tanh","Multiply"]},{name:"RelativePositionBias",level:1,category:"embeddings",status:"planned",description:"T5-style learned relative position biases.",dependencies:["Embedding"]},{name:"ConditionalPositionEncoding",level:1,category:"embeddings",status:"planned",description:"Conditional position embeddings for variable-length inputs.",dependencies:["Conv2d"]},{name:"ParallelFFN",level:1,category:"ffn",status:"implemented",description:"Parallel FFN branches wrapper.",dependencies:["FFN"],source:"stdlib/MetaNeurons.ns"},{name:"SimpleTransformerBlock",level:2,category:"transformer",status:"implemented",description:"Simplified single-block transformer for testing: LayerNorm -> Linear -> Dropout.",dependencies:["LayerNorm","Linear","Dropout"],source:"stdlib/TransformerBlock.ns"},{name:"TransformerBlock",level:2,category:"transformer",status:"implemented",description:"Complete transformer block with dual residual connections: attention + FFN with pre-norm.",dependencies:["Fork","LayerNorm","MultiHeadSelfAttention","Dropout","Add","FFN"],source:"stdlib/TransformerBlock.ns"},{name:"TransformerEncoderBlock",level:2,category:"transformer",status:"planned",description:"Transformer encoder block with self-attention.",dependencies:["Fork","LayerNorm","MultiHeadSelfAttention","Dropout","Add","FFN"]},{name:"TransformerDecoderBlock",level:2,category:"transformer",status:"planned",description:"Transformer decoder block with self-attention and cross-attention.",dependencies:["Fork","LayerNorm","MultiHeadSelfAttention","CrossAttention","Dropout","Add","FFN"]},{name:"TransformerStack",level:2,category:"transformer",status:"planned",description:"N stacked transformer blocks in sequence.",dependencies:["TransformerBlock"]},{name:"PrefixLM",level:2,category:"transformer",status:"planned",description:"Prefix language model block with bidirectional prefix attention.",dependencies:["TransformerBlock"]},{name:"EncoderDecoder",level:2,category:"transformer",status:"planned",description:"Full encoder-decoder transformer architecture.",dependencies:["TransformerEncoderBlock","TransformerDecoderBlock"]},{name:"TransformerStack2",level:2,category:"transformer",status:"implemented",description:"Small 2-layer transformer stack for testing.",dependencies:["SimpleTransformerBlock"],source:"stdlib/TransformerStack.ns"},{name:"SequentialTransformer",level:2,category:"transformer",status:"implemented",description:"Simple single-layer sequential transformer.",dependencies:["SimpleTransformerBlock"],source:"stdlib/TransformerStack.ns"},{name:"ResidualBlock",level:2,category:"cnn_arch",status:"implemented",description:"ResNet basic residual block: Conv -> BN -> ReLU -> Conv -> BN + skip.",dependencies:["Conv2d","BatchNorm","ReLU","Fork","Add"],source:"examples/real_world/resnet.ns"},{name:"ResNetStem",level:2,category:"cnn_arch",status:"implemented",description:"ResNet initial stem: 7x7 Conv -> BN -> ReLU -> MaxPool.",dependencies:["Conv2d","BatchNorm","ReLU","MaxPool"],source:"examples/real_world/resnet.ns"},{name:"ConvBlock",level:2,category:"cnn_arch",status:"implemented",description:"Configurable Conv -> BN -> ReLU -> optional Pool block.",dependencies:["Conv2d","BatchNorm","ReLU","MaxPool","Identity"],source:"examples/real_world/cnn_demo_2.ns"},{name:"ResNeXtBlock",level:2,category:"cnn_arch",status:"planned",description:"ResNeXt block with grouped convolutions.",dependencies:["Conv2d","BatchNorm","ReLU","Fork","Add"]},{name:"DenseBlock",level:2,category:"cnn_arch",status:"planned",description:"DenseNet densely connected block.",dependencies:["Conv2d","BatchNorm","ReLU","Concat"]},{name:"InceptionBlock",level:2,category:"cnn_arch",status:"planned",description:"Inception module with multi-scale parallel convolutions.",dependencies:["Conv2d","MaxPool","Fork3","Concat","ReLU"]},{name:"SEBlock",level:2,category:"cnn_arch",status:"planned",description:"Squeeze-and-Excitation block for channel attention.",dependencies:["GlobalAvgPool","Linear","ReLU","Sigmoid","Multiply"]},{name:"MBConvBlock",level:2,category:"cnn_arch",status:"planned",description:"Mobile Inverted Bottleneck (MobileNetV2, EfficientNet).",dependencies:["Conv2d","DepthwiseConv","BatchNorm","SiLU","SEBlock"]},{name:"FusedMBConv",level:2,category:"cnn_arch",status:"planned",description:"Fused mobile convolution block (EfficientNetV2).",dependencies:["Conv2d","BatchNorm","SiLU","SEBlock"]},{name:"BottleneckBlock",level:2,category:"cnn_arch",status:"planned",description:"Bottleneck residual block: 1x1 -> 3x3 -> 1x1 convolution.",dependencies:["Conv2d","BatchNorm","ReLU","Fork","Add"]},{name:"LSTM",level:2,category:"recurrent",status:"planned",description:"Long Short-Term Memory recurrent unit.",dependencies:["Linear","Sigmoid","Tanh","Multiply","Add"]},{name:"GRU",level:2,category:"recurrent",status:"planned",description:"Gated Recurrent Unit.",dependencies:["Linear","Sigmoid","Tanh","Multiply"]},{name:"BiLSTM",level:2,category:"recurrent",status:"planned",description:"Bidirectional LSTM.",dependencies:["LSTM","Concat"]},{name:"BiGRU",level:2,category:"recurrent",status:"planned",description:"Bidirectional GRU.",dependencies:["GRU","Concat"]},{name:"MambaBlock",level:2,category:"recurrent",status:"planned",description:"Selective state space model block (Mamba architecture).",dependencies:["Linear","Conv1d","SiLU","Multiply"]},{name:"S4Block",level:2,category:"recurrent",status:"planned",description:"Structured State Space Sequence model block.",dependencies:["Linear","Conv1d"]},{name:"H3Block",level:2,category:"recurrent",status:"planned",description:"Hybrid H3 layer combining SSM with attention.",dependencies:["Linear","Conv1d","ScaledDotProductAttention"]},{name:"RetNetBlock",level:2,category:"recurrent",status:"planned",description:"Retentive Network block with multi-scale retention.",dependencies:["Linear","GroupNorm"]},{name:"RWKVBlock",level:2,category:"recurrent",status:"planned",description:"Receptance Weighted Key Value block.",dependencies:["Linear","LayerNorm"]},{name:"ViTEncoderBlock",level:2,category:"vision",status:"implemented",description:"Vision Transformer encoder block with dual residual attention + FFN.",dependencies:["Fork","LayerNorm","MultiHeadSelfAttention","Add","Linear","GELU"],source:"examples/real_world/vision_transformer.ns"},{name:"PatchEmbedding",level:2,category:"vision",status:"implemented",description:"Image to patch sequence embedding for ViT.",dependencies:["Conv2d"],source:"examples/real_world/vision_transformer.ns"},{name:"ConvNeXtBlock",level:2,category:"vision",status:"planned",description:"Modernized ResNet block with depthwise conv and inverted bottleneck.",dependencies:["DepthwiseConv","LayerNorm","Linear","GELU"]},{name:"SwinBlock",level:2,category:"vision",status:"planned",description:"Shifted window attention block for hierarchical vision.",dependencies:["LayerNorm","MultiHeadSelfAttention","Linear","GELU","Fork","Add"]},{name:"ViTBlock",level:2,category:"vision",status:"planned",description:"Vision Transformer block (generic).",dependencies:["LayerNorm","MultiHeadSelfAttention","FFN","Fork","Add"]},{name:"PatchMerging",level:2,category:"vision",status:"planned",description:"Hierarchical patch reduction for Swin-style models.",dependencies:["Linear","LayerNorm"]},{name:"FPN",level:2,category:"vision",status:"planned",description:"Feature Pyramid Network for multi-scale feature fusion.",dependencies:["Conv2d","Linear","Add"]},{name:"UNetBlock",level:2,category:"vision",status:"planned",description:"U-Net encoder/decoder block with skip connections.",dependencies:["Conv2d","BatchNorm","ReLU","TransposedConv","Concat"]},{name:"ResUNetBlock",level:2,category:"vision",status:"planned",description:"Residual U-Net block combining residual connections with U-Net.",dependencies:["Conv2d","BatchNorm","ReLU","Fork","Add","TransposedConv"]},{name:"VAEEncoder",level:2,category:"generative",status:"planned",description:"Variational Autoencoder encoder with mean/variance outputs.",dependencies:["Conv2d","Linear","ReLU","Fork"]},{name:"VAEDecoder",level:2,category:"generative",status:"planned",description:"VAE decoder with transposed convolutions.",dependencies:["Linear","TransposedConv","ReLU"]},{name:"GANGenerator",level:2,category:"generative",status:"planned",description:"GAN generator block.",dependencies:["Linear","TransposedConv","BatchNorm","ReLU"]},{name:"GANDiscriminator",level:2,category:"generative",status:"planned",description:"GAN discriminator block.",dependencies:["Conv2d","BatchNorm","ReLU","Linear"]},{name:"DiffusionUNet",level:2,category:"generative",status:"planned",description:"U-Net architecture adapted for diffusion models.",dependencies:["UNetBlock","MultiHeadSelfAttention","GroupNorm"]},{name:"DiffusionTimestepEmbed",level:2,category:"generative",status:"planned",description:"Timestep embedding/conditioning for diffusion models.",dependencies:["Linear","SiLU"]},{name:"NoiseScheduler",level:2,category:"generative",status:"planned",description:"Diffusion noise scheduling utility.",dependencies:[]},{name:"GCNLayer",level:2,category:"graph_nn",status:"planned",description:"Graph Convolutional Network layer.",dependencies:["Linear","ReLU"]},{name:"GATLayer",level:2,category:"graph_nn",status:"planned",description:"Graph Attention Network layer.",dependencies:["Linear","Softmax"]},{name:"GraphSAGE",level:2,category:"graph_nn",status:"planned",description:"Graph Sample and Aggregate layer.",dependencies:["Linear","ReLU"]},{name:"GINLayer",level:2,category:"graph_nn",status:"planned",description:"Graph Isomorphism Network layer.",dependencies:["Linear","ReLU","BatchNorm"]},{name:"MessagePassing",level:2,category:"graph_nn",status:"planned",description:"Generic message passing layer for GNNs.",dependencies:["Linear"]},{name:"EdgeConv",level:2,category:"graph_nn",status:"planned",description:"Edge convolution for point cloud processing.",dependencies:["Linear","ReLU"]},{name:"GlobalPooling",level:2,category:"graph_nn",status:"planned",description:"Graph-level pooling for readout.",dependencies:["GlobalAvgPool"]},{name:"MelSpectrogram",level:2,category:"audio",status:"planned",description:"Mel-scale spectrogram computation.",dependencies:[]},{name:"MFCC",level:2,category:"audio",status:"planned",description:"Mel-Frequency Cepstral Coefficients extraction.",dependencies:["MelSpectrogram"]},{name:"WaveNetBlock",level:2,category:"audio",status:"planned",description:"Dilated causal convolution block for WaveNet.",dependencies:["Conv1d","Tanh","Sigmoid","Multiply","Add"]},{name:"Conformer",level:2,category:"audio",status:"planned",description:"Convolution-augmented transformer for speech.",dependencies:["MultiHeadSelfAttention","Conv1d","FFN","LayerNorm","Fork","Add"]},{name:"WhisperEncoder",level:2,category:"audio",status:"planned",description:"Whisper speech encoder block.",dependencies:["MultiHeadSelfAttention","FFN","LayerNorm"]},{name:"WhisperDecoder",level:2,category:"audio",status:"planned",description:"Whisper speech decoder block with cross-attention.",dependencies:["MultiHeadSelfAttention","CrossAttention","FFN","LayerNorm"]},{name:"AdaptiveLayerNorm",level:2,category:"normalizations",status:"planned",description:"Adaptive Layer Normalization (e.g., for diffusion conditioning).",dependencies:["LayerNorm","Linear"]},{name:"ConditionalLayerNorm",level:2,category:"normalizations",status:"planned",description:"Class-conditional normalization.",dependencies:["LayerNorm","Linear"]},{name:"SpectralNorm",level:2,category:"normalizations",status:"planned",description:"Spectral normalization for GANs.",dependencies:[]},{name:"LlamaRotaryAttention",level:2,category:"attention",status:"implemented",description:"LLaMA-style attention with Rotary Position Embeddings.",dependencies:["Linear","RotaryEmbedding"],source:"examples/real_world/llama_rope.ns"},{name:"LlamaBlock",level:2,category:"transformer",status:"implemented",description:"LLaMA transformer block: RMSNorm + RoPE attention + SwiGLU FFN with residuals.",dependencies:["Fork","RMSNorm","LlamaRotaryAttention","Add","SwiGLU"],source:"examples/real_world/llama_rope.ns"},{name:"GPTTransformerBlock",level:2,category:"transformer",status:"implemented",description:"GPT-2 style transformer block: LayerNorm -> Attention -> FFN.",dependencies:["LayerNorm","MultiHeadSelfAttention","FFN"],source:"examples/real_world/gpt2_small.ns"},{name:"GPT2Small",level:3,category:"models_lang",status:"implemented",description:"GPT-2 Small: Embedding + Positional + TransformerBlock + LM head.",dependencies:["Embedding","PositionalEncoding","GPTTransformerBlock","LayerNorm","Linear"],source:"examples/real_world/gpt2_small.ns"},{name:"VisionTransformer",level:3,category:"models_vision",status:"implemented",description:"Vision Transformer (ViT): PatchEmbed + PositionalEmbed + Encoder stack + classifier.",dependencies:["PatchEmbedding","LearnedPositionalEmbedding","ViTEncoderBlock","LayerNorm","Slice","Linear"],source:"examples/real_world/vision_transformer.ns"},{name:"ResNet18",level:3,category:"models_vision",status:"implemented",description:"ResNet-18: Stem + 4 stages of residual blocks + classification head.",dependencies:["ResNetStem","ResidualBlock","GlobalAvgPool","Linear"],source:"examples/real_world/resnet.ns"},{name:"MiniLlama",level:3,category:"models_lang",status:"implemented",description:"Minimal LLaMA-style model: Embedding + LlamaBlock + RMSNorm + LM head.",dependencies:["Embedding","LlamaBlock","RMSNorm","Linear"],source:"examples/real_world/llama_rope.ns"},{name:"CNN",level:3,category:"models_vision",status:"implemented",description:"Simple CNN for image classification: Conv stages + GlobalAvgPool + Linear head.",dependencies:["Conv2d","BatchNorm","ReLU","MaxPool","GlobalAvgPool","Flatten","Linear"],source:"examples/real_world/cnn_demo.ns"},{name:"GPT",level:3,category:"models_lang",status:"planned",description:"Autoregressive GPT language model (configurable size).",dependencies:["Embedding","LearnedPositionalEmbedding","TransformerBlock","LayerNorm","Linear"]},{name:"BERT",level:3,category:"models_lang",status:"planned",description:"Bidirectional Encoder Representations from Transformers.",dependencies:["Embedding","LearnedPositionalEmbedding","TransformerEncoderBlock","LayerNorm","Linear"]},{name:"T5",level:3,category:"models_lang",status:"planned",description:"Text-to-Text Transfer Transformer (encoder-decoder).",dependencies:["Embedding","EncoderDecoder","Linear"]},{name:"LLaMA",level:3,category:"models_lang",status:"planned",description:"LLaMA architecture (configurable variant).",dependencies:["Embedding","LlamaBlock","RMSNorm","Linear"]},{name:"Mistral",level:3,category:"models_lang",status:"planned",description:"Mistral model with sliding window attention.",dependencies:["Embedding","TransformerBlock","RMSNorm","Linear"]},{name:"Mamba",level:3,category:"models_lang",status:"planned",description:"Full Mamba model based on selective state spaces.",dependencies:["Embedding","MambaBlock","RMSNorm","Linear"]},{name:"RWKV",level:3,category:"models_lang",status:"planned",description:"Full RWKV model.",dependencies:["Embedding","RWKVBlock","LayerNorm","Linear"]},{name:"Pythia",level:3,category:"models_lang",status:"planned",description:"Pythia model family.",dependencies:["Embedding","TransformerBlock","LayerNorm","Linear"]},{name:"Falcon",level:3,category:"models_lang",status:"planned",description:"Falcon language model.",dependencies:["Embedding","TransformerBlock","LayerNorm","Linear"]},{name:"Phi",level:3,category:"models_lang",status:"planned",description:"Phi small language models.",dependencies:["Embedding","TransformerBlock","LayerNorm","Linear"]},{name:"ResNet",level:3,category:"models_vision",status:"planned",description:"Full ResNet (18/34/50/101/152 variants).",dependencies:["ResNetStem","ResidualBlock","BottleneckBlock","GlobalAvgPool","Linear"]},{name:"EfficientNet",level:3,category:"models_vision",status:"planned",description:"EfficientNet (B0-B7) with compound scaling.",dependencies:["MBConvBlock","FusedMBConv","GlobalAvgPool","Linear"]},{name:"ViT",level:3,category:"models_vision",status:"planned",description:"Vision Transformer (configurable).",dependencies:["PatchEmbedding","ViTBlock","LayerNorm","Linear"]},{name:"Swin",level:3,category:"models_vision",status:"planned",description:"Swin Transformer with shifted windows.",dependencies:["PatchEmbedding","SwinBlock","PatchMerging","LayerNorm","Linear"]},{name:"ConvNeXt",level:3,category:"models_vision",status:"planned",description:"ConvNeXt architecture.",dependencies:["ConvNeXtBlock","LayerNorm","Linear","GlobalAvgPool"]},{name:"CLIPVisualEncoder",level:3,category:"models_vision",status:"planned",description:"CLIP image encoder.",dependencies:["PatchEmbedding","ViTBlock","LayerNorm","Linear"]},{name:"DINOv2",level:3,category:"models_vision",status:"planned",description:"Self-supervised vision model.",dependencies:["PatchEmbedding","ViTBlock","LayerNorm"]},{name:"CLIP",level:3,category:"models_multimodal",status:"planned",description:"Contrastive Language-Image Pre-training.",dependencies:["CLIPVisualEncoder","TransformerBlock","Embedding","Linear"]},{name:"BLIP",level:3,category:"models_multimodal",status:"planned",description:"Bootstrapped Language-Image Pre-training.",dependencies:["ViTBlock","TransformerBlock","Embedding","Linear"]},{name:"Flamingo",level:3,category:"models_multimodal",status:"planned",description:"Visual Language Model with gated cross-attention.",dependencies:["ViTBlock","TransformerBlock","CrossAttention","Linear"]},{name:"LLaVA",level:3,category:"models_multimodal",status:"planned",description:"Large Language and Vision Assistant.",dependencies:["CLIPVisualEncoder","TransformerBlock","Linear"]},{name:"CoCa",level:3,category:"models_multimodal",status:"planned",description:"Contrastive Captioner combining contrastive and generative objectives.",dependencies:["ViTBlock","TransformerBlock","Linear"]},{name:"StableDiffusionUNet",level:3,category:"models_gen",status:"planned",description:"Diffusion model U-Net for Stable Diffusion.",dependencies:["DiffusionUNet","DiffusionTimestepEmbed","CrossAttention"]},{name:"VAEKL",level:3,category:"models_gen",status:"planned",description:"Kullback-Leibler VAE for latent space modeling.",dependencies:["VAEEncoder","VAEDecoder"]},{name:"VQVAE",level:3,category:"models_gen",status:"planned",description:"Vector Quantized VAE with codebook.",dependencies:["VAEEncoder","VAEDecoder","Embedding"]},{name:"StyleGAN",level:3,category:"models_gen",status:"planned",description:"StyleGAN generator architecture.",dependencies:["GANGenerator","Linear","Conv2d"]},{name:"ControlNet",level:3,category:"models_gen",status:"planned",description:"Conditional control for diffusion models.",dependencies:["DiffusionUNet","Conv2d","Linear"]},{name:"Whisper",level:3,category:"models_audio",status:"planned",description:"OpenAI Whisper speech recognition model.",dependencies:["WhisperEncoder","WhisperDecoder","Embedding","Linear"]},{name:"Wav2Vec2",level:3,category:"models_audio",status:"planned",description:"Speech representation learning model.",dependencies:["Conv1d","TransformerBlock","LayerNorm"]},{name:"HuBERT",level:3,category:"models_audio",status:"planned",description:"Hidden Unit BERT for speech.",dependencies:["Conv1d","TransformerBlock","LayerNorm"]},{name:"MusicGen",level:3,category:"models_audio",status:"planned",description:"Music generation model.",dependencies:["Embedding","TransformerBlock","Linear"]},{name:"AudioLDM",level:3,category:"models_audio",status:"planned",description:"Audio Latent Diffusion Model.",dependencies:["DiffusionUNet","MelSpectrogram","VAEKL"]},{name:"AlphaFoldEvoformer",level:3,category:"models_specialized",status:"planned",description:"AlphaFold Evoformer for protein structure prediction.",dependencies:["MultiHeadSelfAttention","FFN","LayerNorm","Linear"]},{name:"ProteinMPNN",level:3,category:"models_specialized",status:"planned",description:"Protein design with message passing.",dependencies:["MessagePassing","Linear","ReLU"]},{name:"ESMFold",level:3,category:"models_specialized",status:"planned",description:"Evolutionary Scale Modeling for proteins.",dependencies:["TransformerBlock","Linear","LayerNorm"]},{name:"MolFormer",level:3,category:"models_specialized",status:"planned",description:"Molecular transformer for chemistry.",dependencies:["TransformerBlock","Embedding","Linear"]},{name:"Switch",level:4,category:"meta_routing",status:"planned",description:"Conditional routing (if-else) between neuron paths.",dependencies:["Identity"]},{name:"Router",level:4,category:"meta_routing",status:"planned",description:"Learned routing for multi-path processing.",dependencies:["Linear","Softmax"]},{name:"MixtureOfExperts",level:4,category:"meta_routing",status:"planned",description:"Sparse expert routing (MoE). Route tokens to top-k experts.",dependencies:["Router","Expert","Add"]},{name:"TopKRouter",level:4,category:"meta_routing",status:"planned",description:"Route to top-k experts based on gating scores.",dependencies:["Linear","Softmax"]},{name:"LoadBalancedRouter",level:4,category:"meta_routing",status:"planned",description:"Expert load balancing for MoE training.",dependencies:["Linear","Softmax"]},{name:"ConditionalCompute",level:4,category:"meta_routing",status:"planned",description:"Dynamic depth with early exit.",dependencies:["Linear","Sigmoid"]},{name:"Sequential",level:4,category:"meta_composition",status:"planned",description:"Linear chain of neurons applied in sequence.",dependencies:[]},{name:"Parallel",level:4,category:"meta_composition",status:"planned",description:"Multiple neurons applied in parallel with result aggregation.",dependencies:["Fork","Concat"]},{name:"ResidualWrapper",level:4,category:"meta_composition",status:"planned",description:"Skip connection wrapper for any neuron.",dependencies:["Fork","Add"]},{name:"Ensemble",level:4,category:"meta_composition",status:"planned",description:"Average/vote over multiple model outputs.",dependencies:["Fork","Add"]},{name:"LoRA",level:4,category:"meta_composition",status:"planned",description:"Low-Rank Adaptation wrapper for parameter-efficient fine-tuning.",dependencies:["Linear","Add"]},{name:"Adapter",level:4,category:"meta_composition",status:"planned",description:"Adapter layer wrapper for transfer learning.",dependencies:["Linear","ReLU","Add"]},{name:"PrefixTuning",level:4,category:"meta_composition",status:"planned",description:"Prefix tuning wrapper for prompt-based fine-tuning.",dependencies:["Embedding","Concat"]},{name:"RecurrentBlock",level:4,category:"meta_recursive",status:"planned",description:"Apply a block N times in sequence.",dependencies:[]},{name:"DynamicDepth",level:4,category:"meta_recursive",status:"planned",description:"Variable-depth network with learned exit.",dependencies:["Linear","Sigmoid"]},{name:"NeuralODE",level:4,category:"meta_recursive",status:"planned",description:"Neural Ordinary Differential Equations.",dependencies:["Linear"]},{name:"UniversalTransformer",level:4,category:"meta_recursive",status:"planned",description:"Adaptive Computation Time transformer.",dependencies:["TransformerBlock","Sigmoid"]},{name:"Pyramid",level:4,category:"meta_multiscale",status:"planned",description:"Multi-scale pyramid processing.",dependencies:["AvgPool","Linear"]},{name:"Cascade",level:4,category:"meta_multiscale",status:"planned",description:"Coarse-to-fine cascaded processing.",dependencies:["Linear"]},{name:"HierarchicalMerge",level:4,category:"meta_multiscale",status:"planned",description:"Merge features across multiple scales.",dependencies:["Linear","Add","Concat"]},{name:"Checkpoint",level:4,category:"meta_utilities",status:"planned",description:"Gradient checkpointing to save memory during training.",dependencies:[]},{name:"Quantize",level:4,category:"meta_utilities",status:"planned",description:"Quantization to INT8/INT4 for inference efficiency.",dependencies:[]},{name:"Prune",level:4,category:"meta_utilities",status:"planned",description:"Structured/unstructured pruning for model compression.",dependencies:[]},{name:"DistillationHead",level:4,category:"meta_utilities",status:"planned",description:"Knowledge distillation output head.",dependencies:["Linear"]},{name:"EMA",level:4,category:"meta_utilities",status:"planned",description:"Exponential Moving Average of model parameters.",dependencies:[]},{name:"PolicyHead",level:4,category:"rl",status:"planned",description:"Policy network head for RL agents.",dependencies:["Linear","Softmax"]},{name:"ValueHead",level:4,category:"rl",status:"planned",description:"Value network head for RL agents.",dependencies:["Linear"]},{name:"ActorCritic",level:4,category:"rl",status:"planned",description:"Actor-Critic architecture combining policy and value heads.",dependencies:["PolicyHead","ValueHead","Fork"]},{name:"DQN",level:4,category:"rl",status:"planned",description:"Deep Q-Network architecture.",dependencies:["Linear","ReLU"]},{name:"PPONetwork",level:4,category:"rl",status:"planned",description:"PPO architecture with shared backbone.",dependencies:["Linear","ReLU","PolicyHead","ValueHead"]},{name:"HuggingFaceModel",level:5,category:"external",status:"planned",description:"Import any model from HuggingFace Hub as a neuron.",dependencies:[]},{name:"TorchHubModel",level:5,category:"external",status:"planned",description:"Import PyTorch Hub models as neurons.",dependencies:[]},{name:"ONNXModel",level:5,category:"external",status:"planned",description:"Import ONNX models as neurons.",dependencies:[]},{name:"TensorFlowModel",level:5,category:"external",status:"planned",description:"Import TensorFlow SavedModel as a neuron.",dependencies:[]},{name:"JAXModel",level:5,category:"external",status:"planned",description:"Import JAX/Flax models as neurons.",dependencies:[]},{name:"SafetensorsModel",level:5,category:"external",status:"planned",description:"Import models from safetensors format.",dependencies:[]},{name:"DimensionAdapter",level:4,category:"adapters",status:"planned",description:"Change feature dimensions between incompatible neurons.",dependencies:["Linear"]},{name:"SequenceLengthAdapter",level:4,category:"adapters",status:"planned",description:"Resample sequence length for compatibility.",dependencies:["Linear"]},{name:"BatchAdapter",level:4,category:"adapters",status:"planned",description:"Handle batch size changes.",dependencies:["Reshape"]},{name:"ChannelAdapter",level:4,category:"adapters",status:"planned",description:"Adapt channel count between layers.",dependencies:["Conv2d"]},{name:"SpatialAdapter",level:4,category:"adapters",status:"planned",description:"Resize spatial dimensions.",dependencies:["AdaptiveAvgPool"]},{name:"DTypeAdapter",level:4,category:"adapters",status:"planned",description:"Convert between float32/float16/bfloat16.",dependencies:["Cast"]},{name:"QuantizationAdapter",level:4,category:"adapters",status:"planned",description:"Convert between float and int8/int4.",dependencies:["Quantize"]},{name:"DeviceAdapter",level:4,category:"adapters",status:"planned",description:"Move tensors between CPU/GPU/TPU.",dependencies:[]},{name:"ImageToPatches",level:4,category:"adapters",status:"planned",description:"Convert image to patch sequence for ViT input.",dependencies:["Conv2d","Reshape","Transpose"]},{name:"PatchesToImage",level:4,category:"adapters",status:"planned",description:"Reconstruct image from patch sequence.",dependencies:["Reshape","Transpose"]},{name:"TokensToEmbedding",level:4,category:"adapters",status:"planned",description:"Convert discrete tokens to continuous embeddings.",dependencies:["Embedding"]},{name:"EmbeddingToLogits",level:4,category:"adapters",status:"planned",description:"Convert continuous embeddings to discrete logits.",dependencies:["Linear"]},{name:"AudioToSpectrogram",level:4,category:"adapters",status:"planned",description:"Convert waveform to frequency representation.",dependencies:["MelSpectrogram"]},{name:"SpectrogramToAudio",level:4,category:"adapters",status:"planned",description:"Reconstruct waveform from spectrogram.",dependencies:[]},{name:"Projection",level:4,category:"adapters",status:"planned",description:"Arbitrary shape transformation via learned projection.",dependencies:["Linear"]},{name:"Upsampler",level:4,category:"adapters",status:"planned",description:"Increase spatial resolution.",dependencies:["TransposedConv"]},{name:"Downsampler",level:4,category:"adapters",status:"planned",description:"Decrease spatial resolution.",dependencies:["Conv2d"]},{name:"Interpolate",level:4,category:"adapters",status:"planned",description:"Smooth resampling via interpolation.",dependencies:[]},{name:"BridgeBlock",level:4,category:"adapters",status:"planned",description:"Generic A-to-B converter block.",dependencies:["Linear","LayerNorm"]},{name:"MemoryBank",level:4,category:"exotic",status:"planned",description:"External memory for Neural Turing Machines / DNC.",dependencies:["Linear","Softmax"]},{name:"KNNMemory",level:4,category:"exotic",status:"planned",description:"k-Nearest Neighbor lookup memory.",dependencies:["Linear"]},{name:"VectorDatabase",level:4,category:"exotic",status:"planned",description:"Embedding search via vector database.",dependencies:["Linear"]},{name:"ContextWindow",level:4,category:"exotic",status:"planned",description:"Sliding window buffer for context management.",dependencies:["Slice","Concat"]},{name:"LogicGate",level:4,category:"exotic",status:"planned",description:"Differentiable logic gate.",dependencies:["Sigmoid"]},{name:"ProgramSynthesis",level:4,category:"exotic",status:"planned",description:"Neural program synthesis module.",dependencies:["Linear","LSTM"]},{name:"TreeLSTM",level:4,category:"exotic",status:"planned",description:"Tree-structured LSTM for hierarchical data.",dependencies:["LSTM"]},{name:"GraphGrammar",level:4,category:"exotic",status:"planned",description:"Graph generation rules module.",dependencies:["GCNLayer","Linear"]},{name:"RotationEquivariant",level:4,category:"exotic",status:"planned",description:"Rotation equivariant layer (E(n) equivariant).",dependencies:["Linear"]},{name:"TranslationInvariant",level:4,category:"exotic",status:"planned",description:"Translation invariant layer.",dependencies:["Conv2d","GlobalAvgPool"]},{name:"PermutationInvariant",level:4,category:"exotic",status:"planned",description:"Permutation invariant layer (Set Transformer).",dependencies:["MultiHeadSelfAttention","GlobalAvgPool"]},{name:"ScaleEquivariant",level:4,category:"exotic",status:"planned",description:"Scale equivariant layer.",dependencies:["Conv2d"]},{name:"EnergyFunction",level:4,category:"exotic",status:"planned",description:"Energy-based model layer.",dependencies:["Linear"]},{name:"Hopfield",level:4,category:"exotic",status:"planned",description:"Modern Hopfield network layer.",dependencies:["Linear","Softmax"]},{name:"Boltzmann",level:4,category:"exotic",status:"planned",description:"Restricted Boltzmann Machine.",dependencies:["Linear","Sigmoid"]},{name:"KolmogorovArnold",level:4,category:"exotic",status:"planned",description:"KAN layers based on Kolmogorov-Arnold representation.",dependencies:["Linear"]},{name:"LiquidNeuron",level:4,category:"exotic",status:"planned",description:"Liquid time-constant networks.",dependencies:["Linear","Tanh"]},{name:"HyperNetwork",level:4,category:"exotic",status:"planned",description:"Networks that generate network weights.",dependencies:["Linear"]},{name:"MetaLearner",level:4,category:"exotic",status:"planned",description:"MAML, Reptile, and other meta-learning approaches.",dependencies:["Linear"]},{name:"NeuralTangentKernel",level:4,category:"exotic",status:"planned",description:"NTK-based computation layer.",dependencies:["Linear"]}];function s(e,n){let t=null,i=new Set([0,1,2,3,4,5]),a="",o="all",r="all";const s=new Map,l=new Map,d=new Set;n.forEach(e=>{s.set(e.name,e),d.add(e.category),l.has(e.name)||l.set(e.name,[])}),n.forEach(e=>{(e.dependencies||[]).forEach(n=>{l.has(n)||l.set(n,[]),l.get(n).push(e.name)})}),function(){const n=e.querySelector("#ng-categoryFilter");[...d].sort().forEach(e=>{const t=document.createElement("option");t.value=e,t.textContent=e.replace(/_/g," "),n.appendChild(t)})}();const c=["L0: Primitives","L1: Composites","L2: Architectural","L3: Models","L4: Meta","L5: External"];function p(){const l=e.querySelector("#ng-listPanel"),d=n.filter(e=>{if(!i.has(e.level))return!1;if("all"!==o&&e.status!==o)return!1;if("all"!==r&&e.category!==r)return!1;if(a){const n=a.toLowerCase();return e.name.toLowerCase().includes(n)||e.description.toLowerCase().includes(n)}return!0}),p=new Map;d.forEach(e=>{p.has(e.level)||p.set(e.level,[]),p.get(e.level).push(e)});let u="";for(let e=0;e<=5;e++){const n=p.get(e);n&&0!==n.length&&(n.sort((e,n)=>e.name.localeCompare(n.name)),u+=`<div class="ng-level-group-header" style="color:var(--ng-level-${e})">${c[e]} (${n.length})</div>`,n.forEach(e=>{const n=t&&t.name===e.name?" selected":"";u+=`<div class="ng-neuron-item${n}" data-name="${e.name}">\n          <span class="ng-status-dot ${e.status}"></span>\n          <span class="ng-name">${e.name}</span>\n          <span class="ng-cat">${e.category}</span>\n        </div>`}))}l.innerHTML=u;const g=d.length,v=d.filter(e=>"implemented"===e.status).length;e.querySelector("#ng-stats").textContent=`${g} of ${n.length} neurons, ${v} implemented`,l.querySelectorAll(".ng-neuron-item").forEach(e=>{e.addEventListener("click",()=>{const n=s.get(e.dataset.name);n&&m(n)})})}function m(e){t=e,window.location.hash=e.name,p(),u(e)}function u(n){const t=e.querySelector("#ng-detailPanel"),i=n.dependencies||[],a=l.get(n.name)||[];let o="";o+=`<div class="ng-detail-header">\n      <h2 style="color:var(--ng-level-${n.level})">${n.name}</h2>\n      <span class="ng-detail-badge ${n.status}">${n.status}</span>\n    </div>`,o+=`<div class="ng-detail-meta">\n      <span><span class="ng-label">Level:</span> ${n.level} (${c[n.level].split(": ")[1]})</span>\n      <span><span class="ng-label">Category:</span> ${n.category.replace(/_/g," ")}</span>\n      ${n.implRef?`<span><span class="ng-label">Impl:</span> ${n.implRef}</span>`:""}\n      ${n.source?`<span><span class="ng-label">Source:</span> ${n.source}</span>`:""}\n    </div>`,o+=`<div class="ng-detail-desc">${n.description}</div>`,o+=`<div class="ng-dep-section">\n      <h3><span class="ng-arrow up">&uarr;</span> Requires (${i.length})</h3>`,i.length>0?(o+='<div class="ng-dep-list">',i.forEach(e=>{const n=s.get(e),t=n?n.status:"planned";o+=`<span class="ng-dep-chip ${t}" data-name="${e}">${e}</span>`}),o+="</div>"):o+='<span class="ng-dep-none">No dependencies (primitive or self-contained)</span>',o+="</div>",o+=`<div class="ng-dep-section">\n      <h3><span class="ng-arrow down">&darr;</span> Required By (${a.length})</h3>`,a.length>0?(o+='<div class="ng-dep-list">',[...a].sort().forEach(e=>{const n=s.get(e),t=n?n.status:"planned";o+=`<span class="ng-dep-chip ${t}" data-name="${e}">${e}</span>`}),o+="</div>"):o+='<span class="ng-dep-none">No neurons depend on this yet</span>',o+="</div>",o+='<div class="ng-graph-container">\n      <h3>Dependency Graph</h3>\n      <div id="ng-graphSvg"></div>\n    </div>',t.innerHTML=o,t.querySelectorAll(".ng-dep-chip").forEach(e=>{e.addEventListener("click",()=>{const n=s.get(e.dataset.name);n&&m(n)})}),function(n,t,i){const a=e.querySelector("#ng-graphSvg"),o=140,r=30,l=30,d=14,c=100,p=t.map(e=>s.get(e)||{name:e,status:"planned",level:0}),u=i.map(e=>s.get(e)||{name:e,status:"planned",level:0}),g=Math.max(p.length,u.length,1),v=Math.max(g*(r+d)+d+40,r+2*d+40),y=l,f=l+o+c,h=l+2*(o+c);function L(e,n){return(v-(n*(r+d)-d))/2+e*(r+d)}const b=(v-r)/2;function k(e){return`var(--ng-level-${e.level||0})`}function N(e){return"implemented"===e.status?"var(--ng-implemented)":"var(--ng-planned)"}let S=`<svg viewBox="0 0 ${3*o+2*c+2*l} ${v}" xmlns="http://www.w3.org/2000/svg" style="min-height:${Math.min(v,500)}px">`;function A(e,n,t,i){const a=i?"var(--ng-bg-hover)":"var(--ng-bg-card)",s=i?"var(--ng-node-selected)":"var(--ng-border)",l=i?2:1,d=6,c=N(t),p=i?"var(--ng-text)":k(t),m=t.name.length>16?t.name.slice(0,15)+"\u2026":t.name;S+=`<g class="ng-graph-node" data-name="${t.name}" style="cursor:pointer">`,S+=`<rect x="${e}" y="${n}" width="${o}" height="${r}" rx="${d}" fill="${a}" stroke="${s}" stroke-width="${l}"/>`,S+=`<circle cx="${e+10}" cy="${n+r/2}" r="4" fill="${c}"/>`,S+=`<text x="${e+20}" y="${n+r/2+4}" fill="${p}" font-size="11" font-weight="${i?700:500}">${m}</text>`,S+="</g>"}p.forEach((e,n)=>{const t=y+o,i=L(n,p.length)+r/2,a=b+r/2,s=(t+f)/2;S+=`<path d="M${t},${i} C${s},${i} ${s},${a} ${f},${a}" fill="none" stroke="var(--ng-edge-dep)" stroke-width="1.5" opacity="0.5"/>`}),u.forEach((e,n)=>{const t=f+o,i=b+r/2,a=h,s=L(n,u.length)+r/2,l=(t+a)/2;S+=`<path d="M${t},${i} C${l},${i} ${l},${s} ${a},${s}" fill="none" stroke="var(--ng-edge-depby)" stroke-width="1.5" opacity="0.5"/>`}),p.forEach((e,n)=>A(y,L(n,p.length),e,!1)),A(f,b,n,!0),u.forEach((e,n)=>A(h,L(n,u.length),e,!1)),p.length>0&&(S+=`<text x="${y+o/2}" y="16" fill="var(--ng-text-dim)" font-size="10" text-anchor="middle" font-weight="600">REQUIRES</text>`);u.length>0&&(S+=`<text x="${h+o/2}" y="16" fill="var(--ng-text-dim)" font-size="10" text-anchor="middle" font-weight="600">REQUIRED BY</text>`);S+="</svg>",a.innerHTML=S,a.querySelectorAll(".ng-graph-node").forEach(e=>{e.addEventListener("click",()=>{const n=s.get(e.dataset.name);n&&m(n)})})}(n,i,a)}let g=null;const v=e.querySelector("#ng-search");function y(e){clearTimeout(g),g=setTimeout(()=>{a=e.target.value.trim(),p()},150)}v.addEventListener("input",y),e.querySelectorAll(".ng-level-pill").forEach(e=>{e.addEventListener("click",()=>{const n=parseInt(e.dataset.level);i.has(n)?(i.delete(n),e.classList.remove("active")):(i.add(n),e.classList.add("active")),p()})});const f=e.querySelector("#ng-statusFilter");function h(e){o=e.target.value,p()}f.addEventListener("change",h);const L=e.querySelector("#ng-categoryFilter");function b(e){r=e.target.value,p()}function k(){const n=window.location.hash.slice(1);if(n){const i=decodeURIComponent(n),a=s.get(i);if(a)return t=a,p(),u(a),void setTimeout(()=>{const n=e.querySelector(`.ng-neuron-item[data-name="${a.name}"]`);n&&n.scrollIntoView({block:"center",behavior:"smooth"})},50)}}return L.addEventListener("change",b),window.addEventListener("hashchange",k),p(),k(),function(){clearTimeout(g),window.removeEventListener("hashchange",k),v.removeEventListener("input",y),f.removeEventListener("change",h),L.removeEventListener("change",b)}}var l=t(4848);function d(){const e=(0,i.useRef)(null);return(0,i.useEffect)(()=>{const n=e.current;if(!n)return;n.innerHTML='\n\x3c!-- Controls Bar --\x3e\n<div class="ng-controls">\n  <div class="ng-logo">NeuroScript <span>Neuron Genealogy</span></div>\n  <input type="text" class="ng-search-box" id="ng-search" placeholder="Search neurons..." autocomplete="off">\n  <div class="ng-level-pills" id="ng-levelPills">\n    <div class="ng-level-pill active" data-level="0">L0</div>\n    <div class="ng-level-pill active" data-level="1">L1</div>\n    <div class="ng-level-pill active" data-level="2">L2</div>\n    <div class="ng-level-pill active" data-level="3">L3</div>\n    <div class="ng-level-pill active" data-level="4">L4</div>\n    <div class="ng-level-pill active" data-level="5">L5</div>\n  </div>\n  <select class="ng-ctrl-select" id="ng-statusFilter">\n    <option value="all">All status</option>\n    <option value="implemented">Implemented</option>\n    <option value="planned">Planned</option>\n  </select>\n  <select class="ng-ctrl-select" id="ng-categoryFilter">\n    <option value="all">All categories</option>\n  </select>\n  <div class="ng-stats" id="ng-stats"></div>\n</div>\n\n\x3c!-- Main two-panel layout --\x3e\n<div class="ng-main">\n  <div class="ng-list-panel" id="ng-listPanel"></div>\n  <div class="ng-detail-panel" id="ng-detailPanel">\n    <div class="ng-detail-empty">Select a neuron from the list<br>to view its dependencies and details</div>\n  </div>\n</div>\n';const t=s(n,r);return()=>{t&&t(),n.innerHTML=""}},[]),(0,l.jsx)("div",{className:"neuron-genealogy",ref:e})}function c(){return(0,l.jsx)(o.A,{fallback:(0,l.jsx)("div",{style:{height:"calc(100vh - 60px)",background:"#0d1117"}}),children:()=>(0,l.jsx)(d,{})})}function p(){return(0,l.jsx)(a.A,{title:"Neuron Genealogy",description:"Interactive explorer for the NeuroScript neuron hierarchy \u2014 300+ neurons with dependency graphs",children:(0,l.jsx)(c,{})})}}}]);