"use strict";(globalThis.webpackChunkneuroscript_docs=globalThis.webpackChunkneuroscript_docs||[]).push([[5782],{2829(n,e,o){let i;function t(n,e){return function(n,e){c+=e,c>=u&&(l=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0}),l.decode(),c=e);return l.decode(r().subarray(n,n+e))}(n>>>=0,e)}o.d(e,{Ay:()=>v,ns:()=>h,wE:()=>_});let a=null;function r(){return null!==a&&0!==a.byteLength||(a=new Uint8Array(i.memory.buffer)),a}function s(n,e,o){if(void 0===o){const o=m.encode(n),i=e(o.length,1)>>>0;return r().subarray(i,i+o.length).set(o),p=o.length,i}let i=n.length,t=e(i,1)>>>0;const a=r();let s=0;for(;s<i;s++){const e=n.charCodeAt(s);if(e>127)break;a[t+s]=e}if(s!==i){0!==s&&(n=n.slice(s)),t=o(t,i,i=s+3*n.length,1)>>>0;const e=r().subarray(t+s,t+i);s+=m.encodeInto(n,e).written,t=o(t,i,s,1)>>>0}return p=s,t}function d(n){const e=i.__wbindgen_externrefs.get(n);return i.__externref_table_dealloc(n),e}let l=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0});l.decode();const u=2146435072;let c=0;const m=new TextEncoder;"encodeInto"in m||(m.encodeInto=function(n,e){const o=m.encode(n);return e.set(o),{read:n.length,written:o.length}});let p=0;function h(n){let e,o;try{const l=s(n,i.__wbindgen_malloc,i.__wbindgen_realloc),u=p,c=i.analyze(l,u);var a=c[0],r=c[1];if(c[3])throw a=0,r=0,d(c[2]);return e=a,o=r,t(a,r)}finally{i.__wbindgen_free(e,o,1)}}function _(n){let e,o;try{const l=s(n,i.__wbindgen_malloc,i.__wbindgen_realloc),u=p,c=i.compile(l,u);var a=c[0],r=c[1];if(c[3])throw a=0,r=0,d(c[2]);return e=a,o=r,t(a,r)}finally{i.__wbindgen_free(e,o,1)}}const b=new Set(["basic","cors","default"]);function f(){const n={wbg:{}};return n.wbg.__wbindgen_cast_2241b6af4c4b2941=function(n,e){return t(n,e)},n.wbg.__wbindgen_init_externref_table=function(){const n=i.__wbindgen_externrefs,e=n.grow(4);n.set(0,void 0),n.set(e+0,void 0),n.set(e+1,null),n.set(e+2,!0),n.set(e+3,!1)},n}function g(n,e){return i=n.exports,y.__wbindgen_wasm_module=e,a=null,i.__wbindgen_start(),i}async function y(n){if(void 0!==i)return i;void 0!==n&&(Object.getPrototypeOf(n)===Object.prototype?({module_or_path:n}=n):console.warn("using deprecated parameters for the initialization function; pass a single object instead")),void 0===n&&(n=new URL(o(6407),o.b));const e=f();("string"==typeof n||"function"==typeof Request&&n instanceof Request||"function"==typeof URL&&n instanceof URL)&&(n=fetch(n));const{instance:t,module:a}=await async function(n,e){if("function"==typeof Response&&n instanceof Response){if("function"==typeof WebAssembly.instantiateStreaming)try{return await WebAssembly.instantiateStreaming(n,e)}catch(o){if(!n.ok||!b.has(n.type)||"application/wasm"===n.headers.get("Content-Type"))throw o;console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n",o)}const i=await n.arrayBuffer();return await WebAssembly.instantiate(i,e)}{const o=await WebAssembly.instantiate(n,e);return o instanceof WebAssembly.Instance?{instance:o,module:n}:o}}(await n,e);return g(t,a)}const v=y},6407(n,e,o){n.exports=o.p+"00a0d775160ad9b0.wasm"},8634(n,e,o){o.r(e),o.d(e,{default:()=>u});var i=o(6540),t=o(3544),a=o(2829),r=o(9350),s=o(4848);const d="neuron MLP(dim):\n  in: [*, dim]\n  out: [*, dim]\n  graph:\n    in ->\n      Linear(dim, dim * 4)\n      GELU()\n      Linear(dim * 4, dim)\n      out";function l(){const[n,e]=(0,i.useState)(d),[o,t]=(0,i.useState)(""),[l,u]=(0,i.useState)(""),[c,m]=(0,i.useState)(!1);(0,i.useEffect)(()=>{(0,a.Ay)().then(()=>{m(!0),p(d)}).catch(n=>{console.error("WASM init failed:",n),u("Failed to initialize compiler: "+n)})},[]);const p=n=>{if(c)try{const e=n.replace(/^use .*$/gm,"# $&"),o=r.y+"\n"+e,i=(0,a.wE)(o);t(i),u("")}catch(e){u(e.toString()),t("")}};return(0,s.jsxs)("div",{style:{display:"flex",flexDirection:"column",gap:"1rem"},children:[(0,s.jsxs)("div",{style:{display:"flex",gap:"1rem"},children:[(0,s.jsx)("button",{onClick:()=>p(n),disabled:!c,className:"button button--primary",children:"Compile"}),(0,s.jsx)("button",{onClick:()=>{const n=[()=>{const n=[64,128,256,512][Math.floor(4*Math.random())]*[2,4][Math.floor(2*Math.random())];return`neuron RandomMLP(dim):\n  in: [*, dim]\n  out: [*, dim]\n  graph:\n    in ->\n      Linear(dim, ${n})\n      GELU()\n      Linear(${n}, dim)\n      out`},()=>{Math.floor(3*Math.random());return"neuron RandomResidual(dim):\n  in: [*, dim]\n  out: [*, dim]\n  graph:\n    in -> Fork() -> (main, skip)\n    main -> \n      LayerNorm(dim)\n      Linear(dim, dim)\n      GELU()\n      Linear(dim, dim)\n      processed\n    (processed, skip) -> Add() -> out"},()=>{Math.floor(3*Math.random()),Math.floor(3*Math.random());return"neuron RandomAttention(dim, heads):\n  in: [*, seq, dim]\n  out: [*, seq, dim]\n  graph:\n    in ->\n      LayerNorm(dim)\n      MultiHeadSelfAttention(dim, heads)\n      Dropout(0.1)\n      out"},()=>{Math.floor(3*Math.random());return"neuron ConvBlock(channels):\n  in: [*, channels, h, w]\n  out: [*, channels, h, w]\n  graph:\n    in ->\n      Conv2d(channels, channels, kernel_size=3, padding=1)\n      BatchNorm2d(channels)\n      ReLU()\n      out"}],o=(0,n[Math.floor(Math.random()*n.length)])();e(o),p(o)},disabled:!c,className:"button button--secondary",children:"Random Model"})]}),(0,s.jsxs)("div",{style:{display:"flex",gap:"1rem",height:"500px"},children:[(0,s.jsxs)("div",{style:{flex:1,display:"flex",flexDirection:"column"},children:[(0,s.jsx)("h3",{children:"Source (NeuroScript)"}),(0,s.jsx)("textarea",{value:n,onChange:n=>{const o=n.target.value;e(o),p(o)},style:{flex:1,fontFamily:"monospace",padding:"1rem",resize:"none",borderRadius:"8px",border:"1px solid #ccc",fontSize:"14px",lineHeight:"1.5"},spellCheck:"false"})]}),(0,s.jsxs)("div",{style:{flex:1,display:"flex",flexDirection:"column"},children:[(0,s.jsx)("h3",{children:"Output (PyTorch)"}),l?(0,s.jsx)("div",{style:{flex:1,backgroundColor:"#fff0f0",color:"#d00",padding:"1rem",fontFamily:"monospace",whiteSpace:"pre-wrap",overflow:"auto",borderRadius:"8px",border:"1px solid #ffcccc"},children:l}):(0,s.jsx)("textarea",{readOnly:!0,value:o,style:{flex:1,fontFamily:"monospace",padding:"1rem",backgroundColor:"#1e1e1e",color:"#d4d4d4",resize:"none",borderRadius:"8px",border:"1px solid #333"}})]})]})]})}function u(){return(0,s.jsx)(t.A,{title:"Playground",description:"Compile NeuroScript to PyTorch in your browser",children:(0,s.jsx)("main",{children:(0,s.jsxs)("div",{className:"container margin-vert--lg",children:[(0,s.jsx)("h1",{children:"NeuroScript Playground"}),(0,s.jsx)("p",{children:"Write NeuroScript code on the left, see compiled PyTorch code on the right."}),(0,s.jsx)(l,{})]})})})}},9350(n,e,o){o.d(e,{y:()=>i});const i="\n\n\nneuron FFN(dim, expansion):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    graph:\n        in ->\n            Linear(dim, expansion)\n            GELU()\n            Linear(expansion, dim)\n            out\n\nneuron FFNWithHidden(in_dim, hidden_dim, out_dim):\n    in: [*shape, in_dim]\n    out: [*shape, out_dim]\n    graph:\n        in ->\n            Linear(in_dim, hidden_dim)\n            GELU()\n            Linear(hidden_dim, out_dim)\n            out\n\nneuron ParallelFFN(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in -> FFN(dim, dim * 2) -> out\n\nneuron AdaptiveAvgPool(output_size):\n    in: [batch, channels, *, *]\n    out: [batch, channels, output_size, output_size]\n    impl: core,pooling/AdaptiveAvgPool\n\nneuron AdaptiveMaxPool(output_size):\n    in: [batch, channels, *, *]\n    out: [batch, channels, output_size, output_size]\n    impl: core,pooling/AdaptiveMaxPool\n\nneuron Add:\n    in main: [*shape]\n    in skip: [*shape]\n    out: [*shape]\n    impl: core,structural/Add\n\nneuron AvgPool(kernel_size, stride=1, padding=0):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,pooling/AvgPool\n\nneuron BatchNorm(num_features):\n    in: [*shape, num_features]\n    out: [*shape, num_features]\n    impl: core,normalization/BatchNorm\n\nneuron Bias(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,operations/Bias\n\nneuron Concat(dim):\n    in a: [*shape_a]\n    in b: [*shape_b]\n    out: [*shape_out]\n    impl: core,structural/Concat\n\nneuron Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, length]\n    out: [batch, out_channels, *]\n    impl: core,convolutions/Conv1d\n\nneuron Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/Conv2d\n\nneuron Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, depth, height, width]\n    out: [batch, out_channels, *, *, *]\n    impl: core,convolutions/Conv3d\n\nneuron DepthwiseConv(channels, kernel_size, stride=1, padding=0, dilation=1, bias=true):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,convolutions/DepthwiseConv\n\nneuron DropConnect(drop_prob):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/DropConnect\n\nneuron Dropout(p):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/Dropout\n\nneuron DropPath(drop_prob):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/DropPath\n\nneuron Einsum(equation):\n    in a: [*shape_a]\n    in b: [*shape_b]\n    out: [*shape_out]\n    impl: core,operations/Einsum\n\nneuron ELU(alpha=1.0):\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/ELU\n\nneuron Embedding(num_embeddings, embedding_dim):\n    in: [*, seq_len]\n    out: [*, seq_len, embedding_dim]\n    impl: core,embeddings/Embedding\n\nneuron Flatten(start_dim=1, end_dim=-1):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Flatten\n\nneuron Fork:\n    in: [*shape]\n    out main: [*shape]\n    out skip: [*shape]\n    impl: core,structural/Fork\n\nneuron Fork3:\n    in: [*shape]\n    out a: [*shape]\n    out b: [*shape]\n    out c: [*shape]\n    impl: core,structural/Fork3\n\nneuron GELU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/GELU\n\nneuron GlobalAvgPool:\n    in: [batch, channels, *, *]\n    out: [batch, channels, 1, 1]\n    impl: core,pooling/GlobalAvgPool\n\nneuron GlobalMaxPool:\n    in: [batch, channels, *, *]\n    out: [batch, channels, 1, 1]\n    impl: core,pooling/GlobalMaxPool\n\nneuron GroupNorm(num_groups, num_channels):\n    in: [*, num_channels, *, *]\n    out: [*, num_channels, *, *]\n    impl: core,normalization/GroupNorm\n\nneuron Identity:\n    in: [*shape]\n    out: [*shape]\n    impl: core,structural/Identity\n\nneuron InstanceNorm(num_features, eps=0.00001, affine=true):\n    in: [batch, num_features, *spatial]\n    out: [batch, num_features, *spatial]\n    impl: core,normalization/InstanceNorm\n\nneuron LayerNorm(dim):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    impl: core,normalization/LayerNorm\n\nneuron LearnedPositionalEmbedding(max_positions, embedding_dim):\n    in: [*, seq_len, embedding_dim]\n    out: [*, seq_len, embedding_dim]\n    impl: core,embeddings/LearnedPositionalEmbedding\n\nneuron Linear(in_dim, out_dim):\n    in: [*, in_dim]\n    out: [*, out_dim]\n    impl: core,nn/Linear\n\nneuron MatMul:\n    in a: [*, n, m]\n    in b: [*, m, p]\n    out: [*, n, p]\n    impl: core,operations/MatMul\n\nneuron MaxPool(kernel_size, stride=1, padding=0, dilation=1):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,pooling/MaxPool\n\nneuron Mish:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Mish\n\nneuron MultiHeadSelfAttention(dim, num_heads):\n    in: [*, seq_len, dim]\n    out: [*, seq_len, dim]\n    impl: core,attention/MultiHeadSelfAttention\n\nneuron Multiply:\n    in a: [*shape]\n    in b: [*shape]\n    out: [*shape]\n    impl: core,structural/Multiply\n\nneuron Pad(padding, value=0, mode=constant):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Pad\n\nneuron PositionalEncoding(dim, max_len):\n    in: [*, seq_len, dim]\n    out: [*, seq_len, dim]\n    impl: core,embeddings/PositionalEncoding\n\nneuron PReLU(num_parameters=1, init=0.25):\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/PReLU\n\nneuron ReLU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/ReLU\n\nneuron Reshape(target_shape):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Reshape\n\nneuron RMSNorm(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,normalization/RMSNorm\n\nneuron RotaryEmbedding(dim, max_position_embeddings=2048, base=10000):\n    in query: [*batch, seq, num_heads, dim]\n    in key: [*batch, seq, num_heads, dim]\n    out q_out: [*batch, seq, num_heads, dim]\n    out k_out: [*batch, seq, num_heads, dim]\n    impl: neuroscript,embeddings/RotaryEmbedding\n\nneuron Scale(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,operations/Scale\n\nneuron ScaledDotProductAttention(d_k):\n    in query: [*, seq_q, d_k]\n    in key: [*, seq_k, d_k]\n    in value: [*, seq_v, d_v]\n    out: [*, seq_q, d_v]\n    impl: core,attention/ScaledDotProductAttention\n\nneuron SeparableConv(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/SeparableConv\n\nneuron Sigmoid:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Sigmoid\n\nneuron SiLU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/SiLU\n\nneuron Slice(dim, start, end):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Slice\n\nneuron Softmax(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,activations/Softmax\n\nneuron Split(num_splits, dim=-1):\n    in: [*shape]\n    out a: [*shape_a]\n    out b: [*shape_b]\n    impl: core,structural/Split\n\nneuron Tanh:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Tanh\n\nneuron Transpose(dims):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Transpose\n\nneuron TransposedConv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/TransposedConv\n\nneuron SimpleTransformerBlock(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            Dropout(0.1)\n            out\n\nneuron TransformerBlock(dim, num_heads, d_ff):\n    in: [batch, seq, dim]\n    out: [batch, seq, dim]\n    graph:\n        in -> Fork() -> (skip1, attn_path)\n        attn_path ->\n            LayerNorm(dim)\n            MultiHeadSelfAttention(dim, num_heads)\n            Dropout(0.1)\n            attn_out\n        (skip1, attn_out) -> Add() -> attn_residual\n        attn_residual -> Fork() -> (skip2, ffn_path)\n        ffn_path ->\n            LayerNorm(dim)\n            FFN(dim, d_ff)\n            Dropout(0.1)\n            ffn_out\n        (skip2, ffn_out) -> Add() -> out\n\nneuron TransformerStack2(d_model, num_heads, d_ff):\n    in: [*, d_model]\n    out: [*, d_model]\n    graph:\n        in ->\n            SimpleTransformerBlock(d_model)\n            SimpleTransformerBlock(d_model)\n            out\n\nneuron SequentialTransformer(d_model, num_heads, d_ff):\n    in: [*, d_model]\n    out: [*, d_model]\n    graph:\n        in ->\n            SimpleTransformerBlock(d_model)\n            out\n"}}]);