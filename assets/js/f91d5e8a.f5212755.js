"use strict";(globalThis.webpackChunkneuroscript_docs=globalThis.webpackChunkneuroscript_docs||[]).push([[8292],{9881(e,n,o){o.r(n),o.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"tutorials/higher-order-neurons","title":"Higher-Order Neurons","description":"Pass neuron types as parameters for generic, reusable architectures","source":"@site/docs/tutorials/higher-order-neurons.mdx","sourceDirName":"tutorials","slug":"/tutorials/higher-order-neurons","permalink":"/docs/tutorials/higher-order-neurons","draft":false,"unlisted":false,"editUrl":"https://github.com/neuroscript/neuroscript/tree/main/website/docs/tutorials/higher-order-neurons.mdx","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Higher-Order Neurons","description":"Pass neuron types as parameters for generic, reusable architectures"},"sidebar":"docsSidebar","previous":{"title":"Variadic Ports","permalink":"/docs/tutorials/variadic-ports"},"next":{"title":"Primitives","permalink":"/docs/primitives/"}}');var t=o(4848),i=o(8453),a=o(3620);const s={sidebar_position:7,title:"Higher-Order Neurons",description:"Pass neuron types as parameters for generic, reusable architectures"},l="Higher-Order Neurons",d={},c=[{value:"The <code>: Neuron</code> Type Annotation",id:"the--neuron-type-annotation",level:2},{value:"Basic Higher-Order Neuron",id:"basic-higher-order-neuron",level:2},{value:"Contract Dispatch with <code>match(param):</code>",id:"contract-dispatch-with-matchparam",level:2},{value:"How It Works",id:"how-it-works",level:2},{value:"Combining with Unroll",id:"combining-with-unroll",level:2},{value:"Key Rules",id:"key-rules",level:2},{value:"Try It Yourself",id:"try-it-yourself",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"higher-order-neurons",children:"Higher-Order Neurons"})}),"\n",(0,t.jsxs)(n.p,{children:["NeuroScript supports ",(0,t.jsx)(n.strong,{children:"higher-order neurons"})," \u2014 neurons that accept other neuron types as parameters. This lets you build generic architectures that work with any block type, similar to higher-order functions in programming."]}),"\n",(0,t.jsxs)(n.h2,{id:"the--neuron-type-annotation",children:["The ",(0,t.jsx)(n.code,{children:": Neuron"})," Type Annotation"]}),"\n",(0,t.jsxs)(n.p,{children:["Mark a parameter as a neuron type by adding ",(0,t.jsx)(n.code,{children:": Neuron"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-neuroscript",children:"neuron Stack(block: Neuron, d_model, count=6):\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"block"})," parameter doesn't hold a value \u2014 it holds a ",(0,t.jsx)(n.strong,{children:"neuron constructor"}),". When someone instantiates ",(0,t.jsx)(n.code,{children:"Stack"}),", they pass a neuron name (like ",(0,t.jsx)(n.code,{children:"TransformerBlock"}),"), and ",(0,t.jsx)(n.code,{children:"block"})," can be used anywhere a neuron name would appear."]}),"\n",(0,t.jsx)(n.h2,{id:"basic-higher-order-neuron",children:"Basic Higher-Order Neuron"}),"\n",(0,t.jsx)(a.A,{title:"Generic Stack",description:"A reusable stack that works with any block type",initialCode:"neuron Stack(block: Neuron, d_model, num_heads, d_ff, count=6):\n  in: [*, seq, d_model]\n  out: [*, seq, d_model]\n  context:\n      blocks = unroll(count):\n          layer = block(d_model, num_heads, d_ff)\n  graph:\n      in ->\n          blocks\n          out"}),"\n",(0,t.jsx)(n.p,{children:"This neuron:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Takes ",(0,t.jsx)(n.code,{children:"block: Neuron"})," as its first parameter"]}),"\n",(0,t.jsxs)(n.li,{children:["Uses ",(0,t.jsx)(n.code,{children:"block(d_model, num_heads, d_ff)"})," in context bindings just like any neuron call"]}),"\n",(0,t.jsxs)(n.li,{children:["Can be instantiated with different block types: ",(0,t.jsx)(n.code,{children:"Stack(TransformerBlock, 512, 8, 2048)"})]}),"\n"]}),"\n",(0,t.jsxs)(n.h2,{id:"contract-dispatch-with-matchparam",children:["Contract Dispatch with ",(0,t.jsx)(n.code,{children:"match(param):"})]}),"\n",(0,t.jsxs)(n.p,{children:["Sometimes you need different wiring strategies depending on what block is passed. The ",(0,t.jsx)(n.code,{children:"match(param):"})," syntax inspects a neuron parameter's port shapes at compile time:"]}),"\n",(0,t.jsx)(a.A,{title:"Shape-Aware Stack",description:"Selects wiring strategy based on the block's port signatures",initialCode:"neuron SmartStack(block: Neuron, d_model, count=6):\n  in: [*, seq, d_model]\n  out: [*, seq, d_model]\n  context:\n      blocks = unroll(count):\n          layer = block(d_model)\n  graph:\n      in ->\n          match(block):\n              in [*, seq, d_model] -> out [*, seq, d_model]:\n                  blocks\n                  out\n              in [*, d_model] -> out [*, d_model]:\n                  blocks\n                  out"}),"\n",(0,t.jsxs)(n.p,{children:["Each arm specifies an ",(0,t.jsx)(n.strong,{children:"input/output port contract"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"in [*, seq, d_model] -> out [*, seq, d_model]"})," matches blocks that process sequences"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"in [*, d_model] -> out [*, d_model]"})," matches blocks that process individual vectors"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The compiler resolves this at compile time: when ",(0,t.jsx)(n.code,{children:"SmartStack"})," is instantiated with a concrete block, it checks the block's declared ports against each arm and selects the first match."]}),"\n",(0,t.jsx)(n.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Parameter declaration"}),": ",(0,t.jsx)(n.code,{children:"block: Neuron"})," tells the compiler this parameter receives a neuron type"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Usage in context"}),": ",(0,t.jsx)(n.code,{children:"block(args...)"})," instantiates the neuron, just like calling any other neuron"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Contract dispatch"})," (optional): ",(0,t.jsx)(n.code,{children:"match(block):"})," lets you inspect the block's port shapes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Resolution"}),": When the higher-order neuron is instantiated with a concrete block, the compiler resolves all ",(0,t.jsx)(n.code,{children:"match(block):"})," expressions at compile time"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"combining-with-unroll",children:"Combining with Unroll"}),"\n",(0,t.jsx)(n.p,{children:"Higher-order neurons compose naturally with named unrolls:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-neuroscript",children:"neuron RepeatBlock(block: Neuron, d_model, count=4):\n    in: [*, seq, d_model]\n    out: [*, seq, d_model]\n    context:\n        layers = unroll(count):\n            layer = block(d_model)\n    graph:\n        in ->\n            layers\n            out\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"block"})," parameter is called inside the unroll to create ",(0,t.jsx)(n.code,{children:"count"})," independent instances, each with its own weights. The ",(0,t.jsx)(n.code,{children:"layers"})," aggregate then threads data through all of them sequentially."]}),"\n",(0,t.jsx)(n.h2,{id:"key-rules",children:"Key Rules"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Parameters with ",(0,t.jsx)(n.code,{children:": Neuron"})," annotation hold neuron constructors, not tensor values"]}),"\n",(0,t.jsx)(n.li,{children:"A neuron-typed parameter can be used anywhere a neuron name appears (in context bindings, in graph calls)"}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"match(param):"})," arms use port contract patterns (",(0,t.jsx)(n.code,{children:"in [shape] -> out [shape]"}),"), not tensor shape patterns"]}),"\n",(0,t.jsxs)(n.li,{children:["Contract dispatch is resolved at ",(0,t.jsx)(n.strong,{children:"compile time"})," \u2014 the block's ports must match at least one arm"]}),"\n",(0,t.jsx)(n.li,{children:"All standard neuron features (unroll, @static, pipeline chaining) work with neuron-typed parameters"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"try-it-yourself",children:"Try It Yourself"}),"\n",(0,t.jsx)(n.p,{children:"Experiment with higher-order neurons:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Change the block parameter to different neuron types"}),"\n",(0,t.jsx)(n.li,{children:"Add contract dispatch to handle blocks with different port shapes"}),"\n",(0,t.jsxs)(n.li,{children:["Combine with ",(0,t.jsx)(n.code,{children:"@static"})," unroll for weight-shared stacks"]}),"\n",(0,t.jsx)(n.li,{children:'Click "Show Analysis" to see how the compiler resolves the contracts'}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},3620(e,n,o){o.d(n,{A:()=>r.A});var r=o(4566)},4566(e,n,o){o.d(n,{A:()=>S});var r=o(6540),t=o(5293);let i;function a(e,n){return function(e,n){h+=n,h>=m&&(u=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0}),u.decode(),h=n);return u.decode(l().subarray(e,e+n))}(e>>>=0,n)}let s=null;function l(){return null!==s&&0!==s.byteLength||(s=new Uint8Array(i.memory.buffer)),s}function d(e,n,o){if(void 0===o){const o=p.encode(e),r=n(o.length,1)>>>0;return l().subarray(r,r+o.length).set(o),f=o.length,r}let r=e.length,t=n(r,1)>>>0;const i=l();let a=0;for(;a<r;a++){const n=e.charCodeAt(a);if(n>127)break;i[t+a]=n}if(a!==r){0!==a&&(e=e.slice(a)),t=o(t,r,r=a+3*e.length,1)>>>0;const n=l().subarray(t+a,t+r);a+=p.encodeInto(e,n).written,t=o(t,r,a,1)>>>0}return f=a,t}function c(e){const n=i.__wbindgen_externrefs.get(e);return i.__externref_table_dealloc(e),n}let u=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0});u.decode();const m=2146435072;let h=0;const p=new TextEncoder;"encodeInto"in p||(p.encodeInto=function(e,n){const o=p.encode(e);return n.set(o),{read:e.length,written:o.length}});let f=0;const g=new Set(["basic","cors","default"]);function b(){const e={wbg:{}};return e.wbg.__wbindgen_cast_2241b6af4c4b2941=function(e,n){return a(e,n)},e.wbg.__wbindgen_init_externref_table=function(){const e=i.__wbindgen_externrefs,n=e.grow(4);e.set(0,void 0),e.set(n+0,void 0),e.set(n+1,null),e.set(n+2,!0),e.set(n+3,!1)},e}function y(e,n){return i=e.exports,x.__wbindgen_wasm_module=n,s=null,i.__wbindgen_start(),i}async function x(e){if(void 0!==i)return i;void 0!==e&&(Object.getPrototypeOf(e)===Object.prototype?({module_or_path:e}=e):console.warn("using deprecated parameters for the initialization function; pass a single object instead")),void 0===e&&(e=new URL(o(6407),o.b));const n=b();("string"==typeof e||"function"==typeof Request&&e instanceof Request||"function"==typeof URL&&e instanceof URL)&&(e=fetch(e));const{instance:r,module:t}=await async function(e,n){if("function"==typeof Response&&e instanceof Response){if("function"==typeof WebAssembly.instantiateStreaming)try{return await WebAssembly.instantiateStreaming(e,n)}catch(o){if(!e.ok||!g.has(e.type)||"application/wasm"===e.headers.get("Content-Type"))throw o;console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n",o)}const r=await e.arrayBuffer();return await WebAssembly.instantiate(r,n)}{const o=await WebAssembly.instantiate(e,n);return o instanceof WebAssembly.Instance?{instance:o,module:e}:o}}(await e,n);return y(r,t)}const k=x;var w=o(4848);let v,j;try{v=o(8553).Ay,j=o(4113).A}catch(C){}const _='"Fira Code", "Cascadia Code", "SF Mono", Monaco, "Inconsolata", "Roboto Mono", "Source Code Pro", Menlo, Consolas, "DejaVu Sans Mono", monospace';function S({mode:e="tutorial",layout:n,initialCode:s="",title:l,description:u,showAnalysis:m,showExampleSelector:h,showCompileButton:p,showCopyButton:g,showStats:b,height:y,responsive:x,examples:S,defaultExampleId:z="mlp"}){const N="playground"===e,{colorMode:L}=(0,t.G)(),A="dark"===L,P="vertical"===(n||(N?"horizontal":"vertical")),T={analysis:m??!N,exampleSelector:h??N,compileButton:p??!0,copyButton:g??N,stats:b??N,responsive:x??N},R=y||(N?"500px":"300px"),B=(0,r.useRef)(null),F=(0,r.useRef)(null);if(T.exampleSelector&&!B.current){const e=o(2012);B.current=S||e.EXAMPLES,F.current=e.getExamplesByCategory()}const M=B.current||[],E=F.current||{},[W,q]=(0,r.useState)(s),[D,H]=(0,r.useState)(""),[O,I]=(0,r.useState)(""),[U,$]=(0,r.useState)(!1),[G,Z]=(0,r.useState)(z),[K,V]=(0,r.useState)([]),[J,Q]=(0,r.useState)(null),[X,Y]=(0,r.useState)(!1),[ee,ne]=(0,r.useState)(!1),[oe,re]=(0,r.useState)(!1),[te,ie]=(0,r.useState)(!1),[ae,se]=(0,r.useState)(!v),le=(0,r.useRef)(null),de=(0,r.useCallback)((e,n=null)=>{if(U){re(!0);try{const o=e.replace(/^use .*$/gm,"# $&");try{const e=function(e){let n,o;try{const s=d(e,i.__wbindgen_malloc,i.__wbindgen_realloc),l=f,u=i.list_neurons(s,l);var r=u[0],t=u[1];if(u[3])throw r=0,t=0,c(u[2]);return n=r,o=t,a(r,t)}finally{i.__wbindgen_free(n,o,1)}}(o),r=JSON.parse(e);V(r),n||1!==r.length||(n=r[0])}catch(C){V([])}const r=function(e,n){let o,r;try{const m=d(e,i.__wbindgen_malloc,i.__wbindgen_realloc),h=f;var t=null==n?0:d(n,i.__wbindgen_malloc,i.__wbindgen_realloc),s=f;const p=i.compile(m,h,t,s);var l=p[0],u=p[1];if(p[3])throw l=0,u=0,c(p[2]);return o=l,r=u,a(l,u)}finally{i.__wbindgen_free(o,r,1)}}(o,n||void 0);if(H(r),I(""),T.analysis)try{const e=function(e){let n,o;try{const s=d(e,i.__wbindgen_malloc,i.__wbindgen_realloc),l=f,u=i.analyze(s,l);var r=u[0],t=u[1];if(u[3])throw r=0,t=0,c(u[2]);return n=r,o=t,a(r,t)}finally{i.__wbindgen_free(n,o,1)}}(o);Q(JSON.parse(e))}catch(C){Q(null)}}catch(o){I(o.toString()),H(""),V([]),Q(null)}finally{re(!1)}}},[U,T.analysis]),ce=(0,r.useCallback)((e,n)=>{le.current&&clearTimeout(le.current),le.current=setTimeout(()=>de(e,n),500)},[de]),ue=(0,r.useCallback)(e=>{q(e.code),Z(e.id),de(e.code,e.targetNeuron)},[de]);(0,r.useEffect)(()=>{k().then(()=>$(!0)).catch(e=>{console.error("WASM init failed:",e),I("Failed to initialize compiler: "+e)})},[]),(0,r.useEffect)(()=>{if(U)if(T.exampleSelector){const e=M.find(e=>e.id===z);e&&ue(e)}else de(s)},[U]),(0,r.useEffect)(()=>{if(!T.responsive)return;const e=()=>ie(window.innerWidth<768);return e(),window.addEventListener("resize",e),()=>window.removeEventListener("resize",e)},[T.responsive]);(0,r.useEffect)(()=>{v||se(!0)},[]);const me=T.exampleSelector?M.find(e=>e.id===G):null,he={fontFamily:_,fontSize:N?13:12,lineHeight:N?1.6:1.5,minimap:{enabled:!1},automaticLayout:!0,scrollBeyondLastLine:!1,tabSize:4,renderLineHighlight:"none",overviewRulerLanes:0,hideCursorInOverviewRuler:!0,overviewRulerBorder:!1,scrollbar:{verticalScrollbarSize:8,horizontalScrollbarSize:8},padding:{top:8,bottom:8}},pe=P?`${Math.max((W.split("\n").length+1)*(N?21:18),N?400:72)}px`:R,fe=A?"neuroscript-dark":"neuroscript-light";return(0,w.jsxs)("div",{style:N?{display:"flex",flexDirection:"column",gap:"1rem",maxWidth:"100%"}:{marginBottom:"2rem"},children:[l&&(0,w.jsx)("h3",{style:{marginTop:"1rem",marginBottom:"0.5rem"},children:l}),u&&(0,w.jsx)("p",{style:{marginBottom:"1rem",color:"var(--ifm-color-emphasis-600)"},children:u}),(T.exampleSelector||T.compileButton)&&(0,w.jsxs)("div",{style:{display:"flex",gap:"1rem",alignItems:"flex-end",flexWrap:"wrap"},children:[T.exampleSelector&&(0,w.jsxs)("div",{style:{flex:"1",minWidth:"250px"},children:[(0,w.jsx)("label",{style:{display:"block",marginBottom:"0.25rem",fontWeight:"bold"},children:"Example:"}),(0,w.jsx)("select",{value:G,onChange:e=>{const n=M.find(n=>n.id===e.target.value);n&&ue(n)},disabled:!U,style:{width:"100%",padding:"0.5rem",borderRadius:"4px",border:"1px solid var(--ifm-color-emphasis-300)",backgroundColor:"var(--ifm-background-color)",color:"var(--ifm-font-color-base)",fontSize:"14px"},children:Object.entries(E).map(([e,n])=>(0,w.jsx)("optgroup",{label:e,children:n.map(e=>(0,w.jsx)("option",{value:e.id,children:e.title},e.id))},e))})]}),T.compileButton&&(0,w.jsx)("div",{style:{marginLeft:"auto"},children:(0,w.jsx)("button",{onClick:()=>de(W),disabled:!U||oe,className:"button button--outline button--primary",style:{fontSize:"14px"},children:oe?"\u23f3 Compiling...":"\u25b6\ufe0f Compile"})})]}),me&&(0,w.jsxs)("div",{style:{padding:"0.75rem",backgroundColor:"var(--ifm-color-emphasis-100)",borderRadius:"8px",borderLeft:"4px solid var(--ifm-color-primary)"},children:[(0,w.jsx)("p",{style:{margin:"0 0 0.5rem 0",fontWeight:"bold"},children:me.description}),(0,w.jsx)("div",{style:{display:"flex",gap:"0.5rem",flexWrap:"wrap"},children:me.features.map(e=>(0,w.jsx)("span",{style:{padding:"0.25rem 0.5rem",backgroundColor:"var(--ifm-color-primary)",color:"white",borderRadius:"12px",fontSize:"12px",fontWeight:"500"},children:e},e))})]}),(0,w.jsxs)("div",{style:{display:"flex",gap:P?"0.5rem":"1rem",...P?{flexDirection:"column"}:{minHeight:R,flexDirection:T.responsive&&te?"column":"row"}},children:[(0,w.jsxs)("div",{style:{display:"flex",flexDirection:"column",minWidth:0,...P?{}:{flex:1}},children:[(0,w.jsxs)("div",{style:{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:"0.25rem"},children:[N?(0,w.jsx)("h3",{style:{margin:0,marginTop:"1rem"},children:"Source (NeuroScript)"}):(0,w.jsx)("strong",{style:{fontSize:"0.9rem",color:"var(--ifm-color-emphasis-600)"},children:"NeuroScript"}),oe&&N&&(0,w.jsx)("span",{style:{fontSize:"12px",color:"var(--ifm-color-primary)"},children:"Compiling..."})]}),(0,w.jsx)("div",{style:{border:"1px solid var(--ifm-color-emphasis-300)",borderRadius:"8px",overflow:"hidden",...P?{}:{flex:1}},children:ae?(0,w.jsx)("textarea",{value:W,onChange:e=>{q(e.target.value),ce(e.target.value)},spellCheck:!1,style:{width:"100%",height:pe,fontFamily:_,fontSize:N?"13px":"12px",lineHeight:N?"1.6":"1.5",padding:"8px",border:"none",resize:"vertical",backgroundColor:A?"#1e1e1e":"#ffffff",color:A?"#d4d4d4":"#24292e",boxSizing:"border-box"}}):(0,w.jsx)(v,{height:pe,language:"neuroscript",theme:fe,value:W,onChange:e=>{const n=e||"";q(n),ce(n)},beforeMount:e=>{j&&j(e)},onMount:()=>{},loading:(0,w.jsx)("div",{style:{padding:"1rem",fontFamily:_,fontSize:"12px",color:"var(--ifm-color-emphasis-500)"},children:"Loading editor..."}),options:{...he,readOnly:N&&!U,lineNumbers:N?"on":"off"}})})]}),(0,w.jsxs)("div",{style:{display:"flex",flexDirection:"column",minWidth:0,...P?{marginTop:"0.5rem"}:{flex:1}},children:[(0,w.jsxs)("div",{style:{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:"0.25rem"},children:[N?(0,w.jsx)("h3",{style:{margin:0,marginTop:"1rem"},children:"Output (PyTorch)"}):(0,w.jsx)("strong",{style:{fontSize:"0.9rem",color:"var(--ifm-color-emphasis-600)"},children:"PyTorch Output"}),T.copyButton&&D&&(0,w.jsx)("button",{onClick:async()=>{try{await navigator.clipboard.writeText(D),ne(!0),setTimeout(()=>ne(!1),2e3)}catch(e){console.error("Failed to copy:",e)}},className:"button button--sm button--outline button--primary",style:{fontSize:"12px"},children:ee?"\u2713 Copied!":"\ud83d\udccb Copy"})]}),O?(0,w.jsx)("div",{style:{padding:"0.75rem",fontFamily:_,fontSize:N?"13px":"12px",whiteSpace:"pre-wrap",overflow:"auto",borderRadius:"8px",lineHeight:N?"1.6":"1.5",...P?{maxHeight:"400px"}:{flex:1},...N?{backgroundColor:"var(--ifm-color-danger-contrast-background)",color:"var(--ifm-color-danger-contrast-foreground)",border:"1px solid var(--ifm-color-danger)",minHeight:"400px"}:{backgroundColor:"var(--ifm-color-danger-contrast-background)",color:"var(--ifm-color-danger)",border:"1px solid var(--ifm-color-danger)"}},children:O}):(0,w.jsx)("div",{style:{border:"1px solid var(--ifm-color-emphasis-300)",borderRadius:"8px",overflow:"hidden",...P?{maxHeight:"400px"}:{flex:1}},children:ae?(0,w.jsx)("pre",{style:{margin:0,padding:"8px",fontFamily:_,fontSize:N?"13px":"12px",lineHeight:N?"1.6":"1.5",height:P?"auto":R,overflow:"auto",backgroundColor:A?"#1e1e1e":"#ffffff",color:A?"#d4d4d4":"#24292e"},children:D||(N?"# Compiled PyTorch code will appear here...":"")}):(0,w.jsx)(v,{height:P?`${Math.max((D.split("\n").length+1)*(N?21:18),N?400:72)}px`:R,language:"python",theme:A?"vs-dark":"vs",value:D||(N?"# Compiled PyTorch code will appear here...":""),loading:(0,w.jsx)("div",{style:{padding:"1rem",fontFamily:_,fontSize:"12px",color:"var(--ifm-color-emphasis-500)"},children:"Loading editor..."}),options:{...he,readOnly:!0,lineNumbers:N?"on":"off",domReadOnly:!0}})}),T.analysis&&J&&!N&&(0,w.jsx)("div",{style:{display:"flex",justifyContent:"flex-end",marginTop:"0.5rem"},children:(0,w.jsx)("button",{onClick:()=>Y(!X),className:"button button--sm "+(X?"button--primary":"button--outline button--primary"),style:{fontSize:"12px"},children:X?"Hide Analysis":"Show Analysis"})})]})]}),T.analysis&&X&&J&&(0,w.jsxs)("div",{style:{marginTop:"1rem",padding:"1rem",backgroundColor:"var(--ifm-color-emphasis-100)",borderRadius:"8px",border:"1px solid var(--ifm-color-emphasis-300)"},children:[(0,w.jsx)("h4",{style:{margin:"0 0 0.75rem 0",fontSize:"1rem"},children:"Shape Analysis"}),J.neurons&&J.neurons.filter(e=>!e.is_primitive).map((e,n)=>(0,w.jsxs)("div",{style:{marginBottom:"1rem"},children:[(0,w.jsxs)("div",{style:{fontWeight:"bold",marginBottom:"0.5rem"},children:[e.name,e.params.length>0&&(0,w.jsxs)("span",{style:{fontWeight:"normal",color:"var(--ifm-color-emphasis-600)"},children:["(",e.params.map(e=>e.name).join(", "),")"]})]}),(0,w.jsxs)("div",{style:{display:"grid",gridTemplateColumns:"auto 1fr",gap:"0.25rem 1rem",fontSize:"0.9rem",paddingLeft:"1rem"},children:[e.inputs.map((e,n)=>(0,w.jsxs)(r.Fragment,{children:[(0,w.jsxs)("span",{style:{color:"var(--ifm-color-emphasis-600)"},children:["in","default"!==e.name?` ${e.name}`:"",":"]}),(0,w.jsx)("code",{className:"shape-input",style:{padding:"2px 6px",borderRadius:"3px",fontSize:"0.85rem"},children:e.shape})]},`in-${n}`)),e.outputs.map((e,n)=>(0,w.jsxs)(r.Fragment,{children:[(0,w.jsxs)("span",{style:{color:"var(--ifm-color-emphasis-600)"},children:["out","default"!==e.name?` ${e.name}`:"",":"]}),(0,w.jsx)("code",{className:"shape-output",style:{padding:"2px 6px",borderRadius:"3px",fontSize:"0.85rem"},children:e.shape})]},`out-${n}`))]}),e.connections.length>0&&(0,w.jsxs)("div",{style:{marginTop:"0.5rem",paddingLeft:"1rem"},children:[(0,w.jsx)("span",{style:{color:"var(--ifm-color-emphasis-600)",fontSize:"0.85rem"},children:"Connections:"}),(0,w.jsx)("div",{style:{fontFamily:_,fontSize:"0.8rem",color:"var(--ifm-color-emphasis-700)",marginTop:"0.25rem"},children:e.connections.map((e,n)=>(0,w.jsxs)("div",{children:[e.source," \u2192 ",e.destination]},n))})]})]},n)),J.match_expressions&&J.match_expressions.length>0&&(0,w.jsxs)("div",{style:{marginTop:"1rem"},children:[(0,w.jsx)("h5",{style:{margin:"0 0 0.5rem 0",fontSize:"0.9rem"},children:"Match Expressions"}),J.match_expressions.map((e,n)=>(0,w.jsxs)("div",{style:{marginBottom:"0.5rem",paddingLeft:"1rem"},children:[(0,w.jsxs)("div",{style:{fontSize:"0.85rem",color:"var(--ifm-color-emphasis-600)"},children:["In ",e.neuron,":"]}),e.arms.map((e,n)=>(0,w.jsxs)("div",{style:{display:"flex",alignItems:"center",gap:"0.5rem",fontSize:"0.85rem",marginLeft:"1rem",opacity:e.is_reachable?1:.5},children:[(0,w.jsxs)("code",{className:"shape-match",style:{padding:"2px 6px",borderRadius:"3px"},children:[e.pattern,e.guard&&(0,w.jsxs)("span",{style:{color:"var(--ifm-color-emphasis-600)"},children:[" where ",e.guard]})]}),!e.is_reachable&&(0,w.jsx)("span",{style:{color:"var(--ifm-color-emphasis-500)",fontSize:"0.8rem"},children:"(unreachable)"})]},n))]},n))]})]}),T.stats&&D&&(0,w.jsxs)("div",{style:{padding:"0.5rem",backgroundColor:"var(--ifm-color-emphasis-100)",borderRadius:"4px",fontSize:"12px",color:"var(--ifm-color-emphasis-700)",textAlign:"right"},children:[K.length," neuron",1!==K.length?"s":""," \u2022 ",D.split("\n").length," lines generated"]})]})}},2012(e,n,o){o.r(n),o.d(n,{EXAMPLES:()=>r,getExampleById:()=>i,getExamplesByCategory:()=>t});const r=[{id:"gpt2-block",title:"GPT-2 Small",category:"Advanced",description:"End-to-end example showing how unroll composes a full GPT-2 model",code:"neuron GPT2Small(vocab_size=50257, d_model=768, num_heads=12, d_ff=3072, num_layers=12):\n    in: [*, seq]\n    out: [*, seq, vocab_size]\n    context:\n        embed = Embedding(vocab_size, d_model)\n        blocks = unroll(num_layers):\n            block = TransformerBlock(d_model, num_heads, d_ff)\n        ln_f = LayerNorm(d_model)\n        head = Linear(d_model, vocab_size)\n    graph:\n        in ->\n            embed\n            blocks\n            ln_f\n            head\n            out",targetNeuron:"GPT2Small",features:["Unroll","Multi-line graph","Transformer architecture"]},{id:"mlp",title:"Simple MLP",category:"Basics",description:"Feed-forward network with dimension parameters and expressions",code:"# A simple multi-layer perceptron with expansion and contraction\nneuron MLP(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            out",targetNeuron:"MLP",features:["Dimension variables","Pipeline syntax","Dimension expressions"]},{id:"linear-projection",title:"Linear Projection",category:"Basics",description:"Simple projection layer changing dimensions",code:"# Project from one dimension to another\nneuron Projection(in_dim, out_dim):\n    in: [batch, in_dim]\n    out: [batch, out_dim]\n    graph:\n        in -> Linear(in_dim, out_dim) -> out",targetNeuron:"Projection",features:["Shape signatures","Dimension propagation"]},{id:"normalization",title:"Normalization Layer",category:"Basics",description:"Layer normalization with dimension preservation",code:"# Normalize activations along the feature dimension\nneuron NormalizedLayer(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            out",targetNeuron:"NormalizedLayer",features:["Normalization","Shape preservation"]},{id:"residual",title:"Residual Block",category:"Patterns",description:"Skip connections with Fork and Add primitives",code:"# Classic residual connection pattern\nneuron ResidualBlock(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        # Fork creates two copies of the input\n        in -> Fork() -> (main, skip)\n\n        # Process the main path\n        main ->\n            LayerNorm(dim)\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            processed\n\n        # Add skip connection back\n        (processed, skip) -> Add() -> out",targetNeuron:"ResidualBlock",features:["Fork primitive","Tuple unpacking","Residual connections"]},{id:"parallel-paths",title:"Parallel Processing",category:"Patterns",description:"Multiple parallel paths with concatenation",code:"# Process input through three parallel paths\nneuron ParallelPaths(dim):\n    in: [*, dim]\n    out: [*, dim * 3]\n    graph:\n        # Split into three paths\n        in -> Fork3() -> (path1, path2, path3)\n\n        # Process each independently\n        path1 -> Linear(dim, dim) -> p1\n        path2 -> Linear(dim, dim) -> p2\n        path3 -> Linear(dim, dim) -> p3\n\n        # Combine results\n        (p1, p2, p3) -> Concat(-1) -> out",targetNeuron:"ParallelPaths",features:["Multi-way fork","Parallel paths","Concatenation"]},{id:"pre-activation",title:"Pre-Activation Residual",category:"Patterns",description:"Residual with normalization before transformation",code:"# Pre-activation residual block (normalize first)\nneuron PreActResidual(dim):\n    in: [batch, dim]\n    out: [batch, dim]\n    graph:\n        in -> Fork() -> (main, skip)\n\n        main ->\n            LayerNorm(dim)\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            processed\n\n        (processed, skip) -> Add() -> out",targetNeuron:"PreActResidual",features:["Pre-activation","Residual pattern","Named dimensions"]},{id:"match-basic",title:"Shape Pattern Matching",category:"Advanced",description:"Match expressions with dimension capture",code:"# Route based on input dimension size\nneuron AdaptiveProjection:\n    in: [*, dim]\n    out: [*, 512]\n    graph:\n        in -> match: ->\n            [*, d] where d > 512: Linear(d, 512) -> out\n            [*, d] where d < 512: Linear(d, 512) -> out\n            [*, d]: Identity() -> out",targetNeuron:"AdaptiveProjection",features:["Match expressions","Dimension capture","Guard conditions"]},{id:"match-routing",title:"Shape-Based Routing",category:"Advanced",description:"Different processing paths based on tensor dimensions",code:"# Choose processing based on feature dimension\nneuron DimensionRouter(out_dim):\n    in: [batch, in_dim]\n    out: [batch, out_dim]\n    graph:\n        in -> match: ->\n            [batch, d] where d > 1024:\n                Linear(d, 512) ->\n                Linear(512, out_dim)\n            [batch, d] where d > 256:\n                Linear(d, out_dim)\n            [batch, d]:\n                Linear(d, out_dim)\n        -> out",targetNeuron:"DimensionRouter",features:["Shape matching","Dimension binding","Multi-line syntax"]},{id:"variadic-shapes",title:"Variadic Wildcards",category:"Advanced",description:"Match variable-length shape prefixes",code:"# Process tensors with arbitrary leading dimensions\nneuron FlexibleNorm(dim):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            out",targetNeuron:"FlexibleNorm",features:["Variadic wildcards","Shape prefixes","Rank-agnostic"]},{id:"attention-head",title:"Attention Head",category:"Real World",description:"Single attention head with Q, K, V projections",code:"# Single-head scaled dot-product attention\nneuron AttentionHead(dim, head_dim):\n    in: [batch, seq, dim]\n    out: [batch, seq, head_dim]\n    graph:\n        # Project to Q, K, V\n        in -> Fork3() -> (q_in, k_in, v_in)\n        q_in -> Linear(dim, head_dim) -> q\n        k_in -> Linear(dim, head_dim) -> k\n        v_in -> Linear(dim, head_dim) -> v\n\n        # Compute attention\n        (q, k, v) -> ScaledDotProductAttention(head_dim) -> out",targetNeuron:"AttentionHead",features:["Multi-input operations","Attention mechanism","Fork-join pattern"]},{id:"transformer-ffn",title:"Transformer FFN",category:"Real World",description:"Feed-forward network from transformer",code:"# Transformer feed-forward network with residual\nneuron TransformerFFN(dim):\n    in: [batch, seq, dim]\n    out: [batch, seq, dim]\n    graph:\n        in -> Fork() -> (main, skip)\n\n        main ->\n            LayerNorm(dim)\n            Linear(dim, dim * 4)\n            GELU()\n            Linear(dim * 4, dim)\n            Dropout(0.1)\n            processed\n\n        (processed, skip) -> Add() -> out",targetNeuron:"TransformerFFN",features:["Transformer components","Dropout","Standard architecture"]},{id:"simple-cnn",title:"CNN Block",category:"Real World",description:"Convolutional block with batch norm",code:"# Basic CNN block with conv + norm + activation\nneuron ConvBlock(channels):\n    in: [batch, channels, h, w]\n    out: [batch, channels, h, w]\n    graph:\n        in ->\n            Conv2d(channels, channels, kernel_size=3, padding=1)\n            BatchNorm(channels)\n            ReLU()\n            out",targetNeuron:"ConvBlock",features:["Convolutional layers","Batch normalization","2D operations"]}];function t(){const e={};return r.forEach(n=>{e[n.category]||(e[n.category]=[]),e[n.category].push(n)}),e}function i(e){return r.find(n=>n.id===e)}},4113(e,n,o){o.d(n,{A:()=>a});const r={defaultToken:"",tokenPostfix:".neuroscript",keywords:["neuron","use","in","out","impl","graph","context","match","where","if","elif","else","unroll","external","and","or","Freeze"],portKeywords:["in","out"],sectionKeywords:["graph","context","impl"],controlKeywords:["match","where","if","elif","else","unroll"],booleans:["true","false"],annotations:["lazy","static","global"],operators:["->","==","!=","<=",">=","<",">","=","+","-","*","/"],tokenizer:{root:[[/\/\/\/.*$/,"comment.doc"],[/#.*$/,"comment"],[/`[^`]*`/,"string"],[/@(lazy|static|global)\b/,"annotation"],[/\b(neuron)(\s+)([A-Z][A-Za-z0-9_]*)/,["keyword.declaration","white","type.identifier"]],[/\b(neuron)\b/,"keyword.declaration"],[/\b(use)\b/,"keyword.import"],[/\b(in|out)\b/,"keyword.port"],[/\b(graph|context|impl)\b/,"keyword.section"],[/\b(match|where)\b/,"keyword.control"],[/\b(if|elif|else)\b/,"keyword.conditional"],[/\b(unroll)\b/,"keyword.loop"],[/\b(and|or)\b/,"keyword.logical"],[/\b(external)\b/,"keyword"],[/\b(Freeze)\b/,"keyword.freeze"],[/\b(true|false)\b/,"constant.boolean"],[/\b([A-Z][A-Za-z0-9_]*)\s*(?=\()/,"function"],[/\b[A-Z][A-Za-z0-9_]*\b/,"type.identifier"],[/-?\d+\.\d+(?:[eE][+-]?\d+)?/,"number.float"],[/-?\b\d+\b/,"number"],[/->/,"keyword.arrow"],[/==|!=|<=|>=|<|>/,"operator.comparison"],[/(?<![=!<>])=(?!=)/,"operator.assignment"],[/[+\-*/]/,"operator.arithmetic"],[/\[/,{token:"delimiter.bracket.shape",next:"@shape"}],[/[()]/,"delimiter.parenthesis"],[/:/,"delimiter"],[/,/,"delimiter"],[/\./,"delimiter.dot"],[/\b[a-z_][a-zA-Z0-9_]*\b/,"variable"],[/\s+/,"white"]],shape:[[/\]/,{token:"delimiter.bracket.shape",next:"@pop"}],[/(\*)([a-z_][a-zA-Z0-9_]*)/,["wildcard","variable"]],[/\*/,"wildcard"],[/\b\d+\b/,"number"],[/[+\-*/]/,"operator.arithmetic"],[/\b[a-z_][a-zA-Z0-9_]*\b/,"variable"],[/,/,"delimiter"],[/[()]/,"delimiter.parenthesis"],[/\s+/,"white"]]}},t={base:"vs",inherit:!0,rules:[{token:"comment",foreground:"6a737d",fontStyle:"italic"},{token:"comment.doc",foreground:"6a737d",fontStyle:"italic"},{token:"string",foreground:"032f62"},{token:"string.impl-ref",foreground:"032f62"},{token:"annotation",foreground:"e36209"},{token:"keyword",foreground:"d73a49"},{token:"keyword.declaration",foreground:"d73a49",fontStyle:"bold"},{token:"keyword.import",foreground:"d73a49"},{token:"keyword.port",foreground:"d73a49"},{token:"keyword.section",foreground:"d73a49"},{token:"keyword.control",foreground:"d73a49"},{token:"keyword.conditional",foreground:"d73a49"},{token:"keyword.loop",foreground:"d73a49"},{token:"keyword.logical",foreground:"d73a49"},{token:"keyword.freeze",foreground:"d73a49"},{token:"keyword.arrow",foreground:"d73a49"},{token:"constant.boolean",foreground:"005cc5"},{token:"number",foreground:"005cc5"},{token:"number.float",foreground:"005cc5"},{token:"function",foreground:"6f42c1"},{token:"type.identifier",foreground:"6f42c1"},{token:"variable",foreground:"24292e"},{token:"namespace",foreground:"e36209"},{token:"wildcard",foreground:"e36209",fontStyle:"bold"},{token:"operator.comparison",foreground:"d73a49"},{token:"operator.assignment",foreground:"d73a49"},{token:"operator.arithmetic",foreground:"d73a49"},{token:"delimiter",foreground:"24292e"},{token:"delimiter.bracket.shape",foreground:"e36209"},{token:"delimiter.parenthesis",foreground:"24292e"},{token:"delimiter.dot",foreground:"24292e"}],colors:{"editor.background":"#ffffff","editor.foreground":"#24292e"}},i={base:"vs-dark",inherit:!0,rules:[{token:"comment",foreground:"6272a4",fontStyle:"italic"},{token:"comment.doc",foreground:"6272a4",fontStyle:"italic"},{token:"string",foreground:"f1fa8c"},{token:"string.impl-ref",foreground:"f1fa8c"},{token:"annotation",foreground:"ffb86c"},{token:"keyword",foreground:"ff79c6"},{token:"keyword.declaration",foreground:"ff79c6",fontStyle:"bold"},{token:"keyword.import",foreground:"ff79c6"},{token:"keyword.port",foreground:"ff79c6"},{token:"keyword.section",foreground:"ff79c6"},{token:"keyword.control",foreground:"ff79c6"},{token:"keyword.conditional",foreground:"ff79c6"},{token:"keyword.loop",foreground:"ff79c6"},{token:"keyword.logical",foreground:"ff79c6"},{token:"keyword.freeze",foreground:"ff79c6"},{token:"keyword.arrow",foreground:"ff79c6"},{token:"constant.boolean",foreground:"bd93f9"},{token:"number",foreground:"bd93f9"},{token:"number.float",foreground:"bd93f9"},{token:"function",foreground:"50fa7b"},{token:"type.identifier",foreground:"8be9fd"},{token:"variable",foreground:"f8f8f2"},{token:"namespace",foreground:"ffb86c"},{token:"wildcard",foreground:"ffb86c",fontStyle:"bold"},{token:"operator.comparison",foreground:"ff79c6"},{token:"operator.assignment",foreground:"ff79c6"},{token:"operator.arithmetic",foreground:"ff79c6"},{token:"delimiter",foreground:"f8f8f2"},{token:"delimiter.bracket.shape",foreground:"ffb86c"},{token:"delimiter.parenthesis",foreground:"f8f8f2"},{token:"delimiter.dot",foreground:"f8f8f2"}],colors:{"editor.background":"#282a36","editor.foreground":"#f8f8f2"}};function a(e){e.languages.getLanguages().some(e=>"neuroscript"===e.id)||(e.languages.register({id:"neuroscript",extensions:[".ns"],aliases:["NeuroScript","neuroscript"]}),e.languages.setMonarchTokensProvider("neuroscript",r),e.languages.setLanguageConfiguration("neuroscript",{comments:{lineComment:"#"},brackets:[["(",")"],["[","]"]],autoClosingPairs:[{open:"(",close:")"},{open:"[",close:"]"},{open:"`",close:"`"}],surroundingPairs:[{open:"(",close:")"},{open:"[",close:"]"},{open:"`",close:"`"}],indentationRules:{increaseIndentPattern:/^\s*(neuron|graph|context|match|if|elif|else|unroll)\b.*:\s*$/,decreaseIndentPattern:/^\s*$/},wordPattern:/[a-zA-Z_][a-zA-Z0-9_]*/}),e.editor.defineTheme("neuroscript-light",t),e.editor.defineTheme("neuroscript-dark",i))}},6407(e,n,o){e.exports=o.p+"0b3eee2d716c4c32.wasm"},8453(e,n,o){o.d(n,{R:()=>a,x:()=>s});var r=o(6540);const t={},i=r.createContext(t);function a(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);