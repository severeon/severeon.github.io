"use strict";(globalThis.webpackChunkneuroscript_docs=globalThis.webpackChunkneuroscript_docs||[]).push([[4142],{2370(n,e,i){i.r(e),i.d(e,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"tutorials/conditionals","title":"Conditionals","description":"Route tensors with if/elif/else based on parameters","source":"@site/docs/tutorials/conditionals.mdx","sourceDirName":"tutorials","slug":"/tutorials/conditionals","permalink":"/docs/tutorials/conditionals","draft":false,"unlisted":false,"editUrl":"https://github.com/neuroscript/neuroscript/tree/main/website/docs/tutorials/conditionals.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Conditionals","description":"Route tensors with if/elif/else based on parameters"},"sidebar":"docsSidebar","previous":{"title":"Match and Guards","permalink":"/docs/tutorials/match-guards"},"next":{"title":"Unroll","permalink":"/docs/tutorials/unroll"}}');var t=i(4848),s=i(8453),a=i(3620);const r={sidebar_position:4,title:"Conditionals",description:"Route tensors with if/elif/else based on parameters"},l="Conditionals (if / elif / else)",d={},c=[{value:"When to Use Each",id:"when-to-use-each",level:2},{value:"Basic Syntax",id:"basic-syntax",level:2},{value:"Inline Conditionals",id:"inline-conditionals",level:2},{value:"Multi-Line Conditionals",id:"multi-line-conditionals",level:2},{value:"Using elif",id:"using-elif",level:2},{value:"Conditionals with Context Bindings",id:"conditionals-with-context-bindings",level:2},{value:"Composing Conditional Neurons",id:"composing-conditional-neurons",level:2},{value:"Comparison with Match Expressions",id:"comparison-with-match-expressions",level:2},{value:"Try It Yourself",id:"try-it-yourself",level:2}];function h(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"conditionals-if--elif--else",children:"Conditionals (if / elif / else)"})}),"\n",(0,t.jsxs)(e.p,{children:["NeuroScript's ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"elif"}),"/",(0,t.jsx)(e.code,{children:"else"})," expressions let you choose between pipelines based on neuron ",(0,t.jsx)(e.strong,{children:"parameters"})," \u2014 values known at compile time like flags, counts, or modes. This complements ",(0,t.jsx)(e.a,{href:"./match-guards",children:"match expressions"}),", which branch on tensor ",(0,t.jsx)(e.strong,{children:"shapes"})," at runtime."]}),"\n",(0,t.jsx)(e.h2,{id:"when-to-use-each",children:"When to Use Each"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Construct"}),(0,t.jsx)(e.th,{children:"Branches on"}),(0,t.jsx)(e.th,{children:"Known at"}),(0,t.jsx)(e.th,{children:"Use for"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"elif"}),"/",(0,t.jsx)(e.code,{children:"else"})]}),(0,t.jsx)(e.td,{children:"Parameter values"}),(0,t.jsx)(e.td,{children:"Compile time"}),(0,t.jsx)(e.td,{children:"Feature flags, mode selection, depth guards"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.code,{children:"match"})," with guards"]}),(0,t.jsx)(e.td,{children:"Tensor shapes"}),(0,t.jsx)(e.td,{children:"Runtime"}),(0,t.jsx)(e.td,{children:"Adaptive processing based on input dimensions"})]})]})]}),"\n",(0,t.jsx)(e.h2,{id:"basic-syntax",children:"Basic Syntax"}),"\n",(0,t.jsxs)(e.p,{children:["The simplest form is an inline ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"if condition: pipeline else: pipeline\n"})}),"\n",(0,t.jsx)(e.p,{children:"Or as a multi-line block inside a pipeline:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"in ->\n    if condition: NeuronA()\n    else: NeuronB()\n    out\n"})}),"\n",(0,t.jsx)(e.h2,{id:"inline-conditionals",children:"Inline Conditionals"}),"\n",(0,t.jsxs)(e.p,{children:["Use inline ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"})," when each branch is a short pipeline:"]}),"\n",(0,t.jsx)(a.A,{title:"Optional Pooling",description:"A flag parameter controls whether pooling is applied",initialCode:"neuron ConvBlock(in_ch, out_ch, has_pool=true):\nin: [batch, in_ch, h, w]\nout: [batch, out_ch, h, w]\ncontext:\n  conv = Conv2d(in_ch, out_ch, 3, padding=1)\n  bn = BatchNorm(out_ch)\n  act = ReLU()\ngraph:\n  in -> conv -> bn -> act\n  act -> if has_pool: MaxPool(2, stride=2) -> out else: Identity() -> out"}),"\n",(0,t.jsxs)(e.p,{children:["Here ",(0,t.jsx)(e.code,{children:"has_pool"})," is a parameter with a default value of ",(0,t.jsx)(e.code,{children:"true"}),". The compiler statically resolves which branch to include."]}),"\n",(0,t.jsx)(e.h2,{id:"multi-line-conditionals",children:"Multi-Line Conditionals"}),"\n",(0,t.jsx)(e.p,{children:"When branches contain multi-step pipelines, use the indented block form:"}),"\n",(0,t.jsx)(a.A,{title:"Multi-Line Conditional",description:"Indented if/else with multi-step branches that feed into the next pipeline step",initialCode:"neuron ConvBlock(in_ch, out_ch, has_pool=true):\nin: [batch, in_ch, h, w]\nout: [batch, out_ch, h, w]\ncontext:\n  conv = Conv2d(in_ch, out_ch, 3, padding=1)\n  bn = BatchNorm(out_ch)\n  act = ReLU()\n  @lazy pool = MaxPool(2, stride=2)\ngraph:\n  in ->\n    conv\n    bn\n    act\n    if has_pool: pool\n    else: Identity()\n    out"}),"\n",(0,t.jsxs)(e.p,{children:["Both branches flow into ",(0,t.jsx)(e.code,{children:"out"})," \u2014 the conditional sits inline within the pipeline, and the next step after the ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"})," block receives whichever branch was selected."]}),"\n",(0,t.jsx)(e.h2,{id:"using-elif",children:"Using elif"}),"\n",(0,t.jsxs)(e.p,{children:["For multi-way branching, add ",(0,t.jsx)(e.code,{children:"elif"})," arms:"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"neuron FlexibleNorm(dim, mode=1):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            if mode == 0: Identity()\n            elif mode == 1: LayerNorm(dim)\n            elif mode == 2: BatchNorm(dim)\n            else: RMSNorm(dim)\n            out\n"})}),"\n",(0,t.jsxs)(e.p,{children:["Each condition is checked in order. The first truthy condition wins. The ",(0,t.jsx)(e.code,{children:"else"})," arm is the fallback."]}),"\n",(0,t.jsx)(e.h2,{id:"conditionals-with-context-bindings",children:"Conditionals with Context Bindings"}),"\n",(0,t.jsxs)(e.p,{children:["When a conditional branch references a neuron that should only be instantiated if the condition is true, use ",(0,t.jsx)(e.code,{children:"@lazy"}),":"]}),"\n",(0,t.jsx)(a.A,{title:"Lazy Conditional",description:"@lazy ensures the pool module is only instantiated when has_pool is true",initialCode:"neuron ConvBlock(in_ch, out_ch, has_pool=true):\nin: [batch, in_ch, h, w]\nout: [batch, out_ch, h, w]\ncontext:\n  conv = Conv2d(in_ch, out_ch, 3, padding=1)\n  bn = BatchNorm(out_ch)\n  act = ReLU()\n  @lazy pool = MaxPool(2, stride=2)\ngraph:\n  in -> conv -> bn -> act\n  act ->\n    if has_pool: pool\n    else: Identity()\n    out"}),"\n",(0,t.jsxs)(e.p,{children:["Without ",(0,t.jsx)(e.code,{children:"@lazy"}),", the pool module would be instantiated in ",(0,t.jsx)(e.code,{children:"__init__"})," even when ",(0,t.jsx)(e.code,{children:"has_pool"})," is ",(0,t.jsx)(e.code,{children:"false"}),". The ",(0,t.jsx)(e.code,{children:"@lazy"})," annotation defers instantiation until the binding is actually used."]}),"\n",(0,t.jsx)(e.h2,{id:"composing-conditional-neurons",children:"Composing Conditional Neurons"}),"\n",(0,t.jsx)(e.p,{children:"Conditionals compose naturally \u2014 callers control the flag:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"neuron CNN(in_channels, num_classes):\n    in: [batch, in_channels, h, w]\n    out: [batch, num_classes]\n    context:\n        conv1 = ConvBlock(in_channels, 32)             # has_pool defaults to true\n        conv2 = ConvBlock(32, 64)                       # has_pool defaults to true\n        conv3 = ConvBlock(64, 128, has_pool=false)      # no pooling on last block\n    graph:\n        in -> conv1 -> conv2 -> conv3 -> GlobalAvgPool() -> Flatten(1) -> Linear(128, num_classes) -> out\n"})}),"\n",(0,t.jsx)(e.h2,{id:"comparison-with-match-expressions",children:"Comparison with Match Expressions"}),"\n",(0,t.jsx)(e.p,{children:"Both constructs route data, but they serve different purposes:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-neuroscript",children:"# if/elif/else: parameter-based (compile-time)\nin ->\n    if use_attention: MultiHeadSelfAttention(dim, heads)\n    else: Linear(dim, dim)\n    out\n\n# match: shape-based (runtime)\nin -> match:\n    [*, d] where d > 512: Linear(d, 512) -> out\n    [*, d]: Linear(d, 256) -> Linear(256, 512) -> out\n"})}),"\n",(0,t.jsxs)(e.p,{children:["Use ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"elif"}),"/",(0,t.jsx)(e.code,{children:"else"})," when the decision depends on a parameter. Use ",(0,t.jsx)(e.code,{children:"match"})," when it depends on the actual tensor shape flowing through the graph."]}),"\n",(0,t.jsx)(e.h2,{id:"try-it-yourself",children:"Try It Yourself"}),"\n",(0,t.jsx)(e.p,{children:"Experiment with conditionals:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Change the ",(0,t.jsx)(e.code,{children:"has_pool"})," default value and see how the output changes"]}),"\n",(0,t.jsxs)(e.li,{children:["Add an ",(0,t.jsx)(e.code,{children:"elif"})," arm for a third option"]}),"\n",(0,t.jsxs)(e.li,{children:["Combine ",(0,t.jsx)(e.code,{children:"if"}),"/",(0,t.jsx)(e.code,{children:"else"})," with ",(0,t.jsx)(e.code,{children:"@lazy"})," bindings for conditional module instantiation"]}),"\n",(0,t.jsx)(e.li,{children:'Click "Show Analysis" to see which branch the compiler selects'}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(h,{...n})}):h(n)}},2829(n,e,i){let o;function t(n,e){return function(n,e){h+=e,h>=c&&(d=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0}),d.decode(),h=e);return d.decode(a().subarray(n,n+e))}(n>>>=0,e)}i.d(e,{Ay:()=>j,MQ:()=>_,ns:()=>m,wE:()=>f});let s=null;function a(){return null!==s&&0!==s.byteLength||(s=new Uint8Array(o.memory.buffer)),s}function r(n,e,i){if(void 0===i){const i=u.encode(n),o=e(i.length,1)>>>0;return a().subarray(o,o+i.length).set(i),p=i.length,o}let o=n.length,t=e(o,1)>>>0;const s=a();let r=0;for(;r<o;r++){const e=n.charCodeAt(r);if(e>127)break;s[t+r]=e}if(r!==o){0!==r&&(n=n.slice(r)),t=i(t,o,o=r+3*n.length,1)>>>0;const e=a().subarray(t+r,t+o);r+=u.encodeInto(n,e).written,t=i(t,o,r,1)>>>0}return p=r,t}function l(n){const e=o.__wbindgen_externrefs.get(n);return o.__externref_table_dealloc(n),e}let d=new TextDecoder("utf-8",{ignoreBOM:!0,fatal:!0});d.decode();const c=2146435072;let h=0;const u=new TextEncoder;"encodeInto"in u||(u.encodeInto=function(n,e){const i=u.encode(n);return e.set(i),{read:n.length,written:i.length}});let p=0;function m(n){let e,i;try{const d=r(n,o.__wbindgen_malloc,o.__wbindgen_realloc),c=p,h=o.analyze(d,c);var s=h[0],a=h[1];if(h[3])throw s=0,a=0,l(h[2]);return e=s,i=a,t(s,a)}finally{o.__wbindgen_free(e,i,1)}}function f(n,e){let i,s;try{const u=r(n,o.__wbindgen_malloc,o.__wbindgen_realloc),m=p;var a=null==e?0:r(e,o.__wbindgen_malloc,o.__wbindgen_realloc),d=p;const f=o.compile(u,m,a,d);var c=f[0],h=f[1];if(f[3])throw c=0,h=0,l(f[2]);return i=c,s=h,t(c,h)}finally{o.__wbindgen_free(i,s,1)}}function _(n){let e,i;try{const d=r(n,o.__wbindgen_malloc,o.__wbindgen_realloc),c=p,h=o.list_neurons(d,c);var s=h[0],a=h[1];if(h[3])throw s=0,a=0,l(h[2]);return e=s,i=a,t(s,a)}finally{o.__wbindgen_free(e,i,1)}}const x=new Set(["basic","cors","default"]);function g(){const n={wbg:{}};return n.wbg.__wbindgen_cast_2241b6af4c4b2941=function(n,e){return t(n,e)},n.wbg.__wbindgen_init_externref_table=function(){const n=o.__wbindgen_externrefs,e=n.grow(4);n.set(0,void 0),n.set(e+0,void 0),n.set(e+1,null),n.set(e+2,!0),n.set(e+3,!1)},n}function b(n,e){return o=n.exports,y.__wbindgen_wasm_module=e,s=null,o.__wbindgen_start(),o}async function y(n){if(void 0!==o)return o;void 0!==n&&(Object.getPrototypeOf(n)===Object.prototype?({module_or_path:n}=n):console.warn("using deprecated parameters for the initialization function; pass a single object instead")),void 0===n&&(n=new URL(i(6407),i.b));const e=g();("string"==typeof n||"function"==typeof Request&&n instanceof Request||"function"==typeof URL&&n instanceof URL)&&(n=fetch(n));const{instance:t,module:s}=await async function(n,e){if("function"==typeof Response&&n instanceof Response){if("function"==typeof WebAssembly.instantiateStreaming)try{return await WebAssembly.instantiateStreaming(n,e)}catch(i){if(!n.ok||!x.has(n.type)||"application/wasm"===n.headers.get("Content-Type"))throw i;console.warn("`WebAssembly.instantiateStreaming` failed because your server does not serve Wasm with `application/wasm` MIME type. Falling back to `WebAssembly.instantiate` which is slower. Original error:\n",i)}const o=await n.arrayBuffer();return await WebAssembly.instantiate(o,e)}{const i=await WebAssembly.instantiate(n,e);return i instanceof WebAssembly.Instance?{instance:i,module:n}:i}}(await n,e);return b(t,s)}const j=y},3620(n,e,i){i.d(e,{A:()=>r});var o=i(6540),t=i(2829),s=i(9350),a=i(4848);function r({initialCode:n,title:e,description:i,showAnalysis:r=!0,height:l="300px"}){const[d,c]=(0,o.useState)(n||""),[h,u]=(0,o.useState)(""),[p,m]=(0,o.useState)(null),[f,_]=(0,o.useState)(""),[x,g]=(0,o.useState)(!1),[b,y]=(0,o.useState)(!1);(0,o.useEffect)(()=>{(0,t.Ay)().then(()=>{g(!0),j(n||"")}).catch(n=>{console.error("WASM init failed:",n),_("Failed to initialize compiler: "+n)})},[]);const j=n=>{if(x)try{const i=n.replace(/^use .*$/gm,"# $&"),o=s.y+"\n"+i,a=(0,t.wE)(o);if(u(a),_(""),r)try{const n=(0,t.ns)(o);m(JSON.parse(n))}catch(e){m(null)}}catch(i){_(i.toString()),u(""),m(null)}};return(0,a.jsxs)("div",{className:"interactive-example",style:{marginBottom:"2rem"},children:[e&&(0,a.jsx)("h3",{style:{marginBottom:"0.5rem"},children:e}),i&&(0,a.jsx)("p",{style:{marginBottom:"1rem",color:"#666"},children:i}),(0,a.jsxs)("div",{style:{display:"flex",gap:"1rem",minHeight:l},children:[(0,a.jsxs)("div",{style:{flex:1,display:"flex",flexDirection:"column"},children:[(0,a.jsx)("div",{style:{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:"0.5rem"},children:(0,a.jsx)("strong",{style:{fontSize:"0.9rem",color:"#666"},children:"NeuroScript"})}),(0,a.jsx)("textarea",{value:d,onChange:n=>{const e=n.target.value;c(e),j(e)},style:{flex:1,fontFamily:'ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, monospace',padding:"1rem",resize:"none",borderRadius:"8px",border:"1px solid #ccc",fontSize:"13px",lineHeight:"1.5",backgroundColor:"#1e1e1e",color:"#d4d4d4"},spellCheck:"false"})]}),(0,a.jsxs)("div",{style:{flex:1,display:"flex",flexDirection:"column"},children:[(0,a.jsxs)("div",{style:{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:"0.5rem"},children:[(0,a.jsx)("strong",{style:{fontSize:"0.9rem",color:"#666"},children:"PyTorch Output"}),r&&p&&(0,a.jsx)("button",{onClick:()=>y(!b),style:{padding:"4px 8px",fontSize:"0.8rem",borderRadius:"4px",border:"1px solid #ccc",backgroundColor:b?"#e0f0e0":"#fff",cursor:"pointer"},children:b?"Hide Analysis":"Show Analysis"})]}),f?(0,a.jsx)("div",{style:{flex:1,backgroundColor:"#fff0f0",color:"#d00",padding:"1rem",fontFamily:'ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, monospace',fontSize:"13px",whiteSpace:"pre-wrap",overflow:"auto",borderRadius:"8px",border:"1px solid #ffcccc"},children:f}):(0,a.jsx)("textarea",{readOnly:!0,value:h,style:{flex:1,fontFamily:'ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, monospace',padding:"1rem",backgroundColor:"#1e1e1e",color:"#d4d4d4",resize:"none",borderRadius:"8px",border:"1px solid #333",fontSize:"13px",lineHeight:"1.5"}})]})]}),r&&b&&p&&(0,a.jsxs)("div",{style:{marginTop:"1rem",padding:"1rem",backgroundColor:"#f8f9fa",borderRadius:"8px",border:"1px solid #e0e0e0"},children:[(0,a.jsx)("h4",{style:{margin:"0 0 1rem 0",fontSize:"1rem"},children:"Shape Analysis"}),p.neurons&&p.neurons.filter(n=>!n.is_primitive).map((n,e)=>(0,a.jsxs)("div",{style:{marginBottom:"1rem"},children:[(0,a.jsxs)("div",{style:{fontWeight:"bold",marginBottom:"0.5rem"},children:[n.name,n.params.length>0&&(0,a.jsxs)("span",{style:{fontWeight:"normal",color:"#666"},children:["(",n.params.map(n=>n.name).join(", "),")"]})]}),(0,a.jsxs)("div",{style:{display:"grid",gridTemplateColumns:"auto 1fr",gap:"0.25rem 1rem",fontSize:"0.9rem",paddingLeft:"1rem"},children:[n.inputs.map((n,e)=>(0,a.jsxs)(o.Fragment,{children:[(0,a.jsxs)("span",{style:{color:"#666"},children:["in","default"!==n.name?` ${n.name}`:"",":"]}),(0,a.jsx)("code",{style:{backgroundColor:"#e8f5e9",padding:"2px 6px",borderRadius:"3px",fontSize:"0.85rem"},children:n.shape})]},`in-${e}`)),n.outputs.map((n,e)=>(0,a.jsxs)(o.Fragment,{children:[(0,a.jsxs)("span",{style:{color:"#666"},children:["out","default"!==n.name?` ${n.name}`:"",":"]}),(0,a.jsx)("code",{style:{backgroundColor:"#e3f2fd",padding:"2px 6px",borderRadius:"3px",fontSize:"0.85rem"},children:n.shape})]},`out-${e}`))]}),n.connections.length>0&&(0,a.jsxs)("div",{style:{marginTop:"0.5rem",paddingLeft:"1rem"},children:[(0,a.jsx)("span",{style:{color:"#666",fontSize:"0.85rem"},children:"Connections:"}),(0,a.jsx)("div",{style:{fontFamily:"ui-monospace, SFMono-Regular, monospace",fontSize:"0.8rem",color:"#444",marginTop:"0.25rem"},children:n.connections.map((n,e)=>(0,a.jsxs)("div",{children:[n.source," \u2192 ",n.destination]},e))})]})]},e)),p.match_expressions&&p.match_expressions.length>0&&(0,a.jsxs)("div",{style:{marginTop:"1rem"},children:[(0,a.jsx)("h5",{style:{margin:"0 0 0.5rem 0",fontSize:"0.9rem"},children:"Match Expressions"}),p.match_expressions.map((n,e)=>(0,a.jsxs)("div",{style:{marginBottom:"0.5rem",paddingLeft:"1rem"},children:[(0,a.jsxs)("div",{style:{fontSize:"0.85rem",color:"#666"},children:["In ",n.neuron,":"]}),n.arms.map((n,e)=>(0,a.jsxs)("div",{style:{display:"flex",alignItems:"center",gap:"0.5rem",fontSize:"0.85rem",marginLeft:"1rem",opacity:n.is_reachable?1:.5},children:[(0,a.jsxs)("code",{style:{backgroundColor:n.is_reachable?"#fff3e0":"#f5f5f5",padding:"2px 6px",borderRadius:"3px"},children:[n.pattern,n.guard&&(0,a.jsxs)("span",{style:{color:"#666"},children:[" where ",n.guard]})]}),!n.is_reachable&&(0,a.jsx)("span",{style:{color:"#999",fontSize:"0.8rem"},children:"(unreachable)"})]},e))]},e))]})]})]})}},6407(n,e,i){n.exports=i.p+"fbb2bcaa77df6bc9.wasm"},8453(n,e,i){i.d(e,{R:()=>a,x:()=>r});var o=i(6540);const t={},s=o.createContext(t);function a(n){const e=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:a(n.components),o.createElement(s.Provider,{value:e},n.children)}},9350(n,e,i){i.d(e,{y:()=>o});const o="\n\n\nneuron FFN(dim, expansion):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    graph:\n        in ->\n            Linear(dim, expansion)\n            GELU()\n            Linear(expansion, dim)\n            out\n\nneuron FFNWithHidden(in_dim, hidden_dim, out_dim):\n    in: [*shape, in_dim]\n    out: [*shape, out_dim]\n    graph:\n        in ->\n            Linear(in_dim, hidden_dim)\n            GELU()\n            Linear(hidden_dim, out_dim)\n            out\n\nneuron ParallelFFN(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in -> FFN(dim, dim * 2) -> out\n\nneuron AdaptiveAvgPool(output_size):\n    in: [batch, channels, *, *]\n    out: [batch, channels, output_size, output_size]\n    impl: core,pooling/AdaptiveAvgPool\n\nneuron AdaptiveMaxPool(output_size):\n    in: [batch, channels, *, *]\n    out: [batch, channels, output_size, output_size]\n    impl: core,pooling/AdaptiveMaxPool\n\nneuron Add:\n    in main: [*shape]\n    in skip: [*shape]\n    out: [*shape]\n    impl: core,structural/Add\n\nneuron AvgPool(kernel_size, stride=1, padding=0):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,pooling/AvgPool\n\nneuron BatchNorm(num_features):\n    in: [*shape, num_features]\n    out: [*shape, num_features]\n    impl: core,normalization/BatchNorm\n\nneuron Bias(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,operations/Bias\n\nneuron Concat(dim):\n    in a: [*shape_a]\n    in b: [*shape_b]\n    out: [*shape_out]\n    impl: core,structural/Concat\n\nneuron Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, length]\n    out: [batch, out_channels, *]\n    impl: core,convolutions/Conv1d\n\nneuron Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/Conv2d\n\nneuron Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, depth, height, width]\n    out: [batch, out_channels, *, *, *]\n    impl: core,convolutions/Conv3d\n\nneuron DepthwiseConv(channels, kernel_size, stride=1, padding=0, dilation=1, bias=true):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,convolutions/DepthwiseConv\n\nneuron DropConnect(drop_prob):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/DropConnect\n\nneuron Dropout(p):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/Dropout\n\nneuron DropPath(drop_prob):\n    in: [*shape]\n    out: [*shape]\n    impl: core,regularization/DropPath\n\nneuron Einsum(equation):\n    in a: [*shape_a]\n    in b: [*shape_b]\n    out: [*shape_out]\n    impl: core,operations/Einsum\n\nneuron ELU(alpha=1.0):\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/ELU\n\nneuron Embedding(num_embeddings, embedding_dim):\n    in: [*, seq_len]\n    out: [*, seq_len, embedding_dim]\n    impl: core,embeddings/Embedding\n\nneuron Flatten(start_dim=1, end_dim=-1):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Flatten\n\nneuron Fork:\n    in: [*shape]\n    out main: [*shape]\n    out skip: [*shape]\n    impl: core,structural/Fork\n\nneuron Fork3:\n    in: [*shape]\n    out a: [*shape]\n    out b: [*shape]\n    out c: [*shape]\n    impl: core,structural/Fork3\n\nneuron GELU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/GELU\n\nneuron GlobalAvgPool:\n    in: [batch, channels, *, *]\n    out: [batch, channels, 1, 1]\n    impl: core,pooling/GlobalAvgPool\n\nneuron GlobalMaxPool:\n    in: [batch, channels, *, *]\n    out: [batch, channels, 1, 1]\n    impl: core,pooling/GlobalMaxPool\n\nneuron GroupNorm(num_groups, num_channels):\n    in: [*, num_channels, *, *]\n    out: [*, num_channels, *, *]\n    impl: core,normalization/GroupNorm\n\nneuron Identity:\n    in: [*shape]\n    out: [*shape]\n    impl: core,structural/Identity\n\nneuron InstanceNorm(num_features, eps=0.00001, affine=true):\n    in: [batch, num_features, *spatial]\n    out: [batch, num_features, *spatial]\n    impl: core,normalization/InstanceNorm\n\nneuron LayerNorm(dim):\n    in: [*shape, dim]\n    out: [*shape, dim]\n    impl: core,normalization/LayerNorm\n\nneuron LearnedPositionalEmbedding(max_positions, embedding_dim):\n    in: [*, seq_len, embedding_dim]\n    out: [*, seq_len, embedding_dim]\n    impl: core,embeddings/LearnedPositionalEmbedding\n\nneuron Linear(in_dim, out_dim):\n    in: [*, in_dim]\n    out: [*, out_dim]\n    impl: core,nn/Linear\n\nneuron MatMul:\n    in a: [*, n, m]\n    in b: [*, m, p]\n    out: [*, n, p]\n    impl: core,operations/MatMul\n\nneuron MaxPool(kernel_size, stride=1, padding=0, dilation=1):\n    in: [batch, channels, height, width]\n    out: [batch, channels, *, *]\n    impl: core,pooling/MaxPool\n\nneuron Mish:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Mish\n\nneuron MultiHeadSelfAttention(dim, num_heads):\n    in: [*, seq_len, dim]\n    out: [*, seq_len, dim]\n    impl: core,attention/MultiHeadSelfAttention\n\nneuron Multiply:\n    in a: [*shape]\n    in b: [*shape]\n    out: [*shape]\n    impl: core,structural/Multiply\n\nneuron Pad(padding, value=0, mode=constant):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Pad\n\nneuron PositionalEncoding(dim, max_len):\n    in: [*, seq_len, dim]\n    out: [*, seq_len, dim]\n    impl: core,embeddings/PositionalEncoding\n\nneuron PReLU(num_parameters=1, init=0.25):\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/PReLU\n\nneuron ReLU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/ReLU\n\nneuron Reshape(target_shape):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Reshape\n\nneuron RMSNorm(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,normalization/RMSNorm\n\nneuron RotaryEmbedding(dim, max_position_embeddings=2048, base=10000):\n    in query: [*batch, seq, num_heads, dim]\n    in key: [*batch, seq, num_heads, dim]\n    out q_out: [*batch, seq, num_heads, dim]\n    out k_out: [*batch, seq, num_heads, dim]\n    impl: neuroscript,embeddings/RotaryEmbedding\n\nneuron Scale(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,operations/Scale\n\nneuron ScaledDotProductAttention(d_k):\n    in query: [*, seq_q, d_k]\n    in key: [*, seq_k, d_k]\n    in value: [*, seq_v, d_v]\n    out: [*, seq_q, d_v]\n    impl: core,attention/ScaledDotProductAttention\n\nneuron SeparableConv(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/SeparableConv\n\nneuron Sigmoid:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Sigmoid\n\nneuron SiLU:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/SiLU\n\nneuron Slice(dim, start, end):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Slice\n\nneuron Softmax(dim):\n    in: [*, dim]\n    out: [*, dim]\n    impl: core,activations/Softmax\n\nneuron Split(num_splits, dim=-1):\n    in: [*shape]\n    out a: [*shape_a]\n    out b: [*shape_b]\n    impl: core,structural/Split\n\nneuron Tanh:\n    in: [*shape]\n    out: [*shape]\n    impl: core,activations/Tanh\n\nneuron Transpose(dims):\n    in: [*shape_in]\n    out: [*shape_out]\n    impl: core,structural/Transpose\n\nneuron TransposedConv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, groups=1, bias=true):\n    in: [batch, in_channels, height, width]\n    out: [batch, out_channels, *, *]\n    impl: core,convolutions/TransposedConv\n\nneuron SimpleTransformerBlock(dim):\n    in: [*, dim]\n    out: [*, dim]\n    graph:\n        in ->\n            LayerNorm(dim)\n            Linear(dim, dim)\n            Dropout(0.1)\n            out\n\nneuron TransformerBlock(dim, num_heads, d_ff):\n    in: [batch, seq, dim]\n    out: [batch, seq, dim]\n    graph:\n        in -> Fork() -> (skip1, attn_path)\n        attn_path ->\n            LayerNorm(dim)\n            MultiHeadSelfAttention(dim, num_heads)\n            Dropout(0.1)\n            attn_out\n        (skip1, attn_out) -> Add() -> attn_residual\n        attn_residual -> Fork() -> (skip2, ffn_path)\n        ffn_path ->\n            LayerNorm(dim)\n            FFN(dim, d_ff)\n            Dropout(0.1)\n            ffn_out\n        (skip2, ffn_out) -> Add() -> out\n\nneuron TransformerStack2(d_model, num_heads, d_ff):\n    in: [*, d_model]\n    out: [*, d_model]\n    graph:\n        in ->\n            SimpleTransformerBlock(d_model)\n            SimpleTransformerBlock(d_model)\n            out\n\nneuron SequentialTransformer(d_model, num_heads, d_ff):\n    in: [*, d_model]\n    out: [*, d_model]\n    graph:\n        in ->\n            SimpleTransformerBlock(d_model)\n            out\n"}}]);