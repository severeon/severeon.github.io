"use strict";(globalThis.webpackChunkneuroscript_docs=globalThis.webpackChunkneuroscript_docs||[]).push([[3650],{8453(e,n,i){i.d(n,{R:()=>r,x:()=>o});var d=i(6540);const s={},t=d.createContext(s);function r(e){const n=d.useContext(t);return d.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),d.createElement(t.Provider,{value:n},e.children)}},9374(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>a,frontMatter:()=>r,metadata:()=>d,toc:()=>c});const d=JSON.parse('{"id":"primitives/Embeddings/embedding","title":"Embedding","description":"Token Embedding","source":"@site/docs/primitives/Embeddings/embedding.md","sourceDirName":"primitives/Embeddings","slug":"/primitives/Embeddings/embedding","permalink":"/docs/primitives/Embeddings/embedding","draft":false,"unlisted":false,"editUrl":"https://github.com/neuroscript/neuroscript/tree/main/website/docs/primitives/Embeddings/embedding.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Embedding"},"sidebar":"docsSidebar","previous":{"title":"MultiHeadSelfAttention","permalink":"/docs/primitives/Attention/multiheadselfattention"},"next":{"title":"PositionalEncoding","permalink":"/docs/primitives/Embeddings/positionalencoding"}}');var s=i(4848),t=i(8453);const r={sidebar_label:"Embedding"},o="Embedding",l={},c=[{value:"Signature",id:"signature",level:2},{value:"Ports",id:"ports",level:2},{value:"Implementation",id:"implementation",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"embedding",children:"Embedding"})}),"\n",(0,s.jsx)(n.p,{children:"Token Embedding"}),"\n",(0,s.jsx)(n.p,{children:"Maps discrete token indices to dense continuous vectors. Fundamental\ncomponent for processing text, categorical data, or any discrete symbols."}),"\n",(0,s.jsx)(n.p,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"num_embeddings: Size of the vocabulary (number of unique tokens)"}),"\n",(0,s.jsx)(n.li,{children:"embedding_dim: Dimension of the dense embedding vectors"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Shape Contract:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Input: [*, seq_len] integer token indices"}),"\n",(0,s.jsx)(n.li,{children:"Output: [*, seq_len, embedding_dim] dense embeddings"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Notes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Input indices must be in range [0, num_embeddings)"}),"\n",(0,s.jsx)(n.li,{children:"Embeddings are learned parameters (initialized randomly)"}),"\n",(0,s.jsx)(n.li,{children:"Common in NLP: word embeddings, position embeddings, token type embeddings"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"signature",children:"Signature"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-neuroscript",children:"neuron Embedding(num_embeddings, embedding_dim)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"ports",children:"Ports"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Inputs:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"default"}),": ",(0,s.jsx)(n.code,{children:"[*, seq_len]"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Outputs:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"default"}),": ",(0,s.jsx)(n.code,{children:"[*, seq_len, embedding_dim]"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"implementation",children:"Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'Source { source: "core", path: "embeddings/Embedding" }\n'})})]})}function a(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}}}]);